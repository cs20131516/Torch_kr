


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
<meta property="og:title" content="PyTorch C++ 프론트엔드 사용하기" />
  
<meta property="og:type" content="article" />
  
<meta property="og:url" content="https://tutorials.pytorch.kr/advanced/cpp_frontend.html" />
  
<meta property="og:description" content="번역: 유용환 PyTorch C++ 프론트엔드는 PyTorch 머신러닝 프레임워크의 순수 C++ 인터페이스입니다. PyTorch의 주된 인터페이스는 물론 파이썬이지만 이 곳의 API는 텐서(tensor)나 자동 미분과 같은 기초적인 자료구조 및 기능을 제공하는 C++ 코드베이스 위에 구현되었습니다. C++ 프론트엔드는 이러한 기초적인 C++ 코드베이스를 비롯해 머신러닝 학습과 추론을 위해 필요한 도구들을 상속하는 순수 C++11 API를 제공합니다. 여기에는 신경망 모델링을 위해 필요한 공용 컴포넌트들의 빌트인 모음, 그것을 ..." />
  
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
  
<meta property="og:image:alt" content="PyTorch C++ 프론트엔드 사용하기" />
  
<meta property="og:ignore_canonical" content="true" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>PyTorch C++ 프론트엔드 사용하기 &mdash; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TorchScript의 동적 병렬 처리(Dynamic Parallelism)" href="torch-script-parallelism.html" />
    <link rel="prev" title="Forward-mode Automatic Differentiation (Beta)" href="../intermediate/forward_ad_usage.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.kr/get-started">시작하기</a>
          </li>

          <li class="active">
            <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
          </li>

          <li>
            <a href="https://pytorch.kr/hub">허브</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">커뮤니티</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.12.0+cu102
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">파이토치(PyTorch) 레시피</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">모든 레시피 보기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">모든 프로토타입 레시피 보기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">파이토치(PyTorch) 시작하기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/intro.html">파이토치(PyTorch) 기본 익히기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/quickstart_tutorial.html">빠른 시작(Quickstart)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/tensorqs_tutorial.html">텐서(Tensor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/data_tutorial.html">Dataset과 DataLoader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/transforms_tutorial.html">변형(Transform)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/buildmodel_tutorial.html">신경망 모델 구성하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/autogradqs_tutorial.html"><code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code>를 사용한 자동 미분</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/optimization_tutorial.html">모델 매개변수 최적화하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/saveloadrun_tutorial.html">모델 저장하고 불러오기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt.html">PyTorch 소개 - YouTube 시리즈</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/introyt1_tutorial.html">PyTorch 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">파이토치(PyTorch) 배우기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">PyTorch로 딥러닝하기: 60분만에 끝장내기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">예제로 배우는 파이토치(PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html"><cite>torch.nn</cite> 이 <em>실제로</em> 무엇인가요?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">TensorBoard로 모델, 데이터, 학습 시각화하기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">이미지/비디오</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision 객체 검출 미세조정(Finetuning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">적대적 예제 생성(Adversarial Example Generation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">배포를 위한 비전 트랜스포머(Vision Transformer) 모델 최적화하기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">오디오</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_data_augmentation_tutorial.html">오디오 데이터 증강</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_recognition_pipeline_tutorial.html">Wav2Vec2를 이용해서 음성 인식하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_command_classification_with_torchaudio_tutorial.html">Speech Command Classification with torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/text_to_speech_with_torchaudio.html">torchaudio를 사용하여 텍스트에서 음성으로 변환(text-to-speech)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">텍스트</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transformer_tutorial.html">nn.Transformer 와 TorchText 로 시퀀스-투-시퀀스(Sequence-to-Sequence) 모델링하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">기초부터 시작하는 NLP:  문자-단위 RNN으로 이름 생성하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">torchtext 라이브러리로 텍스트 분류하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/translation_transformer.html">nn.Transformer와 torchtext로 언어 번역하기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">강화학습</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">강화 학습 (DQN) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">마리오 게임 RL 에이전트로 학습하기</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch 모델을 프로덕션 환경에 배포하기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Flask를 사용하여 Python에서 PyTorch를 REST API로 배포하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">TorchScript 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_export.html">C++에서 TorchScript 모델 로딩하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_onnxruntime.html">(선택) PyTorch 모델을 ONNX으로 변환하고 ONNX 런타임에서 실행하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/realtime_rpi.html">Raspberry Pi 4 에서 실시간 추론(Inference) (30fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_conv_bn_fuser.html">(베타) FX에서 합성곱/배치 정규화(Convolution/Batch Norm) 결합기(Fuser) 만들기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">프론트엔드 API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(베타) PyTorch를 사용한 Channels Last 메모리 형식</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">PyTorch C++ 프론트엔드 사용하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch-script-parallelism.html">TorchScript의 동적 병렬 처리(Dynamic Parallelism)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_autograd.html">C++ 프론트엔드의 자동 미분 (autograd)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch 확장하기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_classes.html">커스텀 C++ 클래스로 TorchScript 확장하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">모델 최적화</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">PyTorch 모듈 프로파일링 하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Ray Tune을 이용한 하이퍼파라미터 튜닝</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">배포를 위한 비전 트랜스포머(Vision Transformer) 모델 최적화하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">가지치기 기법(Pruning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_quantization_tutorial.html">(베타) LSTM 기반 단어 단위 언어 모델의 동적 양자화</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(베타) BERT 모델 동적 양자화하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(베타) 컴퓨터 비전 튜토리얼을 위한 양자화된 전이학습(Quantized Transfer Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="static_quantization_tutorial.html">(베타) PyTorch에서 Eager Mode를 이용한 정적 양자화</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">병렬 및 분산 학습</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">단일 머신을 사용한 모델 병렬화 모범 사례</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">분산 데이터 병렬 처리 시작하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">PyTorch로 분산 어플리케이션 개발하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_ddp_tutorial.html">분산 데이터 병렬(DDP)과 분산 RPC 프레임워크 결합</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pipeline_tutorial.html">파이프라인 병렬화로 트랜스포머 모델 학습시키기</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_pipeline.html">분산 데이터 병렬 처리와 병렬 처리 파이프라인을 사용한 트랜스포머 모델 학습</a></li>
<li class="toctree-l1"><a class="reference internal" href="generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_ios.html">iOS에서의 이미지 분할 DeepLapV3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_android.html">안드로이드에서의 이미지 분할 DeepLapV3</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchrec_tutorial.html">TorchRec 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="sharding.html">Exploring TorchRec sharding</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>PyTorch C++ 프론트엔드 사용하기</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced/cpp_frontend.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">advanced/cpp_frontend</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        

          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="pytorch-c">
<h1>PyTorch C++ 프론트엔드 사용하기<a class="headerlink" href="#pytorch-c" title="Permalink to this headline">¶</a></h1>
<p><strong>번역</strong>: <a class="reference external" href="https://github.com/yoosful">유용환</a></p>
<p>PyTorch C++ 프론트엔드는 PyTorch 머신러닝 프레임워크의 순수 C++
인터페이스입니다. PyTorch의 주된 인터페이스는 물론 파이썬이지만
이 곳의 API는 텐서(tensor)나 자동 미분과 같은 기초적인 자료구조
및 기능을 제공하는 C++ 코드베이스 위에 구현되었습니다. C++
프론트엔드는 이러한 기초적인 C++ 코드베이스를 비롯해 머신러닝 학습과 추론을
위해 필요한 도구들을 상속하는 순수 C++11 API를 제공합니다. 여기에는
신경망 모델링을 위해 필요한 공용 컴포넌트들의 빌트인 모음, 그것을
상속하기 위한 커스텀 모듈, 확률적 경사 하강법과 같은 유명한 최적화 알고리즘
라이브러리, 병렬 데이터 로더 및 데이터셋을 정의하고 불러오기 위한
API, 직렬화 루틴 등이 포합됩니다.</p>
<p>이 튜토리얼은 C++ 프론트엔드로 모델을 학습하는 엔드 투 엔드
예제를 안내합니다. 구체적으로, 우리는 생성 모델 중 하나인
<a class="reference external" href="https://arxiv.org/abs/1511.06434">DCGAN</a> 을 학습시켜
MNIST 숫자 이미지들을 생성할 것입니다. 개념적으로 쉬운 예시이지만,
여러분이 PyTorch C++ 프론트엔드에 대한 대략적인 개요를 파악하고 더
복잡한 모델을 학습시키고 싶은 욕구를 불러일으키기에 충분할 것입니다.
먼저 C++ 프론트엔드 사용에 대한 동기부여가 될 만한 이야기로 시작하고,
곧바로 모델을 정의하고 학습해보도록 하겠습니다.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>C++ 프론트엔드에 대한 짧고 재미있는 발표를 보려면 <a class="reference external" href="https://www.youtube.com/watch?v=auRPXMMHJzc">CppCon 2018 라이트닝 토크</a> 를 시청하세요.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a class="reference external" href="https://pytorch.org/cppdocs/frontend.html">이 노트</a> 는 C++
프론트엔드의 컴포넌트와 디자인 철학의 전반적인 개요를 제공합니다.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>PyTorch C++ 생태계에 대한 문서는 <a class="reference external" href="https://pytorch.org">https://pytorch.org</a>/cppdocs에서
확인할 수 있습니다. API 레벨의 문서뿐만 아니라 개괄적인 설명도
찾을 수 있을 것입니다.</p>
</div>
<div class="section" id="id3">
<h2>동기부여<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>GAN과 MNIST 숫자로의 설레는 여정을 시작하기에 앞서, 먼저
파이썬 대신 C++ 프론트엔드를 사용하는 이유에 대해
설명하겠습니다. 우리(PyTorch 팀)는 파이썬을 사용할 수 없거나
사용하기에 적합하지 않은 환경에서 연구를 가능하게 하기 위해
C++ 프론트엔드를 만들었습니다. 예를 들면 다음과 같습니다.</p>
<ul class="simple">
<li><p><strong>저지연 시스템</strong>: 초당 프레임 수가 높고 지연 시간이 짧은
순수 C++ 게임 엔진에서 강화 학습 연구를 수행할 수 있습니다.
그러한 환경에서는 파이썬 라이브러리보다 순수 C++ 라이브러리를
사용하는 것이 훨씬 더 적합합니다. 파이썬은 느린 인터프리터
때문에 다루기가 쉽지 않습니다.</p></li>
<li><p><strong>고도의 멀티쓰레딩 환경</strong>: 글로벌 인터프리터 락(GIL)으로 인해
파이썬은 동시에 둘 이상의 시스템 쓰레드를 실행할 수 없습니다.
대안으로 멀티프로세싱을 사용하면 확장성이 떨어지며 심각한 한계가
있습니다. C++는 이러한 제약 조건이 없으며 쓰레드를 쉽게 만들고
사용할 수 있습니다. <a class="reference external" href="https://eng.uber.com/deep-neuroevolution/">Deep Neuroevolution</a> 에
사용된 것과 같이 고도의 병렬화가 필요한 모델도 이를 활용할 수
있습니다.</p></li>
<li><p><strong>기존의 C++ 코드베이스</strong>: 백엔드 서버의 웹 페이지 서비스부터
사진 편집 소프트웨어의 3D 그래픽 렌더링에 이르기까지 어떠한
작업이라도 수행하는 기존 C++ 애플리케이션 소유자로서, 머신러닝
방법론을 시스템에 통합하고 싶을 수 있습니다. C++ 프론트엔드는
PyTorch (파이썬) 경험 본연의 높은 유연성과 직관성을 유지하면서,
파이썬과 C++를 앞뒤로 바인딩하는 번거로움 없이 C++를 사용할 수
있게 해줍니다.</p></li>
</ul>
<p>C++ 프론트엔드의 목적은 파이썬 프론트엔드와 경쟁하는 것이 아닌
보완하는 것입니다. 연구자와 엔지니어 모두가 PyTorch의 단순성,
유연성 및 직관적인 API를 매우 좋아합니다. 우리의 목표는 여러분이
위의 예시를 비롯한 모든 가능한 환경에서 이 핵심 디자인 원칙을
이용할 수 있도록 하는 것입니다. 이러한 시나리오 중 하나가 여러분의
사례에 해당하거나, 단순히 관심이 있거나 궁금하다면 아래 내용을 통해
C++ 프론트엔드에 대해 자세히 살펴보세요.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<blockquote>
<div><p>C++ 프론트엔드는 파이썬 프론트엔드와 최대한 유사한 API를</p>
</div></blockquote>
<p>제공하고자 합니다. 만일 파이썬 프론트엔드에 익숙한 사람이 “C++
프론트엔드로 X를 어떻게 해야 하는가?” 의문을 갖는다면, 많은 경우에
파이썬에서와 같은 방식으로 코드를 작성해 파이썬에서와 동일한 함수와
메서드를 사용할 수 있을 것입니다. (다만, 온점을 더블 콜론으로 바꾸는
것에 유의하세요.)</p>
</div>
</div>
<div class="section" id="id4">
<h2>기본 애플리케이션 작성하기<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>먼저 최소한의 C++ 애플리케이션을 작성해 우리의 설정과
빌드 환경이 동일한지 확인하겠습니다. 먼저, C++
프론트엔드를 사용하는 데 필요한 모든 관련 헤더, 라이브러리 및
CMake 빌드 파일을 패키징하는 <em>LibTorch</em> 배포판의 사본이
필요합니다. 리눅스, 맥OS, 윈도우용 LibTorch 배포판은
<a class="reference external" href="https://pytorch.org/get-started/locally/">PyTorch website</a> 에서
다운로드할 수 있습니다. 이 튜토리얼의 나머지 부분은 기본 우분투 리눅스
환경을 가정하지만 맥OS나 윈도우를 사용하셔도 괜찮습니다.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a class="reference external" href="https://pytorch.org/cppdocs/installing.html">PyTorch C++ 배포판 설치</a>
의 설명에 다음의 과정이 더 자세히 안내되어
있습니다.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>윈도우에서는 디버그 및 릴리스 빌드가 ABI와 호환되지 않습니다. 프로젝트를
디버그 모드로 빌드하려면 LibTorch의 디버그 버전을 사용해보세요.
아래의 <code class="docutils literal notranslate"><span class="pre">cmake</span> <span class="pre">--build</span> <span class="pre">.</span></code> 에 올바른 설정을 지정하는 것도 잊지
마세요.</p>
</div>
<p>가장 먼저 할 것은 PyTorch 웹사이트에서 검색된 링크를 통해 LibTorch
배포판을 로컬에 다운로드하는 것입니다. 일반적 Ubuntu Linux 환경의 경우
다음 명령어를 실행합니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># CUDA 9.0 등에 대한 지원이 필요한 경우 아래 URL에서 &quot;cpu&quot;를 &quot;cu90&quot;로 바꾸세요.</span>
wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip
unzip libtorch-shared-with-deps-latest.zip
</pre></div>
</div>
<p>다음으로 <code class="docutils literal notranslate"><span class="pre">torch/torch.h</span></code> 를 호출하는 <code class="docutils literal notranslate"><span class="pre">dcgan.cpp</span></code> 라는 이름의 C++
파일 하나를 작성합시다. 우선은 아래와 같이 3x3 항등 행렬을 출력하기만 하면
됩니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/torch.h&gt;</span><span class="cp"></span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>이 작은 애플리케이션과 이후 완성할 학습용 스크립트를 빌드하기 위해 우리는 아래의 <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> 를
사용할 것입니다:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.0</span><span class="w"> </span><span class="s">FATAL_ERROR</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">dcgan</span><span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span><span class="s">Torch</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span><span class="s">dcgan</span><span class="w"> </span><span class="s">dcgan.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">dcgan</span><span class="w"> </span><span class="s2">&quot;${TORCH_LIBRARIES}&quot;</span><span class="p">)</span>
<span class="nb">set_property</span><span class="p">(</span><span class="s">TARGET</span><span class="w"> </span><span class="s">dcgan</span><span class="w"> </span><span class="s">PROPERTY</span><span class="w"> </span><span class="s">CXX_STANDARD</span><span class="w"> </span><span class="s">14</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>CMake는 LibTorch에 권장되는 빌드 시스템이지만 필수 요구
사항은 아닙니다. Visual Studio 프로젝트 파일, QMake, 일반
Make 파일 등 다른 빌드 환경을 사용해도 됩니다. 하지만
이에 대한 즉각적인 지원은 제공하지 않습니다.</p>
</div>
<p>위 CMake 파일 4번째 줄의 <code class="docutils literal notranslate"><span class="pre">find_package(Torch</span> <span class="pre">REQUIRED)</span></code> 는
CMake가 LibTorch 라이브러리 빌드 설정을 찾도록 안내합니다.
CMake가 해당 파일의 <em>위치</em> 를 찾을 수 있도록 하려면 <code class="docutils literal notranslate"><span class="pre">cmake</span></code> 호출 시
<code class="docutils literal notranslate"><span class="pre">CMAKE_PREFIX_PATH</span></code> 를 설정해야 합니다. 이에 앞서 <code class="docutils literal notranslate"><span class="pre">dcgan</span></code> 애플리케이션에
대해 디렉터리 구조를 다음과 같이 통일하도록 하겠습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>dcgan/
  CMakeLists.txt
  dcgan.cpp
</pre></div>
</div>
<p>또한 앞으로 압축 해제된 LibTorch 배포판의 경로를 <code class="docutils literal notranslate"><span class="pre">/path/to/libtorch</span></code>
로 부르도록 하겠습니다. 이는 <strong>반드시 절대 경로여야</strong> 합니다. 특히
<code class="docutils literal notranslate"><span class="pre">CMAKE_PREFIX_PATH</span></code> 를 <code class="docutils literal notranslate"><span class="pre">../../libtorch</span></code> 와 같이 설정하면 예상치 못한
오류가 발생할 수 있습니다. 그보다는 <code class="docutils literal notranslate"><span class="pre">$PWD/../../libtorch</span></code> 와 같이 해당
절대 경로를 입력하세요. 이제 애플리케이션을 빌드할 준비가 되었습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home# mkdir build
root@fa350df05ecf:/home# <span class="nb">cd</span> build
root@fa350df05ecf:/home/build# cmake -DCMAKE_PREFIX_PATH<span class="o">=</span>/path/to/libtorch ..
-- The C compiler identification is GNU <span class="m">5</span>.4.0
-- The CXX compiler identification is GNU <span class="m">5</span>.4.0
-- Check <span class="k">for</span> working C compiler: /usr/bin/cc
-- Check <span class="k">for</span> working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - <span class="k">done</span>
-- Detecting C compile features
-- Detecting C compile features - <span class="k">done</span>
-- Check <span class="k">for</span> working CXX compiler: /usr/bin/c++
-- Check <span class="k">for</span> working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - <span class="k">done</span>
-- Detecting CXX compile features
-- Detecting CXX compile features - <span class="k">done</span>
-- Looking <span class="k">for</span> pthread.h
-- Looking <span class="k">for</span> pthread.h - found
-- Looking <span class="k">for</span> pthread_create
-- Looking <span class="k">for</span> pthread_create - not found
-- Looking <span class="k">for</span> pthread_create <span class="k">in</span> pthreads
-- Looking <span class="k">for</span> pthread_create <span class="k">in</span> pthreads - not found
-- Looking <span class="k">for</span> pthread_create <span class="k">in</span> pthread
-- Looking <span class="k">for</span> pthread_create <span class="k">in</span> pthread - found
-- Found Threads: TRUE
-- Found torch: /path/to/libtorch/lib/libtorch.so
-- Configuring <span class="k">done</span>
-- Generating <span class="k">done</span>
-- Build files have been written to: /home/build
root@fa350df05ecf:/home/build# cmake --build . --config Release
Scanning dependencies of target dcgan
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable dcgan
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcgan
</pre></div>
</div>
<p>위에서 우리는 먼저 <code class="docutils literal notranslate"><span class="pre">dcgan</span></code> 디렉토리 안에 <code class="docutils literal notranslate"><span class="pre">build</span></code> 폴더를 만들고
이 폴더에 들어가서 필요한 빌드(Make) 파일을 생성하는 <code class="docutils literal notranslate"><span class="pre">cmake</span></code> 명령어를
실행한 후 <code class="docutils literal notranslate"><span class="pre">cmake</span> <span class="pre">--build</span> <span class="pre">.</span> <span class="pre">--config</span> <span class="pre">Release</span></code> 를 실행하여 프로젝트를
성공적으로 컴파일했습니다. 이제 우리의 작은 바이너리를 실행하고 기본
프로젝트 설정에 대한 이 섹션을 완료할 준비가 됐습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home/build# ./dcgan
<span class="m">1</span>  <span class="m">0</span>  <span class="m">0</span>
<span class="m">0</span>  <span class="m">1</span>  <span class="m">0</span>
<span class="m">0</span>  <span class="m">0</span>  <span class="m">1</span>
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">3</span>,3<span class="o">}</span> <span class="o">]</span>
</pre></div>
</div>
<p>제가 보기엔 항등 행렬인 것 같군요!</p>
</div>
<div class="section" id="id6">
<h2>신경망 모델 정의하기<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>이제 기본적인 환경을 설정했으니, 이번 튜토리얼에서 훨씬
더 흥미로운 부분을 살펴봅시다. 먼저 C++ 프론트엔드에서 모듈을
정의하고 상호 작용하는 방법에 대해 논의하겠습니다. 기본적인
소규모 예제 모듈부터 시작하여 C++ 프론트엔드가 제공하는 다양한
내장 모듈 라이브러리를 사용하여 완성도 있는 GAN을 구현하겠습니다.</p>
<div class="section" id="api">
<h3>모듈 API 기초<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h3>
<p>파이썬 인터페이스와 마찬가지로, C++ 프론트엔드에 기반을 둔 신경망도
<em>모듈</em> 이라 불리는 재사용 가능한 빌딩 블록으로 구성되어 있습니다. 파이썬에
다른 모든 모듈이 파생되는 <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 라는 기본 모듈 클래스가
있듯이 C++에는 <code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code> 클래스가 있습니다.
일반적으로 모듈에는 캡슐화된 알고리즘을 구현하는 <code class="docutils literal notranslate"><span class="pre">forward()</span></code>
메서드를 비롯해 매개변수, 버퍼 및 하위 모듈 세 가지 하위 객체가
포함됩니다.</p>
<p>매개변수와 버퍼는 텐서의 형태로 상태를 저장합니다. 매개변수는 그래디언트를
기록하지만 버퍼는 기록하지 않습니다. 매개변수는 일반적으로 신경망의 학습
가능한 가중치입니다. 버퍼의 예로는 배치 정규화를 위한 평균 및 분산이
있습니다. 특정 논리 및 상태 블록을 재사용하기 위해, PyTorch API는
모듈들이 중첩되는 것을 허용합니다. 중첩된 모듈은 <em>하위 모듈</em> 이라고
합니다.</p>
<p>매개변수, 버퍼 및 하위 모듈은 명시적으로 등록(register)을 해야 합니다.
등록이 되면 <code class="docutils literal notranslate"><span class="pre">parameters()</span></code> 나 <code class="docutils literal notranslate"><span class="pre">buffers()</span></code> 같은 메서드를 사용하여 (중첩을
포함한) 전체 모듈 계층 구조에서 모든 매개변수 묶음을 검색할 수 있습니다.
마찬가지로, <code class="docutils literal notranslate"><span class="pre">to(...)</span></code> 와 같은 메서드는 모듈 계층 구조 전체에 대한 메서드입니다.
예를 들어, <code class="docutils literal notranslate"><span class="pre">to(torch::kCUDA)</span></code> 는 모든 매개변수와 버퍼를 CPU에서 CUDA 메모리로
이동시킵니다.</p>
<div class="section" id="id7">
<h4>모듈 정의 및 매개변수 등록<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>이 내용을 코드로 구현하기 위해, 파이썬 인터페이스로 작성된 간단한 모듈 하나를
생각해 봅시다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">M</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
</pre></div>
</div>
<p>이를 C++로 작성하면 다음과 같습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/torch.h&gt;</span><span class="cp"></span>

<span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">M</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_parameter</span><span class="p">(</span><span class="s">&quot;W&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">M</span><span class="p">}));</span><span class="w"></span>
<span class="w">    </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_parameter</span><span class="p">(</span><span class="s">&quot;b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">(</span><span class="n">M</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">addmm</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="n">W</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">W</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p>파이썬에서와 마찬가지로 모듈 기본 클래스에서 파생한 <code class="docutils literal notranslate"><span class="pre">Net</span></code> 이라는 클래스를
정의합니다. (쉬운 설명을 위해 <code class="docutils literal notranslate"><span class="pre">class</span></code> 대신 <code class="docutils literal notranslate"><span class="pre">struct</span></code> 을 사용했습니다.)
파이썬에서 torch.randn을 사용하는 것처럼 생성자에서는 <code class="docutils literal notranslate"><span class="pre">torch::randn</span></code> 을
사용해 텐서를 만듭니다. 한 가지 흥미로운 차이점은 매개변수를 등록하는
방법입니다. 파이썬에서는 텐서를 <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> 으로 감싸는 것과 달리,
C++에서는 <code class="docutils literal notranslate"><span class="pre">register_parameter</span></code> 메서드를 통해 텐서를 전달해야
합니다. 이러한 차이의 원인은 파이썬 API의 경우, 어떤 속성(attirbute)이
<code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code> 타입인지 감지해 그러한 텐서를 자동으로 등록할 수 있기
때문에 나타납니다. C++에서는 리플렉션(reflection)이 매우 제한적이므로 보다
전통적인 (그리하여 덜 마법적인) 방식이 제공됩니다.</p>
</div>
<div class="section" id="id8">
<h4>서브모듈 등록 및 모듈 계층 구조 탐색<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>매개변수 등록과 마찬가지 방법으로 서브모듈을 등록할 수 있습니다.
파이썬에서 서브모듈은 어떤 모듈의 속성으로 지정될 때 자동으로
감지되고 등록됩니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="c1"># Registered as a submodule behind the scenes</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">another_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">M</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">another_bias</span>
</pre></div>
</div>
<p>예를 들어, <code class="docutils literal notranslate"><span class="pre">parameters()</span></code> 메서드를 사용하면 모듈 계층의 모든 매개변수에
재귀적으로 액세스할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<span class="go">[Parameter containing:</span>
<span class="go">tensor([0.0808, 0.8613, 0.2017, 0.5206, 0.5353], requires_grad=True), Parameter containing:</span>
<span class="go">tensor([[-0.3740, -0.0976, -0.4786, -0.4928],</span>
<span class="go">        [-0.1434,  0.4713,  0.1735, -0.3293],</span>
<span class="go">        [-0.3467, -0.3858,  0.1980,  0.1986],</span>
<span class="go">        [-0.1975,  0.4278, -0.1831, -0.2709],</span>
<span class="go">        [ 0.3730,  0.4307,  0.3236, -0.0629]], requires_grad=True), Parameter containing:</span>
<span class="go">tensor([ 0.2038,  0.4638, -0.2023,  0.1230, -0.0516], requires_grad=True)]</span>
</pre></div>
</div>
<p>C++에서 <code class="docutils literal notranslate"><span class="pre">torch::nn::Linear</span></code> 등의 모듈을 서브모듈로 등록하려면 이름에서
유추할 수 있듯이 <code class="docutils literal notranslate"><span class="pre">register_module()</span></code> 메서드를 사용합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">M</span><span class="p">)</span><span class="w"></span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">linear</span><span class="p">(</span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">M</span><span class="p">)))</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">another_bias</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_parameter</span><span class="p">(</span><span class="s">&quot;b&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">(</span><span class="n">M</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">linear</span><span class="p">(</span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">another_bias</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="w"> </span><span class="n">linear</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">another_bias</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><code class="docutils literal notranslate"><span class="pre">torch::nn</span></code> 에 대한 <a class="reference external" href="https://pytorch.org/cppdocs/api/namespace_torch__nn.html">이 문서</a>
에서 <code class="docutils literal notranslate"><span class="pre">torch::nn::Linear</span></code>, <code class="docutils literal notranslate"><span class="pre">torch::nn::Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">torch::nn::Conv2d</span></code>
등 사용 가능한 전체 빌트인 모듈 목록을 확인할 수
있습니다.</p>
</div>
<p>위 코드에서 한 가지 미묘한 사실은 서브모듈은 생성자의 이니셜라이저
목록에 작성되고 매개변수는 생성자의 바디(body)에 작성되었다는
것입니다. 여기에는 충분한 이유가 있으며 아래 C++ 프론트엔드의
<em>오너십 모델</em> 섹션에서 더 다룰 예정입니다. 그렇지만 최종 결론은
파이썬에서처럼 모듈 트리의 매개변수에 재귀적으로 액세스할 수
있다는 것입니다. <code class="docutils literal notranslate"><span class="pre">parameters()</span></code> 를 호출하면 순회가 가능한
<code class="docutils literal notranslate"><span class="pre">std::vector&lt;torch::Tensor&gt;</span></code> 가 반환됩니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>이를 실행한 결과는 다음과 같습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home/build# ./dcgan
<span class="m">0</span>.0345
<span class="m">1</span>.4456
-0.6313
-0.3585
-0.4008
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span><span class="o">}</span> <span class="o">]</span>
-0.1647  <span class="m">0</span>.2891  <span class="m">0</span>.0527 -0.0354
<span class="m">0</span>.3084  <span class="m">0</span>.2025  <span class="m">0</span>.0343  <span class="m">0</span>.1824
-0.4630 -0.2862  <span class="m">0</span>.2500 -0.0420
<span class="m">0</span>.3679 -0.1482 -0.0460  <span class="m">0</span>.1967
<span class="m">0</span>.2132 -0.1992  <span class="m">0</span>.4257  <span class="m">0</span>.0739
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span>,4<span class="o">}</span> <span class="o">]</span>
<span class="m">0</span>.01 *
<span class="m">3</span>.6861
-10.1166
-45.0333
<span class="m">7</span>.9983
-20.0705
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span><span class="o">}</span> <span class="o">]</span>
</pre></div>
</div>
<p>파이썬에서와 같이 세 개의 매개변수가 출력됐습니다. 이 매개변수들의 이름을
확인할 수 있도록 C++ API는 <code class="docutils literal notranslate"><span class="pre">named_parameters()</span></code> 메서드를 제공하며, 이는
파이썬에서와 같이 <code class="docutils literal notranslate"><span class="pre">Orderdict</span></code> 를 반환합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Net</span><span class="w"> </span><span class="nf">net</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">pair</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">named_parameters</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">pair</span><span class="p">.</span><span class="n">key</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">pair</span><span class="p">.</span><span class="n">value</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>마찬가지로 코드를 실행하면 결과는 아래와 같습니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home/build# make <span class="o">&amp;&amp;</span> ./dcgan                                                                                                                                            <span class="m">11</span>:13:48
Scanning dependencies of target dcgan
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable dcgan
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcgan
b: -0.1863
-0.8611
-0.1228
<span class="m">1</span>.3269
<span class="m">0</span>.9858
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span><span class="o">}</span> <span class="o">]</span>
linear.weight:  <span class="m">0</span>.0339  <span class="m">0</span>.2484  <span class="m">0</span>.2035 -0.2103
-0.0715 -0.2975 -0.4350 -0.1878
-0.3616  <span class="m">0</span>.1050 -0.4982  <span class="m">0</span>.0335
-0.1605  <span class="m">0</span>.4963  <span class="m">0</span>.4099 -0.2883
<span class="m">0</span>.1818 -0.3447 -0.1501 -0.0215
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span>,4<span class="o">}</span> <span class="o">]</span>
linear.bias: -0.0250
<span class="m">0</span>.0408
<span class="m">0</span>.3756
-0.2149
-0.3636
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">5</span><span class="o">}</span> <span class="o">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code> 에 대한 <a class="reference external" href="https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_module.html#exhale-class-classtorch-1-1nn-1-1-module">문서</a> 는
모듈 계층 구조에 대한 메서드 목록 전체가 포함되어
있습니다.</p>
</div>
</div>
<div class="section" id="forward">
<h4>순전파(forward) 모드로 네트워크 실행<a class="headerlink" href="#forward" title="Permalink to this headline">¶</a></h4>
<p>네트워크를 C++로 실행하기 위해서는, 우리가 정의한 <code class="docutils literal notranslate"><span class="pre">forward()</span></code> 메서드를
호출하기만 하면 됩니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">ones</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">}))</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>출력은 대략 아래와 같을 것입니다</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home/build# ./dcgan
<span class="m">0</span>.8559  <span class="m">1</span>.1572  <span class="m">2</span>.1069 -0.1247  <span class="m">0</span>.8060
<span class="m">0</span>.8559  <span class="m">1</span>.1572  <span class="m">2</span>.1069 -0.1247  <span class="m">0</span>.8060
<span class="o">[</span> Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">2</span>,5<span class="o">}</span> <span class="o">]</span>
</pre></div>
</div>
</div>
<div class="section" id="ownership">
<h4>모듈 오너십 (Ownership)<a class="headerlink" href="#ownership" title="Permalink to this headline">¶</a></h4>
<p>이제 우리는 C++에서 모듈을 정의하고, 매개변수를 등록하고, 하위 모듈을
등록하고, <code class="docutils literal notranslate"><span class="pre">parameters()</span></code> 등의 메서드를 통해 모듈 계층을 탐색하고,
모듈의 <code class="docutils literal notranslate"><span class="pre">forward()</span></code> 메서드를 실행하는 방법을 배웠습니다. C++ API에는
다른 메서드, 클래스, 그리고 주제가 많지만 전체 목록은 <a class="reference external" href="https://pytorch.org/cppdocs/api/namespace_torch__nn.html">문서</a> 를
참조하시기 바랍니다. 잠시 후에 DCGAN 모델과 엔드 투 엔드 학습
파이프라인을 구현하면서도 몇 가지 개념을 더 다룰 예정입니다. 그에 앞서
C++ 프론트엔드에서 <code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code> 의 하위 클래스들에 대해 제공하는
<em>오너십 모델</em> 에 대해 간단히 설명하겠습니다.</p>
<p>이 논의에서 오너십 모델이란 모듈을 저장하고 전달하는 방식
(누가 혹은 무엇이 특정 모듈 인스턴스를 소유하는지)을 지칭합니다.
파이썬에서 객체는 항상 힙에 동적으로 할당되며 레퍼런스 시맨틱을
가지는데, 이는 다루고 이해하기가 매우 쉽습니다. 실제로 파이썬에서는
객체가 어디에 존재하고 어떻게 레퍼런스되는지 신경 쓰지 않고 하려는
일에만 집중할 수 있습니다.</p>
<p>저급 언어인 C++는 이 부분에서 더 많은 옵션을 제공합니다. 이는
C++ 프론트엔드의 복잡성을 증가시키며 그 설계와 인체공학적 요소에도
큰 영향을 줍니다. 특히, C++ 프론트엔드 모듈에서는 밸류 시맨틱
<em>또는</em> 레퍼런스 시맨틱을 사용할 수 있습니다. 전자가 지금까지의
사례에서 살펴본 가장 단순한 경우로, 모듈 객체가 스택에 할당되고
함수에 전달될 때 레퍼런스 혹은 포인터로 복사 및 이동(<code class="docutils literal notranslate"><span class="pre">std:move</span></code>)
시키거나 가져올 수 있습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">};</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">a</span><span class="p">(</span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="kt">void</span><span class="w"> </span><span class="nf">b</span><span class="p">(</span><span class="n">Net</span><span class="o">&amp;</span><span class="w"> </span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="kt">void</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">Net</span><span class="o">*</span><span class="w"> </span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">a</span><span class="p">(</span><span class="n">net</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">a</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">net</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="n">b</span><span class="p">(</span><span class="n">net</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">c</span><span class="p">(</span><span class="o">&amp;</span><span class="n">net</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>후자(레퍼런스 시맨틱)의 경우, <code class="docutils literal notranslate"><span class="pre">std::shared_ptr</span></code> 를 사용할 수 있습니다.
모든 곳에서 <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> 를 사용한다는 가정 하에, 레퍼런스 시맨틱의
장점은 파이썬에서와 같이 모듈이 함수에 전달되고 인자가 선언되는 방식에
대해 생각할 부담을 덜어준다는 것입니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{};</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">a</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Net</span><span class="o">&gt;</span><span class="w"> </span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">net</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">Net</span><span class="o">&gt;</span><span class="p">();</span><span class="w"></span>
<span class="w">  </span><span class="n">a</span><span class="p">(</span><span class="n">net</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>경험적으로, 동적 언어를 사용하던 연구자들은 비록 밸류 시맨틱이
더 C++에 “네이티브”함에도 불구하고 레퍼런스 시맨틱을 훨씬
선호합니다. 또한 <code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code> 의 설계는
사용자 친화적인 파이썬 API를 유사하게 따르기 위해 shared 오너십에
의존합니다. 앞서 예시로 들었던 <code class="docutils literal notranslate"><span class="pre">Net</span></code> 의 정의를 축약해서 다시
살펴봅시다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">M</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="n">linear</span><span class="p">(</span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">M</span><span class="p">)))</span><span class="w"></span>
<span class="w">  </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="w"> </span><span class="n">linear</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p>하위 모듈인 <code class="docutils literal notranslate"><span class="pre">linear</span></code> 를 사용하기 위해 이를 클래스에 직접 저장하고자
합니다. 그러나 동시에 모듈의 기초 클래스가 이 하위 모듈에 대해 알고 접근할
수 있기를 원합니다. 이를 위해서는 해당 하위 모듈에 대한 참조를 저장해야 합니다.
이 순간 이미 우리는 shared 오너십을 필요로 합니다. <code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code>
클래스와 구상 클래스인 <code class="docutils literal notranslate"><span class="pre">Net</span></code> 모두에서 하위 모듈에 대한 레퍼런스가
필요합니다. 따라서 기초 클래스는 모듈을 <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> 로 저장하며 이에
따라 구상 클래스 또한 마찬가지일 것입니다.</p>
<p>하지만 잠깐! 위의 코드에는 <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> 에 대한 언급이 없습니다! 왜 그런
것일까요? 왜냐하면 <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;MyModule&gt;</span></code> 는 타이핑하기에 너무 길기 때문입니다.
연구원들의 생산성을 유지하기 위해, 우리는 레퍼런스 시맨틱을 유지하면서 밸류
시맨틱만의 장점인 <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> 에 대한 언급을 숨기기 위한 정교한 계획을
세웠습니다. 그 작동 방식을 이해하기 위해 코어 라이브러리에 있는 <code class="docutils literal notranslate"><span class="pre">torch::nn::Linear</span></code>
모듈의 단순화된 정의를 살펴보겠습니다. (전체 정의는
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/nn/modules/linear.h">여기</a> 에서
확인할 수 있습니다.)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">LinearImpl</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">LinearImpl</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">out</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">input</span><span class="p">);</span><span class="w"></span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="n">bias</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>

<span class="n">TORCH_MODULE</span><span class="p">(</span><span class="n">Linear</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>요약하자면 이 모듈은 <code class="docutils literal notranslate"><span class="pre">Linear</span></code> 가 아닌 <code class="docutils literal notranslate"><span class="pre">LinearImpl</span></code> 이라고 불립니다. 그리고
<code class="docutils literal notranslate"><span class="pre">TORCH_MODULE</span></code> 라는 매크로가 실제 <code class="docutils literal notranslate"><span class="pre">Linear</span></code> 클래스를 정의합니다. 이렇게 “생성된”
클래스는 <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;LinearImpl&gt;</span></code> 를 감싸는 래퍼(wrapper)입니다.
단순한 typedef가 아닌 래퍼이므로 생성자도 여전히 예상하는 대로 작동합니다.
즉, <code class="docutils literal notranslate"><span class="pre">std::make_shared&lt;LinearImpl&gt;(3,</span> <span class="pre">4)</span></code> 가 아닌 <code class="docutils literal notranslate"><span class="pre">torch::nn::Linear(3,</span> <span class="pre">4)</span></code>
라고 쓸 수 있습니다. 이렇게 매크로에 의해 생성된 클래스는 <em>holder</em> 모듈이라고
부릅니다. (shared) 포인터와 마찬가지로 화살표 연산자(즉,
<code class="docutils literal notranslate"><span class="pre">model-&gt;forward(...)</span></code>)를 사용해 기저 객체에 액세스합니다.
결론적으로 파이썬 API와 매우 유사한 오너십 모델을 얻었습니다.
기본적으로 레퍼런스 시맨틱을 따르지만, <code class="docutils literal notranslate"><span class="pre">std:shared_ptr</span></code> 나
<code class="docutils literal notranslate"><span class="pre">std::make_shared</span></code> 등을 타이핑할 필요가 없습니다. 우리의 <code class="docutils literal notranslate"><span class="pre">Net</span></code> 예시에서
모듈 holder API를 사용하면 아래와 같습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">NetImpl</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{};</span><span class="w"></span>
<span class="n">TORCH_MODULE</span><span class="p">(</span><span class="n">Net</span><span class="p">);</span><span class="w"></span>

<span class="kt">void</span><span class="w"> </span><span class="nf">a</span><span class="p">(</span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="w"> </span><span class="n">net</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">a</span><span class="p">(</span><span class="n">net</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>여기서 언급할 만한 미묘한 문제가 하나 있습니다. 기본 생성자에 의해 만들어진
<code class="docutils literal notranslate"><span class="pre">std::shared_ptr</span></code> 는 “비어” 있습니다. 즉, null 포인터입니다. 기본 생성자로
만들어진 <code class="docutils literal notranslate"><span class="pre">Linear</span></code> 이나 <code class="docutils literal notranslate"><span class="pre">Net</span></code> 은 무엇이어야 할까요? 음, 이건 어려운 결정입니다.
빈 (null) <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;LinearImpl&gt;</span></code> 로 정할 수 있습니다. 하지만
<code class="docutils literal notranslate"><span class="pre">Linear(3,</span> <span class="pre">4)</span></code> 가 <code class="docutils literal notranslate"><span class="pre">std::make_shared&lt;LinearImpl&gt;(3,</span> <span class="pre">4)</span></code> 와 같다는 것을 기억합시다.
즉, <code class="docutils literal notranslate"><span class="pre">Linear</span> <span class="pre">linear;</span></code> 이 null 포인터여야 한다고 결정한다면
생성자에서 인자를 전혀 받지 않거나 모든 인자에 대해 기본값을 사용하는
모듈을 생성할 방법이 없어집니다. 이러한 이유로 현재
API에서 기본 생성자에 의해 만들어진 모듈 holder(<code class="docutils literal notranslate"><span class="pre">Linear()</span></code> 등)는
기저 모듈(<code class="docutils literal notranslate"><span class="pre">LinearImpl()</span></code>)의 기본 생성자를 호출합니다. 만약
기저 모듈에 기본 생성자가 없으면 컴파일러 오류가 발생합니다.
반대로 빈 holder를 생성하려면 holder 생성자에 <code class="docutils literal notranslate"><span class="pre">nullptr</span></code> 를
전달하면 됩니다.</p>
<p>실제로는 앞에서와 같이 하위 모듈을 사용해 모듈을 <em>이니셜라이저 (initializer) 목록</em> 에
등록 및 생성하거나,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">M</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="n">linear</span><span class="p">(</span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">M</span><span class="p">)))</span><span class="w"></span>
<span class="w">  </span><span class="p">{</span><span class="w"> </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="w"> </span><span class="n">linear</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p>파이썬 사용자들에게 더 친숙한 방법으로, 먼저 null 포인터로 홀더를 생성한 이후
생성자에서 값을 지정할 수 있습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">Net</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">Net</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">M</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">linear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">M</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="w"> </span><span class="n">linear</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span><span class="w"> </span><span class="c1">// construct an empty holder</span>
<span class="p">};</span><span class="w"></span>
</pre></div>
</div>
<p>결론적으로 어떤 오너십 모델, 어떤 시맨틱을 사용하면 좋을까요? C++
프론트엔드 API는 모듈 holder가 제공하는 오너십 모델을 가장 잘 지원합니다.
이 메커니즘의 유일한 단점은 모듈 선언 아래에 boilerplate 한 줄이
추가된다는 것입니다. 즉, 가장 단순한 모델은 C++ 모듈의 기초를 배울 떄
나오는 밸류 시맨틱 모델입니다. 작고 간단한 스크립트의 경우,
이것만으로 충분할 수 있습니다. 그러나 언젠가는 기술적 이유로 인해
이 기능이 항상 지원되지는 않는다는 사실을 알게 될 것입니다. 예를 들어 직렬화
API(<code class="docutils literal notranslate"><span class="pre">torch::save</span></code> 및 <code class="docutils literal notranslate"><span class="pre">torch::load</span></code>)는 모듈 holder(혹은 일반
<code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code>)만을 지원합니다. 따라서 C++ 프론트엔드로 모듈을
정의할 떄에는 모듈 holder API 방식이 권장되며, 앞으로 본 튜토리얼에서
이 API를 사용하겠습니다.</p>
</div>
</div>
<div class="section" id="id13">
<h3>DCGAN 모듈 정의하기<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>이제 이 글에서 해결하려는 머신러닝 태스크를 위한 모듈을 정의하는데
필요한 배경과 도입부 설명이 끝났습니다. 다시 상기하자면, 우리의 태스크는
<a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST 데이터셋</a> 의 숫자 이미지를
생성하는 것입니다. 우리는 이 태스크를 풀기 위해
<a class="reference external" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">적대적 생성 신경망(GAN)</a> 을
사용하고자 합니다. 그 중에서도 우리는 <a class="reference external" href="https://arxiv.org/abs/1511.06434">DCGAN 아키텍처</a> 를 사용할 것입니다.
DCGAN은 가장 초기에 발표됐던 제일 간단한 GAN이지만 이 태스크를 위해서는
충분합니다.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>이 튜토리얼에 나온 소스 코드 전체는 <a class="reference external" href="https://github.com/pytorch/examples/tree/master/cpp/dcgan">이 저장소</a> 에서 확인할 수 있습니다.</p>
</div>
<div class="section" id="id16">
<h4>GAN이 뭐였죠?<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h4>
<p>GAN은 <em>생성기(generator)</em> 와 <em>판별기(discriminator)</em> 라는
두 가지 신경망 모델로 구성됩니다. 생성기는 노이즈 분포에서 샘플을 입력받고,
각 노이즈 샘플을 목표 분포(이 경우 MNIST 데이터셋)와 유사한 이미지로
변환하는 것이 목표입니다. 판별기는 MNIST 데이터셋의 <em>진짜</em>
이미지를 입력받거나 생성기로부터 <em>가짜</em> 이미지를 입력받습니다.
그리고 어떤 이미지가 얼마나 진짜같은지 (<code class="docutils literal notranslate"><span class="pre">1</span></code> 에 가까운 출력)
혹은 가짜같은 지 (<code class="docutils literal notranslate"><span class="pre">0</span></code> 에 가까운 출력) 판별합니다. 생성기가
만든 이미지가 얼마나 진짜같은 지 판별기가 피드백하고 이 피드백은 생성기
학습에 사용됩니다. 판별기가 진짜에 대한 안목이 얼마나 좋은 지에
대한 피드백은 판별기를 최적화하기 위해 사용됩니다. 이론적으로,
생성기와 판별기 사이의 섬세한 균형은 이 둘을 동시에 개선시킵니다.
이를 통해 생성기는 목표 분포와 구별할 수 없는 이미지를 생성하고,
(그때쯤이면) 잘 학습되어 있을 판별기의 안목을 속여 진짜와 가짜
이미지 모두에 대해 <code class="docutils literal notranslate"><span class="pre">0.5</span></code> 의 확률을 출력할 것입니다. 최종
결과물은 노이즈를 입력받아 실제 숫자의 이미지를 출력으로 생성하는
기계입니다.</p>
</div>
<div class="section" id="generator">
<h4>생성기 (Generator) 모듈<a class="headerlink" href="#generator" title="Permalink to this headline">¶</a></h4>
<p>먼저 일련의 전치된 (transposed) 2D 합성곱, 배치 정규화 및
ReLU 활성화 유닛으로 구성된 생성기 모듈을 정의하겠습니다.
모듈의 <code class="docutils literal notranslate"><span class="pre">forward()</span></code> 메서드를 직접 정의하여 모듈 간 입력을
(함수형으로) 명시적으로 전달합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="nc">DCGANGeneratorImpl</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">DCGANGeneratorImpl</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">kNoiseSize</span><span class="p">)</span><span class="w"></span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">conv1</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">ConvTranspose2dOptions</span><span class="p">(</span><span class="n">kNoiseSize</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">        </span><span class="n">batch_norm1</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span><span class="w"></span>
<span class="w">        </span><span class="n">conv2</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">ConvTranspose2dOptions</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">        </span><span class="n">batch_norm2</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span><span class="w"></span>
<span class="w">        </span><span class="n">conv3</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">ConvTranspose2dOptions</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">        </span><span class="n">batch_norm3</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span><span class="w"></span>
<span class="w">        </span><span class="n">conv4</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">ConvTranspose2dOptions</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>
<span class="w">                  </span><span class="p">.</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">))</span><span class="w"></span>
<span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">   </span><span class="c1">// register_module() is needed if we want to use the parameters() method later on</span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;conv1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">conv1</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;conv2&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">conv2</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;conv3&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">conv3</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;conv4&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">conv4</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;batch_norm1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">batch_norm1</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;batch_norm2&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">batch_norm2</span><span class="p">);</span><span class="w"></span>
<span class="w">   </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;batch_norm3&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">batch_norm3</span><span class="p">);</span><span class="w"></span>
<span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">relu</span><span class="p">(</span><span class="n">batch_norm1</span><span class="p">(</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)));</span><span class="w"></span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">relu</span><span class="p">(</span><span class="n">batch_norm2</span><span class="p">(</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)));</span><span class="w"></span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">relu</span><span class="p">(</span><span class="n">batch_norm3</span><span class="p">(</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)));</span><span class="w"></span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">tanh</span><span class="p">(</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">));</span><span class="w"></span>
<span class="w">   </span><span class="k">return</span><span class="w"> </span><span class="n">x</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="p">}</span><span class="w"></span>

<span class="w"> </span><span class="n">nn</span><span class="o">::</span><span class="n">ConvTranspose2d</span><span class="w"> </span><span class="n">conv1</span><span class="p">,</span><span class="w"> </span><span class="n">conv2</span><span class="p">,</span><span class="w"> </span><span class="n">conv3</span><span class="p">,</span><span class="w"> </span><span class="n">conv4</span><span class="p">;</span><span class="w"></span>
<span class="w"> </span><span class="n">nn</span><span class="o">::</span><span class="n">BatchNorm2d</span><span class="w"> </span><span class="n">batch_norm1</span><span class="p">,</span><span class="w"> </span><span class="n">batch_norm2</span><span class="p">,</span><span class="w"> </span><span class="n">batch_norm3</span><span class="p">;</span><span class="w"></span>
<span class="p">};</span><span class="w"></span>
<span class="n">TORCH_MODULE</span><span class="p">(</span><span class="n">DCGANGenerator</span><span class="p">);</span><span class="w"></span>

<span class="n">DCGANGenerator</span><span class="w"> </span><span class="nf">generator</span><span class="p">(</span><span class="n">kNoiseSize</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>이제 <code class="docutils literal notranslate"><span class="pre">DCGANGenerator</span></code> 의 <code class="docutils literal notranslate"><span class="pre">forward()</span></code> 를 호출해 노이즈 샘플을 이미지에 매핑할 수 있습니다.</p>
<p>여기서 사용한 <code class="docutils literal notranslate"><span class="pre">nn::ConvTranspose2d</span></code> 및 <code class="docutils literal notranslate"><span class="pre">nn::BatchNorm2d</span></code> 등의 모듈은
앞서 설명한 구조를 따릅니다. 상수 <code class="docutils literal notranslate"><span class="pre">kNoiseSize</span></code> 는 입력 노이즈 벡터의 크기를
결정하며 <code class="docutils literal notranslate"><span class="pre">100</span></code> 으로 설정됩니다. 하이퍼파라미터는 물론 대학원생들의 많은 노력을
통해 세팅됐습니다.</p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>하이퍼파라미터를 정하느라 다친 대학원생은 없었습니다. 그들은 서로서로 개사료를 먹이니까요.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>C++ 프론트엔드의 <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> 와 같은 기본 제공 모듈에 옵션이 전달되는 방법에 대한
간단히 설명하자면, 모든 모듈은 몇 가지 필수 옵션을 갖고 있습니다. (예: <code class="docutils literal notranslate"><span class="pre">BatchNorm2d</span></code> 의
feature 개수) 만약 <code class="docutils literal notranslate"><span class="pre">BatchNorm2d(128)</span></code>, <code class="docutils literal notranslate"><span class="pre">Dropout(0.5)</span></code>, <code class="docutils literal notranslate"><span class="pre">Conv2d(8,</span> <span class="pre">4,</span> <span class="pre">2)</span></code> 와
같이 필수 옵션만 설정하려 한다면 모듈 생성자에 직접 전달할 수 있습니다.
(여기서는 각각 입력 채널 수, 출력 채널 수 및 커널 크기를 의미)
그러나 만약 <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> 의 <code class="docutils literal notranslate"><span class="pre">bias</span></code> 와 같이 일반적으로 기본값을 사용하는
다른 옵션을 수정해야 하는 경우, <em>options</em> 객체를 생성해 전달해야 합니다.
C++ 프론트엔드의  모듈은 <code class="docutils literal notranslate"><span class="pre">ModuleOptions</span></code> 이라고 하는 연관된 옵션 struct를
가지고 있습니다. 여기서 <code class="docutils literal notranslate"><span class="pre">Module</span></code> 은 해당 모듈의 이름으로, 예를 들어 <code class="docutils literal notranslate"><span class="pre">Linear</span></code>
의 경우 <code class="docutils literal notranslate"><span class="pre">LinearOptions</span></code> 와 같습니다. 우리는 위의 <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> 모듈에
대해 이를 수행한 것입니다.</p>
</div>
</div>
<div class="section" id="discriminator">
<h4>판별기(Discriminator) 모듈<a class="headerlink" href="#discriminator" title="Permalink to this headline">¶</a></h4>
<p>판별기는 마찬가지로 합성곱, 배치 정규화 및 활성화의
연속입니다. 하지만 이번에 합성곱은 전치되지 않은 기본
합성곱이며, 일반적 ReLU 대신에 알파 값이 0.2인 leaky ReLU를
사용합니다. 또한 최종 활성화는 값을 0과 1 사이의 범위로 압축하는
Sigmoid가 됩니다. 그런 다음 이렇게 압축된 값을 판별자가
이미지에 대해 출력하는 확률로 해석할 수 있습니다.</p>
<p>판별기를 만들기 위해 <cite>Sequential</cite> 모듈이라는 다른 것을 시도해 보겠습니다.
파이썬에서와 같이, PyTorch는 모델 정의를 위해 두 가지 API를 제공합니다.
(생성기 모듈 예시와 같이) 입력이 연속적인 함수를 통해 전달되는 함수형 API와
전체 모델을 하위 모듈로 포함하는 <cite>Sequential</cite> 모듈을 생성하는 객체 지향형
API입니다. <cite>Sequential</cite> 을 사용하면 판별기는 대략 다음과 같습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">::</span><span class="n">Sequential</span><span class="w"> </span><span class="nf">discriminator</span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="c1">// Layer 1</span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2d</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2dOptions</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">).</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLUOptions</span><span class="p">().</span><span class="n">negative_slope</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="c1">// Layer 2</span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2d</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2dOptions</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">).</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLUOptions</span><span class="p">().</span><span class="n">negative_slope</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="c1">// Layer 3</span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2d</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2dOptions</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">).</span><span class="n">stride</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="n">padding</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">LeakyReLUOptions</span><span class="p">().</span><span class="n">negative_slope</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="c1">// Layer 4</span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2d</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">nn</span><span class="o">::</span><span class="n">Conv2dOptions</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">).</span><span class="n">stride</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">padding</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">bias</span><span class="p">(</span><span class="nb">false</span><span class="p">)),</span><span class="w"></span>
<span class="w">  </span><span class="n">nn</span><span class="o">::</span><span class="n">Sigmoid</span><span class="p">());</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모듈은 단순한 함수 합성만을 수행합니다. 첫 번째 하위 모듈의 출력은
두 번째 하위 모듈의 입력이 되고 세 번째 하위 모듈의 출력은 네 번째 하위 모듈의 입력이
되고 이후에도 마찬가지입니다.</p>
</div>
</div>
</div>
</div>
<div class="section" id="id17">
<h2>데이터 불러오기<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<p>이제 생성기와 판별기 모델을 정의했으므로 이러한 모델을 학습시킬
데이터가 필요합니다. 파이썬과 마찬가지로 C++ 프론트엔드는
강력한 병렬 데이터 로더(data loader)를 제공한다. 이 데이터 로더는
사용자가 직접 정의할 수 있는 데이터셋에서 데이터 배치를 읽을 수 있으며
설정을 위한 많은 옵션을 제공합니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>파이썬 데이터 로더가 멀티 프로세싱을 사용하는 반면, C++ 데이터 로더는 실제로 멀티 스레딩을 사용해 어떠한 새로운 프로세스도 시작하지 않습니다.</p>
</div>
<p>데이터 로더는 <code class="docutils literal notranslate"><span class="pre">torch::data::</span></code> 네임스페이스에 포함된 C++ 프론트엔드의
<code class="docutils literal notranslate"><span class="pre">data</span></code> API의 일부입니다. 이 API는 다음과 같은 몇 가지 컴포넌트로 구성됩니다.</p>
<ul class="simple">
<li><p>데이터 로더 클래스</p></li>
<li><p>데이터셋을 정의하기 위한 API</p></li>
<li><p><em>변환</em> 을 정의하기 위한 API (데이터셋에 적용 가능)</p></li>
<li><p><em>샘플러</em> 를 정의하기 위한 API (데이터셋을 위한 인덱스를 생성)</p></li>
<li><p>기존 데이터셋, 변환, 샘플러들의 라이브러리</p></li>
</ul>
<p>이 튜토리얼에서는 C++ 프론트엔드와 함께 제공되는 <code class="docutils literal notranslate"><span class="pre">MNIST</span></code> 데이터셋을
사용합니다. <code class="docutils literal notranslate"><span class="pre">torch::data::datasets::MNIST</span></code> 인스턴스를 만들어
다음 두 가지 변환을 적용해봅시다. 첫째, 이미지를 정규화하여 <code class="docutils literal notranslate"><span class="pre">-1</span></code> 과
<code class="docutils literal notranslate"><span class="pre">+1</span></code> 사이에 있도록 합니다. (기존 범위는 <code class="docutils literal notranslate"><span class="pre">0</span></code> 과 <code class="docutils literal notranslate"><span class="pre">1</span></code> 사이)
둘째, 텐서 배치(batch)를 첫 번째 차원을 따라 단일 텐서로 쌓는 이른바
<code class="docutils literal notranslate"><span class="pre">Stack</span></code> <em>collation</em> 을 적용합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">datasets</span><span class="o">::</span><span class="n">MNIST</span><span class="p">(</span><span class="s">&quot;./mnist&quot;</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="p">.</span><span class="n">map</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">transforms</span><span class="o">::</span><span class="n">Normalize</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5</span><span class="p">))</span><span class="w"></span>
<span class="w">    </span><span class="p">.</span><span class="n">map</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">transforms</span><span class="o">::</span><span class="n">Stack</span><span class="o">&lt;&gt;</span><span class="p">());</span><span class="w"></span>
</pre></div>
</div>
<p>MNIST 데이터셋은 학습 바이너리 실행 위치를 기준으로 <code class="docutils literal notranslate"><span class="pre">./mnist</span></code>
디렉토리에 위치해야 합니다. MNIST 데이터셋은 <a class="reference external" href="https://gist.github.com/goldsborough/6dd52a5e01ed73a642c1e772084bcd03">이 스크립트</a> 를
사용해 다운로드할 수 있습니다.</p>
<p>다음으로, 데이터 로더를 만들고 이 데이터셋을 전달합니다. 새로운 데이터
로더를 만들기 위해 <code class="docutils literal notranslate"><span class="pre">torch::data::make_data_loader</span></code> 를 사용합니다.
이 로더는 올바른 타입(데이터셋 타입, 샘플러 타입 및 기타 구현 세부사항에
따라 결정됨)의 <code class="docutils literal notranslate"><span class="pre">std::unique_ptr</span></code> 를 반환합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">data_loader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">make_data_loader</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">dataset</span><span class="p">));</span><span class="w"></span>
</pre></div>
</div>
<p>데이터 로더에는 많은 옵션이 제공됩니다. 전체 목록은 <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/data/dataloader_options.h">여기</a>
에서 확인할 수 있습니다.
예를 들어 데이터 로딩 속도를 높이기 위해 작업자 수를 늘릴 수
있습니다. 기본값은 0이며, 이는 주 쓰레드가 사용됨을 의미합니다.
<code class="docutils literal notranslate"><span class="pre">workers</span></code> 를 <code class="docutils literal notranslate"><span class="pre">2</span></code> 로 설정하면 데이터를 동시에 로드하는 쓰레드가
두 개 생성됩니다. 또한 배치 크기를 기본값 <code class="docutils literal notranslate"><span class="pre">1</span></code> 에서 <code class="docutils literal notranslate"><span class="pre">64</span></code> (<code class="docutils literal notranslate"><span class="pre">kBatchSize</span></code> 값)
와 같이 더 적당한 값으로 늘려야 합니다. 그러면
<code class="docutils literal notranslate"><span class="pre">DataLoaderOptions</span></code> 객체를 만들어 적절한 속성을 설정해 보겠습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">data_loader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">make_data_loader</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">DataLoaderOptions</span><span class="p">().</span><span class="n">batch_size</span><span class="p">(</span><span class="n">kBatchSize</span><span class="p">).</span><span class="n">workers</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span><span class="w"></span>
</pre></div>
</div>
<p>이제 데이터 배치를 로드하는 루프를 작성할 수 있습니다. 지금은
콘솔에만 출력할 것입니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">Example</span><span class="o">&lt;&gt;&amp;</span><span class="w"> </span><span class="n">batch</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">*</span><span class="n">data_loader</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Batch size: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; | Labels: &quot;</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>이 경우 데이터 로더가 반환하는 타입은 <code class="docutils literal notranslate"><span class="pre">torch::data::Example</span></code> 입니다.
이 타입은 데이터를 위한 <code class="docutils literal notranslate"><span class="pre">data</span></code> 필드와 레이블을 위한 <code class="docutils literal notranslate"><span class="pre">target</span></code> 필드가
있는 간단한 struct입니다. 앞서 <code class="docutils literal notranslate"><span class="pre">Stack</span></code> collation을 적용했기 때문에,
데이터 로더는 이 example을 하나만 반환합니다. 데이터 로더에 collation을
적용하지 않으면, <code class="docutils literal notranslate"><span class="pre">std::vector&lt;torch::data::Example&lt;&gt;&gt;</span></code> 를 yield하며,
각 배치의 example에는 하나의 element가 있을 것입니다.</p>
<p>이 코드를 다시 빌드하고 실행하면 대략 다음과 같은 내용을 얻을 것입니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@fa350df05ecf:/home/build# make
Scanning dependencies of target dcgan
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable dcgan
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcgan
root@fa350df05ecf:/home/build# make
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcgan
root@fa350df05ecf:/home/build# ./dcgan
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">5</span> <span class="m">2</span> <span class="m">6</span> <span class="m">7</span> <span class="m">2</span> <span class="m">1</span> <span class="m">6</span> <span class="m">7</span> <span class="m">0</span> <span class="m">1</span> <span class="m">6</span> <span class="m">2</span> <span class="m">3</span> <span class="m">6</span> <span class="m">9</span> <span class="m">1</span> <span class="m">8</span> <span class="m">4</span> <span class="m">0</span> <span class="m">6</span> <span class="m">5</span> <span class="m">3</span> <span class="m">3</span> <span class="m">0</span> <span class="m">4</span> <span class="m">6</span> <span class="m">6</span> <span class="m">6</span> <span class="m">4</span> <span class="m">0</span> <span class="m">8</span> <span class="m">6</span> <span class="m">0</span> <span class="m">6</span> <span class="m">9</span> <span class="m">2</span> <span class="m">4</span> <span class="m">0</span> <span class="m">2</span> <span class="m">8</span> <span class="m">6</span> <span class="m">3</span> <span class="m">3</span> <span class="m">2</span> <span class="m">9</span> <span class="m">2</span> <span class="m">0</span> <span class="m">1</span> <span class="m">4</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span> <span class="m">8</span> <span class="m">2</span> <span class="m">9</span> <span class="m">9</span> <span class="m">3</span> <span class="m">5</span> <span class="m">8</span> <span class="m">0</span> <span class="m">0</span> <span class="m">7</span> <span class="m">9</span> <span class="m">9</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">2</span> <span class="m">2</span> <span class="m">4</span> <span class="m">7</span> <span class="m">1</span> <span class="m">2</span> <span class="m">8</span> <span class="m">8</span> <span class="m">6</span> <span class="m">9</span> <span class="m">0</span> <span class="m">2</span> <span class="m">2</span> <span class="m">9</span> <span class="m">3</span> <span class="m">6</span> <span class="m">1</span> <span class="m">3</span> <span class="m">8</span> <span class="m">0</span> <span class="m">4</span> <span class="m">4</span> <span class="m">8</span> <span class="m">8</span> <span class="m">8</span> <span class="m">9</span> <span class="m">2</span> <span class="m">6</span> <span class="m">4</span> <span class="m">7</span> <span class="m">1</span> <span class="m">5</span> <span class="m">0</span> <span class="m">9</span> <span class="m">7</span> <span class="m">5</span> <span class="m">4</span> <span class="m">3</span> <span class="m">5</span> <span class="m">4</span> <span class="m">1</span> <span class="m">2</span> <span class="m">8</span> <span class="m">0</span> <span class="m">7</span> <span class="m">1</span> <span class="m">9</span> <span class="m">6</span> <span class="m">1</span> <span class="m">6</span> <span class="m">5</span> <span class="m">3</span> <span class="m">4</span> <span class="m">4</span> <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">2</span> <span class="m">3</span> <span class="m">5</span> <span class="m">0</span> <span class="m">1</span> <span class="m">6</span> <span class="m">2</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">4</span> <span class="m">5</span> <span class="m">4</span> <span class="m">2</span> <span class="m">1</span> <span class="m">4</span> <span class="m">8</span> <span class="m">3</span> <span class="m">8</span> <span class="m">3</span> <span class="m">6</span> <span class="m">1</span> <span class="m">5</span> <span class="m">4</span> <span class="m">3</span> <span class="m">6</span> <span class="m">2</span> <span class="m">2</span> <span class="m">5</span> <span class="m">1</span> <span class="m">3</span> <span class="m">1</span> <span class="m">5</span> <span class="m">0</span> <span class="m">8</span> <span class="m">2</span> <span class="m">1</span> <span class="m">5</span> <span class="m">3</span> <span class="m">2</span> <span class="m">4</span> <span class="m">4</span> <span class="m">5</span> <span class="m">9</span> <span class="m">7</span> <span class="m">2</span> <span class="m">8</span> <span class="m">9</span> <span class="m">2</span> <span class="m">0</span> <span class="m">6</span> <span class="m">7</span> <span class="m">4</span> <span class="m">3</span> <span class="m">8</span> <span class="m">3</span> <span class="m">5</span> <span class="m">8</span> <span class="m">8</span> <span class="m">3</span> <span class="m">0</span> <span class="m">5</span> <span class="m">8</span> <span class="m">0</span> <span class="m">8</span> <span class="m">7</span> <span class="m">8</span> <span class="m">5</span> <span class="m">5</span> <span class="m">6</span> <span class="m">1</span> <span class="m">7</span> <span class="m">8</span> <span class="m">0</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">3</span> <span class="m">3</span> <span class="m">7</span> <span class="m">1</span> <span class="m">4</span> <span class="m">1</span> <span class="m">6</span> <span class="m">1</span> <span class="m">0</span> <span class="m">3</span> <span class="m">6</span> <span class="m">4</span> <span class="m">0</span> <span class="m">2</span> <span class="m">5</span> <span class="m">4</span> <span class="m">0</span> <span class="m">4</span> <span class="m">2</span> <span class="m">8</span> <span class="m">1</span> <span class="m">9</span> <span class="m">6</span> <span class="m">5</span> <span class="m">1</span> <span class="m">6</span> <span class="m">3</span> <span class="m">2</span> <span class="m">8</span> <span class="m">9</span> <span class="m">2</span> <span class="m">3</span> <span class="m">8</span> <span class="m">7</span> <span class="m">4</span> <span class="m">5</span> <span class="m">9</span> <span class="m">6</span> <span class="m">0</span> <span class="m">8</span> <span class="m">3</span> <span class="m">0</span> <span class="m">0</span> <span class="m">6</span> <span class="m">4</span> <span class="m">8</span> <span class="m">2</span> <span class="m">5</span> <span class="m">4</span> <span class="m">1</span> <span class="m">8</span> <span class="m">3</span> <span class="m">7</span> <span class="m">8</span> <span class="m">0</span> <span class="m">0</span> <span class="m">8</span> <span class="m">9</span> <span class="m">6</span> <span class="m">7</span> <span class="m">2</span> <span class="m">1</span> <span class="m">4</span> <span class="m">7</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">3</span> <span class="m">0</span> <span class="m">5</span> <span class="m">5</span> <span class="m">9</span> <span class="m">8</span> <span class="m">3</span> <span class="m">9</span> <span class="m">8</span> <span class="m">9</span> <span class="m">5</span> <span class="m">9</span> <span class="m">5</span> <span class="m">0</span> <span class="m">4</span> <span class="m">1</span> <span class="m">2</span> <span class="m">7</span> <span class="m">7</span> <span class="m">2</span> <span class="m">0</span> <span class="m">0</span> <span class="m">5</span> <span class="m">4</span> <span class="m">8</span> <span class="m">7</span> <span class="m">7</span> <span class="m">6</span> <span class="m">1</span> <span class="m">0</span> <span class="m">7</span> <span class="m">9</span> <span class="m">3</span> <span class="m">0</span> <span class="m">6</span> <span class="m">3</span> <span class="m">2</span> <span class="m">6</span> <span class="m">2</span> <span class="m">7</span> <span class="m">6</span> <span class="m">3</span> <span class="m">3</span> <span class="m">4</span> <span class="m">0</span> <span class="m">5</span> <span class="m">8</span> <span class="m">8</span> <span class="m">9</span> <span class="m">1</span> <span class="m">9</span> <span class="m">2</span> <span class="m">1</span> <span class="m">9</span> <span class="m">4</span> <span class="m">4</span> <span class="m">9</span> <span class="m">2</span> <span class="m">4</span> <span class="m">6</span> <span class="m">2</span> <span class="m">9</span> <span class="m">4</span> <span class="m">0</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">9</span> <span class="m">6</span> <span class="m">7</span> <span class="m">5</span> <span class="m">3</span> <span class="m">5</span> <span class="m">9</span> <span class="m">0</span> <span class="m">8</span> <span class="m">6</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">2</span> <span class="m">1</span> <span class="m">9</span> <span class="m">8</span> <span class="m">8</span> <span class="m">1</span> <span class="m">1</span> <span class="m">8</span> <span class="m">2</span> <span class="m">0</span> <span class="m">7</span> <span class="m">1</span> <span class="m">4</span> <span class="m">1</span> <span class="m">6</span> <span class="m">7</span> <span class="m">5</span> <span class="m">1</span> <span class="m">7</span> <span class="m">7</span> <span class="m">4</span> <span class="m">0</span> <span class="m">3</span> <span class="m">2</span> <span class="m">9</span> <span class="m">0</span> <span class="m">6</span> <span class="m">6</span> <span class="m">3</span> <span class="m">4</span> <span class="m">4</span> <span class="m">8</span> <span class="m">1</span> <span class="m">2</span> <span class="m">8</span> <span class="m">6</span> <span class="m">9</span> <span class="m">2</span> <span class="m">0</span> <span class="m">3</span> <span class="m">1</span> <span class="m">2</span> <span class="m">8</span> <span class="m">5</span> <span class="m">6</span> <span class="m">4</span> <span class="m">8</span> <span class="m">5</span> <span class="m">8</span> <span class="m">6</span> <span class="m">2</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">9</span> <span class="m">3</span> <span class="m">0</span> <span class="m">3</span> <span class="m">6</span> <span class="m">5</span> <span class="m">1</span> <span class="m">8</span> <span class="m">6</span> <span class="m">0</span> <span class="m">1</span> <span class="m">9</span> <span class="m">9</span> <span class="m">1</span> <span class="m">6</span> <span class="m">1</span> <span class="m">7</span> <span class="m">7</span> <span class="m">4</span> <span class="m">4</span> <span class="m">4</span> <span class="m">7</span> <span class="m">8</span> <span class="m">8</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">2</span> <span class="m">6</span> <span class="m">0</span> <span class="m">4</span> <span class="m">6</span> <span class="m">8</span> <span class="m">2</span> <span class="m">5</span> <span class="m">3</span> <span class="m">9</span> <span class="m">8</span> <span class="m">4</span> <span class="m">0</span> <span class="m">9</span> <span class="m">9</span> <span class="m">3</span> <span class="m">7</span> <span class="m">0</span> <span class="m">5</span> <span class="m">8</span> <span class="m">2</span> <span class="m">4</span> <span class="m">5</span> <span class="m">6</span> <span class="m">2</span> <span class="m">8</span> <span class="m">2</span> <span class="m">5</span> <span class="m">3</span> <span class="m">7</span> <span class="m">1</span> <span class="m">9</span> <span class="m">1</span> <span class="m">8</span> <span class="m">2</span> <span class="m">2</span> <span class="m">7</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">9</span> <span class="m">1</span> <span class="m">9</span> <span class="m">2</span> <span class="m">7</span> <span class="m">2</span> <span class="m">6</span> <span class="m">0</span> <span class="m">8</span> <span class="m">6</span> <span class="m">8</span> <span class="m">7</span> <span class="m">7</span> <span class="m">4</span> <span class="m">8</span> <span class="m">6</span> <span class="m">1</span> <span class="m">1</span> <span class="m">6</span> <span class="m">8</span> <span class="m">5</span> <span class="m">7</span> <span class="m">9</span> <span class="m">1</span> <span class="m">3</span> <span class="m">2</span> <span class="m">0</span> <span class="m">5</span> <span class="m">1</span> <span class="m">7</span> <span class="m">3</span> <span class="m">1</span> <span class="m">6</span> <span class="m">1</span> <span class="m">0</span> <span class="m">8</span> <span class="m">6</span> <span class="m">0</span> <span class="m">8</span> <span class="m">1</span> <span class="m">0</span> <span class="m">5</span> <span class="m">4</span> <span class="m">9</span> <span class="m">3</span> <span class="m">8</span> <span class="m">5</span> <span class="m">8</span> <span class="m">4</span> <span class="m">8</span> <span class="m">0</span> <span class="m">1</span> <span class="m">2</span> <span class="m">6</span> <span class="m">2</span> <span class="m">4</span> <span class="m">2</span> <span class="m">7</span> <span class="m">7</span> <span class="m">3</span> <span class="m">7</span> <span class="m">4</span> <span class="m">5</span> <span class="m">3</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">8</span> <span class="m">8</span> <span class="m">3</span> <span class="m">1</span> <span class="m">8</span> <span class="m">6</span> <span class="m">4</span> <span class="m">2</span> <span class="m">9</span> <span class="m">5</span> <span class="m">8</span> <span class="m">0</span> <span class="m">2</span> <span class="m">8</span> <span class="m">6</span> <span class="m">6</span> <span class="m">7</span> <span class="m">0</span> <span class="m">9</span> <span class="m">8</span> <span class="m">3</span> <span class="m">8</span> <span class="m">7</span> <span class="m">1</span> <span class="m">6</span> <span class="m">6</span> <span class="m">2</span> <span class="m">7</span> <span class="m">7</span> <span class="m">4</span> <span class="m">5</span> <span class="m">5</span> <span class="m">2</span> <span class="m">1</span> <span class="m">7</span> <span class="m">9</span> <span class="m">5</span> <span class="m">4</span> <span class="m">9</span> <span class="m">1</span> <span class="m">0</span> <span class="m">3</span> <span class="m">1</span> <span class="m">9</span> <span class="m">3</span> <span class="m">9</span> <span class="m">8</span> <span class="m">8</span> <span class="m">5</span> <span class="m">3</span> <span class="m">7</span> <span class="m">5</span> <span class="m">3</span> <span class="m">6</span> <span class="m">8</span> <span class="m">9</span> <span class="m">4</span> <span class="m">2</span> <span class="m">0</span> <span class="m">1</span> <span class="m">2</span> <span class="m">5</span> <span class="m">4</span> <span class="m">7</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">9</span> <span class="m">2</span> <span class="m">7</span> <span class="m">0</span> <span class="m">8</span> <span class="m">4</span> <span class="m">4</span> <span class="m">2</span> <span class="m">7</span> <span class="m">5</span> <span class="m">0</span> <span class="m">0</span> <span class="m">6</span> <span class="m">2</span> <span class="m">0</span> <span class="m">5</span> <span class="m">9</span> <span class="m">5</span> <span class="m">9</span> <span class="m">8</span> <span class="m">8</span> <span class="m">9</span> <span class="m">3</span> <span class="m">5</span> <span class="m">7</span> <span class="m">5</span> <span class="m">4</span> <span class="m">7</span> <span class="m">3</span> <span class="m">0</span> <span class="m">5</span> <span class="m">7</span> <span class="m">6</span> <span class="m">5</span> <span class="m">7</span> <span class="m">1</span> <span class="m">6</span> <span class="m">2</span> <span class="m">8</span> <span class="m">7</span> <span class="m">6</span> <span class="m">3</span> <span class="m">2</span> <span class="m">6</span> <span class="m">5</span> <span class="m">6</span> <span class="m">1</span> <span class="m">2</span> <span class="m">7</span> <span class="m">7</span> <span class="m">0</span> <span class="m">0</span> <span class="m">5</span> <span class="m">9</span> <span class="m">0</span> <span class="m">0</span> <span class="m">9</span> <span class="m">1</span> <span class="m">7</span> <span class="m">8</span> <span class="m">3</span> <span class="m">2</span> <span class="m">9</span> <span class="m">4</span>
Batch size: <span class="m">64</span> <span class="p">|</span> Labels: <span class="m">7</span> <span class="m">6</span> <span class="m">5</span> <span class="m">7</span> <span class="m">7</span> <span class="m">5</span> <span class="m">2</span> <span class="m">2</span> <span class="m">4</span> <span class="m">9</span> <span class="m">9</span> <span class="m">4</span> <span class="m">8</span> <span class="m">7</span> <span class="m">4</span> <span class="m">8</span> <span class="m">9</span> <span class="m">4</span> <span class="m">5</span> <span class="m">7</span> <span class="m">1</span> <span class="m">2</span> <span class="m">6</span> <span class="m">9</span> <span class="m">8</span> <span class="m">5</span> <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">1</span> <span class="m">1</span> <span class="m">3</span> <span class="m">9</span> <span class="m">8</span> <span class="m">7</span> <span class="m">9</span> <span class="m">5</span> <span class="m">0</span> <span class="m">8</span> <span class="m">5</span> <span class="m">1</span> <span class="m">8</span> <span class="m">7</span> <span class="m">2</span> <span class="m">6</span> <span class="m">5</span> <span class="m">1</span> <span class="m">2</span> <span class="m">0</span> <span class="m">9</span> <span class="m">7</span> <span class="m">4</span> <span class="m">0</span> <span class="m">9</span> <span class="m">0</span> <span class="m">4</span> <span class="m">6</span> <span class="m">0</span> <span class="m">0</span> <span class="m">8</span> <span class="m">6</span>
...
</pre></div>
</div>
<p>즉, MNIST 데이터셋에서 데이터를 성공적으로 로드할 수 있습니다.</p>
</div>
<div class="section" id="id20">
<h2>학습 루프 작성하기<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h2>
<p>이제 예제의 알고리즘 부분을 마무리하고 생성기와 판별기 사이에서 일어나는 섬세한
작용을 구현해 보겠습니다. 먼저 생성기와 판별기 각각을 위해
총 두 개의 optimizer를 생성하겠습니다. 우리가 사용하는
optimizer는 <a class="reference external" href="https://arxiv.org/pdf/1412.6980.pdf">Adam</a> 알고리즘을 구현합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">Adam</span><span class="w"> </span><span class="nf">generator_optimizer</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">parameters</span><span class="p">(),</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">AdamOptions</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">).</span><span class="n">beta1</span><span class="p">(</span><span class="mf">0.5</span><span class="p">));</span><span class="w"></span>
<span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">Adam</span><span class="w"> </span><span class="nf">discriminator_optimizer</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">parameters</span><span class="p">(),</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">AdamOptions</span><span class="p">(</span><span class="mf">5e-4</span><span class="p">).</span><span class="n">beta1</span><span class="p">(</span><span class="mf">0.5</span><span class="p">));</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>이 글 작성 당시, C++ 프론트엔드가 Adagrad, Adam, LBFGS, RMSprop 및 SGD를 구현하는 옵티마이저를 제공합니다. 최신 리스트는 <a class="reference external" href="https://pytorch.org/cppdocs/api/namespace_torch__optim.html">docs</a> 에 있습니다.</p>
</div>
<p>다음으로, 우리의 학습 루프를 수정해야 합니다. 매 에폭마다 데이터 로더를 반복 실행하는
바깥 루프를 추가해 다음의 GAN 학습 코드를 작성합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">kNumberOfEpochs</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">epoch</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">batch_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">Example</span><span class="o">&lt;&gt;&amp;</span><span class="w"> </span><span class="n">batch</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">*</span><span class="n">data_loader</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="c1">// Train discriminator with real images.</span>
<span class="w">    </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">zero_grad</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">real_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">real_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">empty</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)).</span><span class="n">uniform_</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">real_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">real_images</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">d_loss_real</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span><span class="w"> </span><span class="n">real_labels</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">d_loss_real</span><span class="p">.</span><span class="n">backward</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Train discriminator with fake images.</span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">noise</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span><span class="w"> </span><span class="n">kNoiseSize</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">});</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">fake_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">noise</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">fake_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">fake_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">fake_images</span><span class="p">.</span><span class="n">detach</span><span class="p">());</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">d_loss_fake</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">fake_output</span><span class="p">,</span><span class="w"> </span><span class="n">fake_labels</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">d_loss_fake</span><span class="p">.</span><span class="n">backward</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">d_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d_loss_real</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">d_loss_fake</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">discriminator_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Train generator.</span>
<span class="w">    </span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">zero_grad</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">fake_labels</span><span class="p">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">fake_output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">fake_images</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">g_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">fake_output</span><span class="p">,</span><span class="w"> </span><span class="n">fake_labels</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">g_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="n">generator_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">printf</span><span class="p">(</span><span class="w"></span>
<span class="w">        </span><span class="s">&quot;</span><span class="se">\r</span><span class="s">[%2ld/%2ld][%3ld/%3ld] D_loss: %.4f | G_loss: %.4f&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="n">epoch</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="n">kNumberOfEpochs</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="o">++</span><span class="n">batch_index</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="n">batches_per_epoch</span><span class="p">,</span><span class="w"></span>
<span class="w">        </span><span class="n">d_loss</span><span class="p">.</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(),</span><span class="w"></span>
<span class="w">        </span><span class="n">g_loss</span><span class="p">.</span><span class="n">item</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">());</span><span class="w"></span>
<span class="w">  </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>위 코드는 먼저 진짜 (real) 이미지에 대해 판별기를 평가하는데, 이 때
판별기는 높은 확률을 출력해야 합니다. 이를 위해
<code class="docutils literal notranslate"><span class="pre">torch::empty(batch.data.size(0)).uniform_(0.8,</span> <span class="pre">1.0)</span></code> 를 목표 확률
값으로 사용합니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>판별기를 보다 견고하게 학습하기 위해 모든 곳에서 1.0이 아닌 0.8과 1.0 사이의 균일 분포에서 임의의 값을 선택합니다. 이 트릭을 <em>label smoothing</em> 이라고 합니다.</p>
</div>
<p>판별기를 평가하기에 앞서 매개변수의 그래디언트를 0으로 만듭니다.
손실을 계산한 후 <code class="docutils literal notranslate"><span class="pre">d_loss.backward()</span></code> 를 호출해 이를
네트워크에 역전파합니다. 가짜 (fake) 이미지들에 대해서 이 과정을
반복합니다. 데이터셋의 이미지를 사용하는 대신, 생성자에
무작위 노이즈를 입력하여 여기서 사용할 가짜 이미지를 만듭니다.
그리고 그 가짜 이미지들을 판별기에 전달합니다. 이번에는
판별기가 낮은 확률, 이상적으로는 모두 0을 출력하기를 바랍니다.
진짜 이미지와 가짜 이미지 배치 모두에 대한 판별기 손실을 계산한
후에는, 판별기의 optimizer 매개변수 업데이트를 한 단계씩
진행할 수 있습니다.</p>
<p>생성기를 학습시키기 위해 우선 그래디언트를 다시 한번 0으로 설정하고
다시 가짜 이미지로 판별기를 평가합니다. 그러나 이번에는 판별기가
확률 1에 매우 근접하게 출력하게 하여, 생성기가 판별기를
속여 실제 (데이터셋에 있는) 진짜라고 생각하는 이미지를 생성할 수
있도록 하려 합니다. 이를 위해 <code class="docutils literal notranslate"><span class="pre">fake_labels</span></code> 텐서를 모두
1로 채우겠습니다. 마지막으로 매개변수를 업데이트하기 위해
생성기의 optimzier 매개변수 업데이트를 진행합니다.</p>
<p>이제 CPU로 모델을 학습시킬 준비가 되었습니다. 상태나 샘플 출력을
캡처할 수 있는 코드는 아직 없지만 잠시 후에 추가하겠습니다. 지금은
모델이 <em>무언가</em> 를 수행하고 있다는 것만을 관찰하고, 나중에는 생성된
이미지를 기반으로 이 무언가가 의미 있는지 여부를 확인할 것입니다.
다시 빌드하고 실행하면 다음과 같은 내용이 출력돼야 합니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@3c0711f20896:/home/build# make <span class="o">&amp;&amp;</span> ./dcgan
Scanning dependencies of target dcgan
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable dcgan
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcga
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">100</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.6876 <span class="p">|</span> G_loss: <span class="m">4</span>.1304
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">200</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3776 <span class="p">|</span> G_loss: <span class="m">4</span>.3101
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">300</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3652 <span class="p">|</span> G_loss: <span class="m">4</span>.6626
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">400</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.8057 <span class="p">|</span> G_loss: <span class="m">2</span>.2795
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">500</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3531 <span class="p">|</span> G_loss: <span class="m">4</span>.4452
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">600</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3501 <span class="p">|</span> G_loss: <span class="m">5</span>.0811
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">700</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3581 <span class="p">|</span> G_loss: <span class="m">4</span>.5623
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">800</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.6423 <span class="p">|</span> G_loss: <span class="m">1</span>.7385
<span class="o">[</span> <span class="m">1</span>/10<span class="o">][</span><span class="m">900</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3592 <span class="p">|</span> G_loss: <span class="m">4</span>.7333
<span class="o">[</span> <span class="m">2</span>/10<span class="o">][</span><span class="m">100</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.4660 <span class="p">|</span> G_loss: <span class="m">2</span>.5242
<span class="o">[</span> <span class="m">2</span>/10<span class="o">][</span><span class="m">200</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.6364 <span class="p">|</span> G_loss: <span class="m">2</span>.0886
<span class="o">[</span> <span class="m">2</span>/10<span class="o">][</span><span class="m">300</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3717 <span class="p">|</span> G_loss: <span class="m">3</span>.8103
<span class="o">[</span> <span class="m">2</span>/10<span class="o">][</span><span class="m">400</span>/938<span class="o">]</span> D_loss: <span class="m">1</span>.0201 <span class="p">|</span> G_loss: <span class="m">1</span>.3544
<span class="o">[</span> <span class="m">2</span>/10<span class="o">][</span><span class="m">500</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.4522 <span class="p">|</span> G_loss: <span class="m">2</span>.6545
...
</pre></div>
</div>
</div>
<div class="section" id="gpu">
<h2>GPU로 이동하기<a class="headerlink" href="#gpu" title="Permalink to this headline">¶</a></h2>
<p>이 스크립트는 CPU에서 잘 동작하지만, 합성곱 연산이 GPU에서 훨씬 빠르다는
것은 잘 알려진 사실입니다. 어떻게 학습을 GPU로 옮길 수 있을 지에 대해 빠르게 논의해
보겠습니다. 이를 위해 해야 할 일 두 가지로 GPU 장치(device) 사양을 우리가 직접 할당한
텐서에 전달하는 것과, C++ 프론트엔드의 모든 텐서와 모듈이 갖고 있는 <code class="docutils literal notranslate"><span class="pre">to()</span></code>
메서드를 사용해 다른 모든 텐서를 GPU에 명시적으로 복사하는 것이 있습니다.
두 가지를 모두 달성하는 가장 간단한 방법으로 학습 스크립트 최상위에
<code class="docutils literal notranslate"><span class="pre">torch::Device</span></code> 인스턴스를 만들어 <code class="docutils literal notranslate"><span class="pre">torch::zeros</span></code> 와 같은
텐서 팩토리 함수나 <code class="docutils literal notranslate"><span class="pre">to()</span></code> 메서드에 전달할 수 있습니다. 먼저 CPU device로
이를 구현해보겠습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// 학습 스크립트 최상단에 이 코드를 넣으세요.</span>
<span class="n">torch</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCPU</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>아래와 같은 새로운 텐서 할당의 경우,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">fake_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span><span class="w"></span>
</pre></div>
</div>
<p>마지막 인자로 <code class="docutils literal notranslate"><span class="pre">device</span></code> 를 받도록 수정합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">fake_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span><span class="w"> </span><span class="n">device</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>MNIST 데이터셋의 텐서처럼 우리가 직접 생성하지 않는 텐서에서는
명시적으로 <code class="docutils literal notranslate"><span class="pre">to()</span></code> 호출을 삽입해야 합니다. 따라서 아래 코드의 경우,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">real_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>다음과 같이 변합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">real_images</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>또한, 모델 매개변수를 올바른 장치로 옮겨야 합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span><span class="w"></span>
<span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>만일 텐서가 이미 <code class="docutils literal notranslate"><span class="pre">to()</span></code> 에 전달된 장치 상에 있다면 그 호출은 아무 일도 하지 않습니다. 사본이 생성되지도 않습니다.</p>
</div>
<p>이제 CPU에서 실행되는 이전의 코드가 보다 명시적으로 바뀌었습니다.
하지만 이제는 장치를 CUDA 장치로 변경하는 것 또한 매우 쉽습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">kCUDA</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>이제 모든 텐서가 GPU에 존재하며 어떠한 다운스트림 코드 변경 없이도
모든 연산을 위해 빠른 CUDA 커널을 호출합니다. 특정 인덱스의 장치를
지정하려면 <code class="docutils literal notranslate"><span class="pre">Device</span></code> 생성자의 두 번째 인자로 전달하면 됩니다.
서로 다른 장치에 서로 다른 텐서가 존재하기를 원하는 경우,
별도의 장치 인스턴스(예: CUDA 장치 0과 다른 CUDA 장치 1)를
전달할 수도 있습니다. 뿐만 아니라, 이러한 설정을 동적으로 수행할 수도
있어 다음과 같이 학습 스크립트의 휴대성을 높이는 데 종종 유용하게 사용됩니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kCPU</span><span class="p">;</span><span class="w"></span>
<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">cuda</span><span class="o">::</span><span class="n">is_available</span><span class="p">())</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;CUDA is available! Training on GPU.&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="n">device</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kCUDA</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>나아가 아래와 같은 코드도 가능합니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">cuda</span><span class="o">::</span><span class="n">is_available</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kCUDA</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">kCPU</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="id21">
<h2>학습 상태 저장 및 복원하기<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h2>
<p>마지막으로 학습 스크립트에 추가해야 할 내용은 모델 매개변수 및
옵티마이저의 상태, 그리고 생성된 몇 개의 이미지 샘플을
주기적으로 저장하는 것입니다. 학습 과정 도중에 컴퓨터가 다운되면
이렇게 저장된 상태로부터 학습 상태를 복원할 수 있습니다.
이는 장시간 지속되는 학습을 위해 필수로 요구됩니다. 다행히도
C++ 프론트엔드는 개별 텐서뿐만 아니라 모델 및 옵티마이저 상태를
직렬화하고 역직렬화할 수 있는 API를 제공합니다.</p>
<p>이를 위한 핵심 API는 <code class="docutils literal notranslate"><span class="pre">torch::save(thing,filename)</span></code> 와
<code class="docutils literal notranslate"><span class="pre">torch::load(thing,filename)</span></code> 로, 여기서 <code class="docutils literal notranslate"><span class="pre">thing</span></code> 은
<code class="docutils literal notranslate"><span class="pre">torch::nn::Module</span></code> 의 하위 클래스 혹은 우리의 학습 스크립트의 <code class="docutils literal notranslate"><span class="pre">Adam</span></code>
객체와 같은 옵티마이저 인스턴스가 될 수 있습니다. 모델 및 옵티마이저 상태를
특정 주기마다 저장하도록 학습 루프를 수정해보겠습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">batch_index</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">kCheckpointEvery</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="c1">// 모델 및 옵티마이저 상태를 저장합니다.</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">save</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;generator-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">save</span><span class="p">(</span><span class="n">generator_optimizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;generator-optimizer-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">save</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;discriminator-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">save</span><span class="p">(</span><span class="n">discriminator_optimizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;discriminator-optimizer-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="c1">// 생성기를 샘플링하고 이미지를 저장합니다.</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">forward</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="n">kNoiseSize</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">device</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">save</span><span class="p">((</span><span class="n">samples</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">2.0</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">str</span><span class="p">(</span><span class="s">&quot;dcgan-sample-&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">checkpoint_counter</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;.pt&quot;</span><span class="p">));</span><span class="w"></span>
<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">-&gt; checkpoint &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="o">++</span><span class="n">checkpoint_counter</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="sc">&#39;\n&#39;</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>여기서 <code class="docutils literal notranslate"><span class="pre">100</span></code> 배치마다 상태를 저장하려면 <code class="docutils literal notranslate"><span class="pre">kCheckpointEvery</span></code> 를 <code class="docutils literal notranslate"><span class="pre">100</span></code>
과 같은 정수로 설정할 수 있으며, <code class="docutils literal notranslate"><span class="pre">checkpoint_counter</span></code> 는 상태를 저장할 때마다
증가하는 카운터입니다.</p>
<p>학습 상태를 복원하기 위해 모델 및 옵티마이저를 모두 생성한 후 학습 루프 앞에
다음 코드를 추가할 수 있습니다.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">Adam</span><span class="w"> </span><span class="nf">generator_optimizer</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">generator</span><span class="o">-&gt;</span><span class="n">parameters</span><span class="p">(),</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">AdamOptions</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">).</span><span class="n">beta1</span><span class="p">(</span><span class="mf">0.5</span><span class="p">));</span><span class="w"></span>
<span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">Adam</span><span class="w"> </span><span class="nf">discriminator_optimizer</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">discriminator</span><span class="o">-&gt;</span><span class="n">parameters</span><span class="p">(),</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">optim</span><span class="o">::</span><span class="n">AdamOptions</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">).</span><span class="n">beta1</span><span class="p">(</span><span class="mf">0.5</span><span class="p">));</span><span class="w"></span>

<span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">kRestoreFromCheckpoint</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;generator-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">generator_optimizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;generator-optimizer-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">discriminator</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;discriminator-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">discriminator_optimizer</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;discriminator-optimizer-checkpoint.pt&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">int64_t</span><span class="w"> </span><span class="n">checkpoint_counter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">kNumberOfEpochs</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">epoch</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">batch_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">Example</span><span class="o">&lt;&gt;&amp;</span><span class="w"> </span><span class="n">batch</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">*</span><span class="n">data_loader</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
</pre></div>
</div>
</div>
<div class="section" id="id22">
<h2>생성한 이미지 검사하기<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h2>
<p>학습 스크립트가 완성되어 CPU에서든 GPU에서든 GAN을 훈련시킬 준비가
됐습니다. 학습 과정의 중간 출력을 검사하기 위해
<code class="docutils literal notranslate"><span class="pre">&quot;dcgan-sample-xxx.pt&quot;</span></code> 에 주기적으로 이미지 샘플을 저장하는 코드를
추가했으니, 텐서들을 불러와 matplotlib로 시각화하는 간단한 파이썬
스크립트를 작성해보겠습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">unicode_literals</span>

<span class="kn">import</span> <span class="nn">argparse</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-i&quot;</span><span class="p">,</span> <span class="s2">&quot;--sample-file&quot;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-o&quot;</span><span class="p">,</span> <span class="s2">&quot;--out-file&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;out.png&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-d&quot;</span><span class="p">,</span> <span class="s2">&quot;--dimension&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">options</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">sample_file</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">dimension</span> <span class="o">*</span> <span class="n">options</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
  <span class="n">array</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">dimension</span><span class="p">,</span> <span class="n">options</span><span class="o">.</span><span class="n">dimension</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">index</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
  <span class="n">axis</span><span class="o">.</span><span class="n">get_xaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">axis</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">out_file</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved &quot;</span><span class="p">,</span> <span class="n">options</span><span class="o">.</span><span class="n">out_file</span><span class="p">)</span>
</pre></div>
</div>
<p>이제 모델을 약 30 에폭 정도 학습시킵시다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@3c0711f20896:/home/build# make <span class="o">&amp;&amp;</span> ./dcgan                                                                                                                                <span class="m">10</span>:17:57
Scanning dependencies of target dcgan
<span class="o">[</span> <span class="m">50</span>%<span class="o">]</span> Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Linking CXX executable dcgan
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span> Built target dcgan
CUDA is available! Training on GPU.
<span class="o">[</span> <span class="m">1</span>/30<span class="o">][</span><span class="m">200</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.4953 <span class="p">|</span> G_loss: <span class="m">4</span>.0195
-&gt; checkpoint <span class="m">1</span>
<span class="o">[</span> <span class="m">1</span>/30<span class="o">][</span><span class="m">400</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3610 <span class="p">|</span> G_loss: <span class="m">4</span>.8148
-&gt; checkpoint <span class="m">2</span>
<span class="o">[</span> <span class="m">1</span>/30<span class="o">][</span><span class="m">600</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.4072 <span class="p">|</span> G_loss: <span class="m">4</span>.36760
-&gt; checkpoint <span class="m">3</span>
<span class="o">[</span> <span class="m">1</span>/30<span class="o">][</span><span class="m">800</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.4444 <span class="p">|</span> G_loss: <span class="m">4</span>.0250
-&gt; checkpoint <span class="m">4</span>
<span class="o">[</span> <span class="m">2</span>/30<span class="o">][</span><span class="m">200</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3761 <span class="p">|</span> G_loss: <span class="m">3</span>.8790
-&gt; checkpoint <span class="m">5</span>
<span class="o">[</span> <span class="m">2</span>/30<span class="o">][</span><span class="m">400</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3977 <span class="p">|</span> G_loss: <span class="m">3</span>.3315
...
-&gt; checkpoint <span class="m">120</span>
<span class="o">[</span><span class="m">30</span>/30<span class="o">][</span><span class="m">938</span>/938<span class="o">]</span> D_loss: <span class="m">0</span>.3610 <span class="p">|</span> G_loss: <span class="m">3</span>.8084
</pre></div>
</div>
<p>그리고 이미지들을 플롯에 시각화합니다.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>root@3c0711f20896:/home/build# python display.py -i dcgan-sample-100.pt
Saved out.png
</pre></div>
</div>
<p>그 결과는 아래와 같을 것입니다.</p>
<div class="figure align-default">
<img alt="digits" src="../_images/digits.png" />
</div>
<p>숫자네요! 만세! 이제 여러분 차례입니다. 숫자가 보다 나아 보이도록
모델을 개선할 수 있나요?</p>
</div>
<div class="section" id="id23">
<h2>결론<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h2>
<p>이 튜토리얼을 통해 PyTorch C++ 프론트엔드에 대한 어느 정도 이해도가 생기셨기
바랍니다. 필연적으로 PyTorch 같은 머신러닝 라이브러리는 매우 다양하고
광범위한 API를 가지고 있습니다. 따라서, 여기서 논의하기에 시간과 공간이
부족했던 개념들이 많습니다. 그러나 직접 API를 사용해보고,
<a class="reference external" href="https://pytorch.org/cppdocs/">문서</a>, 그 중에서도 특히
<a class="reference external" href="https://pytorch.org/cppdocs/api/library_root.html">라이브러리 API</a>
섹션을 참조해보는 것을 권장드립니다. 또한, C++ 프론트엔드가 파이썬
프론트엔드의 디자인과 시맨틱을 따른다는 사실을 잘 기억하면 보다 빠르게
학습할 수 있을 것입니다.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>본 튜토리얼에 대한 전체 소스코드는 <a class="reference external" href="https://github.com/pytorch/examples/tree/master/cpp/dcgan">이 저장소</a> 에 제공되어 있습니다.</p>
</div>
<p>언제나 그렇듯이 어떤 문제가 생기거나 질문이 있으면 저희
<a class="reference external" href="https://discuss.pytorch.org/">포럼</a> 을 이용하거나 <a class="reference external" href="https://github.com/pytorch/pytorch/issues">Github 이슈</a> 로 연락주세요.</p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="torch-script-parallelism.html" class="btn btn-neutral float-right" title="TorchScript의 동적 병렬 처리(Dynamic Parallelism)" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../intermediate/forward_ad_usage.html" class="btn btn-neutral" title="Forward-mode Automatic Differentiation (Beta)" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr class="rating-hr hr-top">
      <div class="rating-container">
        <div class="rating-prompt">이 튜토리얼이 어떠셨나요?</div>
        <div class="stars-outer">
          <i class="far fa-star" title="1 Star" data-behavior="tutorial-rating" data-count="1"></i>
          <i class="far fa-star" title="2 Stars" data-behavior="tutorial-rating" data-count="2"></i>
          <i class="far fa-star" title="3 Stars" data-behavior="tutorial-rating" data-count="3"></i>
          <i class="far fa-star" title="4 Stars" data-behavior="tutorial-rating" data-count="4"></i>
          <i class="far fa-star" title="5 Stars" data-behavior="tutorial-rating" data-count="5"></i>
        </div>
      </div>
    <hr class="rating-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorch Korea User Group).

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> 이 튜토리얼은 프로토타입(prototype) 기능들에 대해서 설명하고 있습니다. 프로토타입 기능은 일반적으로 피드백 및 테스트용으로, 런타임 플래그 없이는 PyPI나 Conda로 배포되는 바이너리에서는 사용할 수 없습니다.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">PyTorch C++ 프론트엔드 사용하기</a><ul>
<li><a class="reference internal" href="#id3">동기부여</a></li>
<li><a class="reference internal" href="#id4">기본 애플리케이션 작성하기</a></li>
<li><a class="reference internal" href="#id6">신경망 모델 정의하기</a><ul>
<li><a class="reference internal" href="#api">모듈 API 기초</a><ul>
<li><a class="reference internal" href="#id7">모듈 정의 및 매개변수 등록</a></li>
<li><a class="reference internal" href="#id8">서브모듈 등록 및 모듈 계층 구조 탐색</a></li>
<li><a class="reference internal" href="#forward">순전파(forward) 모드로 네트워크 실행</a></li>
<li><a class="reference internal" href="#ownership">모듈 오너십 (Ownership)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id13">DCGAN 모듈 정의하기</a><ul>
<li><a class="reference internal" href="#id16">GAN이 뭐였죠?</a></li>
<li><a class="reference internal" href="#generator">생성기 (Generator) 모듈</a></li>
<li><a class="reference internal" href="#discriminator">판별기(Discriminator) 모듈</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id17">데이터 불러오기</a></li>
<li><a class="reference internal" href="#id20">학습 루프 작성하기</a></li>
<li><a class="reference internal" href="#gpu">GPU로 이동하기</a></li>
<li><a class="reference internal" href="#id21">학습 상태 저장 및 복원하기</a></li>
<li><a class="reference internal" href="#id22">생성한 이미지 검사하기</a></li>
<li><a class="reference internal" href="#id23">결론</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  
  
     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
         <script src="../_static/katex_autorenderer.js"></script>
     
  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }

    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; isplay: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }
</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-LZRD6GXDLF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-LZRD6GXDLF');   // GA4
  gtag('config', 'UA-71919972-3');  // UA
</script>


<script>
  $("[data-behavior='call-to-action-event']").on('click', function(){
    ga('send', {
      hitType: 'event',
      eventCategory: $(this).attr("data-response"),
      eventAction: 'click',
      eventLabel: window.location.href
    });

    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }
</script>

<script type="text/javascript">
  var collapsedSections = ['파이토치(PyTorch) 레시피', '파이토치(PyTorch) 배우기', '이미지/비디오', '오디오', '텍스트', '강화학습', 'PyTorch 모델을 프로덕션 환경에 배포하기', 'Code Transforms with FX', '프론트엔드 API', 'PyTorch 확장하기', '모델 최적화', '병렬 및 분산 학습', 'Mobile', 'Introduction to PyTorch on YouTube', 'Recommendation Systems'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>PyTorchKorea @ GitHub</h2>
          <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
          <a class="with-right-arrow" href="https://github.com/PyTorchKorea" target="_blank">GitHub로 이동</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>한국어 튜토리얼</h2>
          <p>한국어로 번역 중인 PyTorch 튜토리얼입니다.</p>
          <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>커뮤니티</h2>
          <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
          <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.kr/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
            <li><a href="https://pytorch.kr//about">사용자 모임 소개</a></li>
            <li><a href="https://pytorch.kr//about/contributors">기여해주신 분들</a></li>
            <li><a href="https://pytorch.kr//resources">리소스</a></li>
            <li><a href="https://pytorch.kr//coc">행동 강령</a></li>
          </ul>
        </div>
      </div>
      <div class="trademark-disclaimer">
        <ul>
          <li>파이토치 한국 사용자 모임은 사용자들이 함께 모여 만들어가는 독립적인 커뮤니티로, 모든 활동은 Facebook과 관련이 없습니다. (We're independent user community. All activities are not related to Facebook.)</li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a>을 지켜주세요. PyTorch, PyTorch 로고 및 모든 관련 표기는 Facebook, Inc의 상표입니다. (Please follow <a href="https://pytorch.kr/coc">code of conduct</a>. PyTorch, the PyTorch logo and all related marks are trademarks of Facebook, Inc.)</li>
        </ul>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.kr/get-started">시작하기</a>
          </li>

          <li class="active">
            <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
          </li>

          <li>
            <a href="https://pytorch.kr/hub">허브</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.kr/">커뮤니티</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>