{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTimer \ube60\ub974\uac8c \uc2dc\uc791\ud558\uae30\n========================\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 `torch.utils.benchmark.Timer`\\ \uc758 \uc8fc\uc694 API\ub4e4\uc744 \ub2e4\ub904\ubcf4\ub3c4\ub85d\n\ud558\uaca0\uc2b5\ub2c8\ub2e4. PyTorch Timer\ub294\n`timeit.Timer <https://docs.python.org/3/library/timeit.html#timeit.Timer>`__\nAPI \uae30\ubc18\uc73c\ub85c, \uba87\uba87 PyTorch \ud2b9\ud654\ub41c \uae30\ub2a5(modification)\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\ub0b4\uc7a5 `Timer` \ud074\ub798\uc2a4\uc5d0 \uc775\uc219\ud558\uc2e4 \ud544\uc694\ub294 \uc5c6\uc9c0\ub9cc, \uc131\ub2a5 \uce21\uc815(work)\uc758 \uae30\ubcf8\uc801\uc778\n\ub0b4\uc6a9\ub4e4\uc5d0\ub294 \uc775\uc219\ud558\ub2e4\uace0 \uac00\uc815\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ubcf4\ub2e4 \uc885\ud569\uc801\uc778 \uc131\ub2a5 \ud29c\ub2dd \ud29c\ud1a0\ub9ac\uc5bc\uc740 \ub2e4\uc74c \ub9c1\ud06c\ub97c \ucc38\uace0\ud574\uc8fc\uc138\uc694:\n\n    https://tutorials.pytorch.kr/recipes/recipes/benchmark.html\n\n\n**\ubaa9\ucc28:**\n    1. `Timer \uc815\uc758\ud558\uae30 <#id1>`__\n    2. `\uc2e4\uc81c \uc2dc\uac04(wall time): \\`Timer.blocked_autorange(...)\\` <#wall-time-timer-blocked-autorange>`__\n    3. `C++ \ucf54\ub4dc\uc870\uac01(snippet) <#c-snippet>`__\n    4. `\uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218(instruction counts): \\`Timer.collect_callgrind(...)\\` <#instruction-counts-timer-collect-callgrind>`__\n    5. `\uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218: \ub354 \uae4a\uc774 \ud30c\ubcf4\uae30 <#id2>`__\n    6. `Callgrind\ub97c \uc0ac\uc6a9\ud55c A/B \ud14c\uc2a4\ud2b8 <#callgrind-a-b>`__\n    7. `\ub9c8\ubb34\ub9ac <#id3>`__\n    8. `\uac01\uc8fc <#id4>`__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Timer \uc815\uc758\ud558\uae30\n~~~~~~~~~~~~~~~~~~~\n\n`Timer` \ub294 \uc791\uc5c5\uc744 \uc815\uc758\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark import Timer\n\ntimer = Timer(\n    # \ubc18\ubcf5\ubb38(loop)\uc5d0\uc11c \uc2e4\ud589\ud558\uace0 \uc2dc\uac04\uc744 \uce21\uc815\ud560 \uc5f0\uc0b0\uc744 \uc815\uc758\ud569\ub2c8\ub2e4\n    stmt=\"x * y\",\n\n    # `setup` \uc740 \ubc18\ubcf5 \uce21\uc815\uc744 \uc2dc\uc791\ud558\uae30 \uc804\uc5d0 \uc2e4\ud589\ub418\ubbc0\ub85c,\n    # `stmt` \uc5d0\uc11c \ud544\uc694\ud55c \ubaa8\ub4e0 \uc0c1\ud0dc\ub97c \uc900\ube44(populate)\ud558\ub294\ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4\n    setup=\"\"\"\n        x = torch.ones((128,))\n        y = torch.ones((128,))\n    \"\"\",\n\n    # \ub610\ub294, `globals` \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc678\ubd80 \ubc94\uc704(outer scope)\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ubcc0\uc218\ub4e4\uc744\n    # \uc804\ub2ec\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4\n    # -------------------------------------------------------------------------\n    # globals={\n    #     \"x\": torch.ones((128,)),\n    #     \"y\": torch.ones((128,)),\n    # },\n\n    # PyTorch\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \uc4f0\ub808\ub4dc(thread)\uc758 \uc218\ub97c \uc870\uc808\ud569\ub2c8\ub2e4 (\uae30\ubcf8\uac12: 1)\n    num_threads=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. \uc2e4\uc81c \uc2e4\ud589 \uc2dc\uac04(wall time): `Timer.blocked_autorange(...)`\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uc774 \uba54\uc11c\ub4dc(method)\ub294 \uba87 \ubc88\uc774\ub098 \ubc18\ubcf5\ud560\uc9c0 \uc801\uc808\ud55c \ud69f\uc218\ub97c \uace0\ub974\uac70\ub098, \uc4f0\ub808\ub4dc\uc758 \uc218\ub97c\n\ubcc0\uacbd(fix)\ud558\uac70\ub098,\uacb0\uacfc\ub97c \ud3b8\ud558\uac8c \ud45c\ud604\ud558\ub294 \ubc29\ubc95\uc744 \uc81c\uacf5\ud558\ub294 \ub4f1, \uc138\ubd80\uc801\uc778 \uc0ac\ud56d\ub4e4\uc744\n\ucc98\ub9ac(handle)\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Measurement \uac1d\uccb4\ub294 \uc5ec\ub7ec\ubc88 \ubc18\ubcf5\ud558\uc5ec \uce21\uc815\ud55c \uacb0\uacfc\ub97c \uc800\uc7a5\ud558\uace0, \ub2e4\uc591\ud55c \ud3b8\uc758 \uae30\ub2a5\n# (utility feature)\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.\nfrom torch.utils.benchmark import Measurement\n\nm: Measurement = timer.blocked_autorange(min_run_time=1)\nprint(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **Snippet wall time.**\n\n        <torch.utils.benchmark.utils.common.Measurement object at 0x7f1929a38ed0>\n        x * y\n        setup:\n          x = torch.ones((128,))\n          y = torch.ones((128,))\n\n          Median: 2.34 us\n          IQR:    0.07 us (2.31 to 2.38)\n          424 measurements, 1000 runs per measurement, 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. C++ \ucf54\ub4dc \uc870\uac01(snippet)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark import Language\n\ncpp_timer = Timer(\n    \"x * y;\",\n    \"\"\"\n        auto x = torch::ones({128});\n        auto y = torch::ones({128});\n    \"\"\",\n    language=Language.CPP,\n)\n\nprint(cpp_timer.blocked_autorange(min_run_time=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **C++ snippet wall time.**\n\n        <torch.utils.benchmark.utils.common.Measurement object at 0x7f192b019ed0>\n        x * y;\n        setup:\n          auto x = torch::ones({128});\n          auto y = torch::ones({128});\n\n          Median: 1.21 us\n          IQR:    0.03 us (1.20 to 1.23)\n          83 measurements, 10000 runs per measurement, 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2f9\uc5f0\ud788 C++ \ucf54\ub4dc \uc870\uac01(snippet)\uc774 \ub354 \ube60\ub974\uace0 \ud3b8\ucc28(variation)\uac00 \uc801\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. \uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218(instruction counts): `Timer.collect_callgrind(...)`\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\ub354 \uc790\uc138\ud55c \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uae30 \uc704\ud574, `Timer.collect_callgrind` \ub294\n\uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218(instruction count)\ub97c \uc218\uc9d1\ud558\ub294\n`Callgrind <https://valgrind.org/docs/manual/cl-manual.html>` \ub97c \uac10\uc2f8\uace0(wrap) \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub294 \ucf54\ub4dc \uc870\uac01(snippet)\uc774 \uc5b4\ub5bb\uac8c \uc2e4\ud589\ub418\ub294\uc9c0\uc5d0 \ub300\ud574 \uc138\ubd84\ud654\ub418\uace0 \uacb0\uc815\uc801\uc778(deterministic)\n\ud1b5\ucc30\uc744 \uc81c\uacf5\ud558\ubbc0\ub85c \uc720\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark import CallgrindStats, FunctionCounts\n\nstats: CallgrindStats = cpp_timer.collect_callgrind()\nprint(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **C++ Callgrind stats (summary)**\n\n        <torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7f1929a35850>\n        x * y;\n        setup:\n          auto x = torch::ones({128});\n          auto y = torch::ones({128});\n\n                                All          Noisy symbols removed\n            Instructions:       563600                     563600\n            Baseline:                0                          0\n        100 runs per measurement, 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. \uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218: \ub354 \uae4a\uc774 \ud30c\ubcf4\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCallgrindStats\uc758 \ubb38\uc790\uc5f4 \ud45c\ud604\uc740 Measurement\uc758 \uadf8\uac83\uacfc \uc720\uc0ac\ud569\ub2c8\ub2e4.\n`Noisy symbol` \uc740 Python\uc758 \uac1c\ub150\uc785\ub2c8\ub2e4. (CPython \uc778\ud130\ud504\ub9ac\ud130(interpreter)\uc5d0\uc11c\ub294\n\ubd88\ud544\uc694\ud558\ub2e4(noisy)\uace0 \uc54c\ub824\uc9c4 \ud638\ucd9c\ub4e4\uc744 \uc81c\uc678\ud569\ub2c8\ub2e4)\n\n\uc77c\ub2e8 \ub354 \uc790\uc138\ud55c \ubd84\uc11d\uc744 \uc704\ud574, \ud2b9\uc815 \ud638\ucd9c(call)\uc744 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n`CallgrindStats.stats()` \uc740 \uc774\ub97c \ub354 \uc27d\uac8c\ud574\uc8fc\ub294 FunctionCounts \uac1d\uccb4\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\uac1c\ub150\uc801\uc73c\ub85c, FunctionCounts\ub294 \uac01 \uc30d(pair)\uc774 `(\uba85\ub839\uc5b4 \ud638\ucd9c \ud69f\uc218, \ud30c\uc77c \uacbd\ub85c \ubc0f \ud568\uc218 \uc774\ub984)`\n\uc778 \ud615\ud0dc\ub85c \uad6c\uc131\ub41c, \uc720\uc6a9\ud55c \uba54\uc11c\ub4dc(utility method)\uac00 \uc788\ub294 \uc30d(pair)\uc758 \ud29c\ud50c(tuple)\ub85c\n\uc0dd\uac01\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uacbd\ub85c(path)\uc5d0 \ub300\ud55c \ucc38\uace0 \uc0ac\ud56d:\n  \uc77c\ubc18\uc801\uc73c\ub85c \uc808\ub300\uacbd\ub85c(absolute path)\ub294 \uc2e0\uacbd\uc4f0\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \uacf1\ud558\uae30 \ud638\ucd9c\uc758\n  \uc804\uccb4 \uacbd\ub85c\uc640 \ud568\uc218 \uc774\ub984\uc740 \uc774\ub7f0 \uc2dd\uc77c \uac83\uc785\ub2c8\ub2e4:\n\n      /the/prefix/to/your/pytorch/install/dir/pytorch/build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const&) const [/the/path/to/your/conda/install/miniconda3/envs/ab_ref/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so]\n\n  \uc2e4\uc81c\ub85c \uc6b0\ub9ac\uac00 \uad00\uc2ec\uc744 \uac16\ub294 \uc815\ubcf4\ub4e4\uc740 \uc774\ub7f0 \uc2dd\uc73c\ub85c \ud45c\ud604\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4:\n\n      build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const&) const\n\n  CallgrindStats.as_standardized()\ub294 \ud30c\uc77c \uacbd\ub85c\uc758 \uc758\ubbf8\uc5c6\ub294 \ubd80\ubd84(low signal portion)\ubfd0\ub9cc\n  \uc544\ub2c8\ub77c, \uacf5\uc720 \uac1d\uccb4(shared object)\ub4e4\ub3c4 \uc81c\uac70(strip)\ud558\ub294\ub370 \ucd5c\uc120\uc744 \ub2e4\ud558\ubbc0\ub85c, \ub300\ubd80\ubd84\uc758 \uacbd\uc6b0\n  \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \uad8c\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inclusive_stats = stats.as_standardized().stats(inclusive=False)\nprint(inclusive_stats[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **C++ Callgrind stats (detailed)**\n\n        torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192a6dfd90>\n          47264  ???:_int_free\n          25963  ???:_int_malloc\n          19900  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&)\n          18000  ???:__tls_get_addr\n          13500  ???:malloc\n          11300  build/../c10/util/SmallVector.h:a ... (at::TensorIteratorConfig const&)\n          10345  ???:_int_memalign\n          10000  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&)\n           9200  ???:free\n           8000  build/../c10/util/SmallVector.h:a ... IteratorBase::get_strides() const\n\n        Total: 173472\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \uc678\uc5d0\ub3c4 \uc694\uc57d\ud574\uc57c \ud560 \ub0b4\uc6a9\ub4e4\uc774 \ub9ce\uc2b5\ub2c8\ub2e4. `FunctionCounts.transform` \uba54\uc18c\ub4dc\ub97c\n\uc0ac\uc6a9\ud558\uc5ec \ud568\uc218 \uacbd\ub85c\uc758 \uc77c\ubd80\ub97c \uc790\ub974\uace0, \ud638\ucd9c\ub41c \ud568\uc218\ub97c \uc81c\uac70(discard)\ud569\ub2c8\ub2e4.\n\uadf8\ub807\uac8c \ud558\uba74 \uc911\ubcf5(collision, \uc608. `foo.h` \uc5d0 \uac19\uc774 \ub9e4\ud551\ub41c `foo.h:a()` \uc640 `foo.h:b()` )\ub41c\n\ud69f\uc218\ub294 \ub354\ud574\uc9d1\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport re\n\ndef group_by_file(fn_name: str):\n    if fn_name.startswith(\"???\"):\n        fn_dir, fn_file = fn_name.split(\":\")[:2]\n    else:\n        fn_dir, fn_file = os.path.split(fn_name.split(\":\")[0])\n        fn_dir = re.sub(\"^.*build/../\", \"\", fn_dir)\n        fn_dir = re.sub(\"^.*torch/\", \"torch/\", fn_dir)\n\n    return f\"{fn_dir:<15} {fn_file}\"\n\nprint(inclusive_stats.transform(group_by_file)[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **Callgrind stats (condensed)**\n\n        <torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750>\n          118200  aten/src/ATen   TensorIterator.cpp\n           65000  c10/util        SmallVector.h\n           47264  ???             _int_free\n           25963  ???             _int_malloc\n           20900  c10/util        intrusive_ptr.h\n           18000  ???             __tls_get_addr\n           15900  c10/core        TensorImpl.h\n           15100  c10/core        CPUAllocator.cpp\n           13500  ???             malloc\n           12500  c10/core        TensorImpl.cpp\n\n        Total: 352327\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Callgrind\ub97c \uc0ac\uc6a9\ud55c A/B \ud14c\uc2a4\ud2b8\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218 \uce21\uc815\uc758 \uac00\uc7a5 \uc720\uc6a9\ud55c \uae30\ub2a5 \uc911 \ud558\ub098\ub294 \uc131\ub2a5\uc744 \ubd84\uc11d\ud560 \ub54c\n\uc911\uc694\ud55c \uac83\uc73c\ub85c, \uc5f0\uc0b0\uc744 \uc138\ubc00\ud558\uac8c \ube44\uad50\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uc774\ub97c \uc2e4\uc81c\ub85c \ud655\uc778\ud574\ubcf4\uae30 \uc704\ud574, \ud150\uc11c(Tensor)\ub97c \ube0c\ub85c\ub4dc\uce90\uc2a4\ud2b8(broadcast)\ud558\uc5ec\n128 \ud06c\uae30\uc758 \ud150\uc11c(Tensor)\uc640 \uacf1\ud558\ub294 {128} x {1} \uacf1\uc148\uacfc \ube44\uad50\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n  result = {a0 * b0, a1 * b0, ..., a127 * b0}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "broadcasting_stats = Timer(\n    \"x * y;\",\n    \"\"\"\n        auto x = torch::ones({128});\n        auto y = torch::ones({1});\n    \"\"\",\n    language=Language.CPP,\n).collect_callgrind().as_standardized().stats(inclusive=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc885\uc885 \uc11c\ub85c \ub2e4\ub978 \ub450 \ud658\uacbd\uc5d0\uc11c A/B \ud14c\uc2a4\ud2b8\ub97c \uc9c4\ud589\ud558\uace0 \uc2f6\uc744 \ub54c\uac00 \uc788\uc2b5\ub2c8\ub2e4. (\uc608.\nPR\uc744 \ud14c\uc2a4\ud2b8\ud558\uac70\ub098, \ucef4\ud30c\uc77c \ud50c\ub798\uadf8(flag) \uc2e4\ud5d8 \ub4f1)\n\uc774\ub294 CallgrindStats\uc640 FunctionCounts, Measurement\ub294 \ubaa8\ub450 pickle\ud654(picklalbe)\uac00\n\uac00\ub2a5\ud558\uae30 \ub54c\ubb38\uc5d0 \ub9e4\uc6b0 \uac04\ub2e8\ud569\ub2c8\ub2e4. \uac01 \ud658\uacbd\uc5d0\uc11c \uce21\uc815\ud55c \uacb0\uacfc\ub4e4\uc744 \uc800\uc7a5\ud558\uace0, \ub2e8\uc77c\n\ud504\ub85c\uc138\uc2a4\uc5d0\uc11c \ubd88\ub7ec\uc640\uc11c \ubd84\uc11d\ud558\uae30\ub9cc \ud558\uba74 \ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n\n# \uac00\ub2a5\ud558\ub2e4\ub294 \uac83\uc744 \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574 `broadcasting_stats` \uc744 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc635\ub2c8\ub2e4.\nbroadcasting_stats = pickle.loads(pickle.dumps(broadcasting_stats))\n\n\n# \ub450 \uc791\uc5c5\uc744 \ube44\uad50\ud569\ub2c8\ub2e4:\ndelta = broadcasting_stats - inclusive_stats\n\ndef extract_fn_name(fn: str):\n    \"\"\"Trim everything except the function name.\"\"\"\n    fn = \":\".join(fn.split(\":\")[1:])\n    return re.sub(r\"\\(.+\\)\", \"(...)\", fn)\n\n# `.transform` \uc744 \uc0ac\uc6a9\ud558\uc5ec diff\ub97c \uc77d\uc744 \uc218 \uc788\uac8c \ub9cc\ub4ed\ub2c8\ub2e4:\nprint(delta.transform(extract_fn_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **Instruction count delta**\n\n        <torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750>\n            17600  at::TensorIteratorBase::compute_strides(...)\n            12700  at::TensorIteratorBase::allocate_or_resize_outputs()\n            10200  c10::SmallVectorImpl<long>::operator=(...)\n             7400  at::infer_size(...)\n             6200  at::TensorIteratorBase::invert_perm(...) const\n             6064  _int_free\n             5100  at::TensorIteratorBase::reorder_dimensions()\n             4300  malloc\n             4300  at::TensorIteratorBase::compatible_stride(...) const\n              ...\n              -28  _int_memalign\n             -100  c10::impl::check_tensor_options_and_extract_memory_format(...)\n             -300  __memcmp_avx2_movbe\n             -400  at::detail::empty_cpu(...)\n            -1100  at::TensorIteratorBase::numel() const\n            -1300  void at::native::(...)\n            -2400  c10::TensorImpl::is_contiguous(...) const\n            -6100  at::TensorIteratorBase::compute_fast_setup_type(...)\n           -22600  at::TensorIteratorBase::fast_set_up(...)\n\n        Total: 58091\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ube0c\ub85c\ub4dc\uce90\uc2a4\ud305\ud588\ub358 \ubc84\uc804\uc740 \ud638\ucd9c\ub2f9(\uc0d8\ud50c \ub2f9 100\ubc88\uc758 \uc2e4\ud589\uc744 \uc218\uc9d1\ud558\uc600\uc74c\uc744 \uae30\uc5b5\ud558\uc138\uc694)\n580\ubc88, \ub300\ub7b5 10%\ub9cc\ud07c \uba85\ub839\uc5b4\uac00 \ub354 \uc2e4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. TensorIterator \ud638\ucd9c\uc774 \uc81c\ubc95 \ub9ce\uc73c\ubbc0\ub85c\n\uc870\uae08 \ub354 \uae4a\uc774 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. FunctionCounts.filter\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ub97c \uc27d\uac8c \uc218\ud589\ud560 \uc218\n\uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(delta.transform(extract_fn_name).filter(lambda fn: \"TensorIterator\" in fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: **Instruction count delta (filter)**\n\n        <torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f19299544d0>\n            17600  at::TensorIteratorBase::compute_strides(...)\n            12700  at::TensorIteratorBase::allocate_or_resize_outputs()\n             6200  at::TensorIteratorBase::invert_perm(...) const\n             5100  at::TensorIteratorBase::reorder_dimensions()\n             4300  at::TensorIteratorBase::compatible_stride(...) const\n             4000  at::TensorIteratorBase::compute_shape(...)\n             2300  at::TensorIteratorBase::coalesce_dimensions()\n             1600  at::TensorIteratorBase::build(...)\n            -1100  at::TensorIteratorBase::numel() const\n            -6100  at::TensorIteratorBase::compute_fast_setup_type(...)\n           -22600  at::TensorIteratorBase::fast_set_up(...)\n\n        Total: 24000\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\ub807\uac8c \ubcf4\uba74 \uc9c4\ud589 \ub0b4\uc5ed\uc774 \uba85\ud655\ud569\ub2c8\ub2e4:TensorIterator \uad6c\uc131(setup) \uc2dc \ub354 \ube60\ub978 \uacbd\ub85c\uac00\n\uc788\uc9c0\ub9cc, {128} x {1} \uacbd\uc6b0\uc5d0\ub294 \uc774\uac83\uc774 \uc544\ub2cc \ub354 \ube44\uc6a9\uc774 \ub9ce\uc774 \ub4dc\ub294 \uc77c\ubc18\uc801\uc778 \ubd84\uc11d\uc744\n\uc218\ud589\ud574\uc57c \ud569\ub2c8\ub2e4. \ud544\ud130\uc5d0\uc11c \uc0dd\ub7b5(omit)\ub41c \uac00\uc7a5 \uc8fc\uc694\ud55c \ud638\ucd9c\uc740\n`c10::SmallVectorImpl<long>::operator=(...)` \uc73c\ub85c, \uc77c\ubc18\uc801\uc778 \uad6c\uc131(setup)\uc758 \uc77c\ubd80\n\uc774\uae30\ub3c4 \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. \ub9c8\ubb34\ub9ac\n~~~~~~~~~~~~~~\n\n\uc694\uc57d\ud558\uba74 `Timer.blocked_autorange` \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\uc81c \uc2e4\ud589 \uc2dc\uac04(wall time)\uc744 \uc218\uc9d1\ud569\ub2c8\ub2e4.\n\uc2dc\uac04 \ud3b8\ucc28\uac00 \ub108\ubb34 \ud06c\uba74, `min_run_time` \uc744 \ub298\ub9ac\uac70\ub098, \ub9cc\uc57d C++\uc774 \ub354 \ud3b8\ud558\uba74 C++ \ucf54\ub4dc\n\uc870\uac01\uc744 \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4.\n\n\uc138\ubd84\ud654\ub41c \ubd84\uc11d\uc744 \uc704\ud574, `Timer.collect_callgrind` \ub97c \uc0ac\uc6a9\ud558\uc5ec \uba85\ub839\uc5b4 \uc2e4\ud589 \ud69f\uc218\ub97c\n\uce21\uc815\ud558\uace0 `FunctionCounts.(__add__ / __sub__ / transform / filter)` \ub97c \uc0ac\uc6a9\ud558\uc5ec\n\uacb0\uacfc\ub97c \ucabc\uac1c\uc5b4 \ubd84\uc11d(slice-and-dice)\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. \uac01\uc8fc\n~~~~~~~~~~~~\n\n  - \ubb35\uc2dc\uc801(implied) `import torch`\n      `globals` \uac00 \"torch\"\ub97c \ud3ec\ud568\ud558\uc9c0 \uc54a\uc73c\uba74, Timer\uac00 \uc790\ub3d9\uc73c\ub85c \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n      \uc989, `Timer(\"torch.empty(())\")` \uac00 \ub3d9\uc791\ud569\ub2c8\ub2e4. (\ub2e4\ub978 \ubd88\ub7ec\uc624\uae30(import)\n      \ub294 \ubc18\ub4dc\uc2dc `setup` \uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4 -\n      \uc608. `Timer(\"np.zeros(())\", \"import numpy as np\")` )\n\n  - REL_WITH_DEB_INFO\n      \uc2e4\ud589\ub418\ub294 PyTorch \ub0b4\ubd80\uc5d0 \ub300\ud55c \uc804\uccb4 \uc815\ubcf4\ub97c \uc81c\uacf5\ud558\uae30 \uc704\ud574, Callgrind\ub294\n      C++ \ub514\ubc84\uadf8 \uc2ec\ubcfc(debug symbol)\uc5d0 \uc811\uadfc\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574 PyTorch\ub97c\n      \ube4c\ub4dc\ud560 \ub54c REL_WITH_DEB_INFO=1 \uc744 \uc124\uc815\ud574\uc57c \ud569\ub2c8\ub2e4. \uadf8\ub807\uc9c0 \uc54a\uc73c\uba74\n      \ud568\uc218 \ud638\ucd9c\uc774 \ubd88\ud22c\uba85(opaque)\ud574\uc9d1\ub2c8\ub2e4. (\uc774\ub7f0 \uacbd\uc6b0 CallgrindStats\uac00\n      \ub514\ubc84\uadf8 \uc2ec\ubcfc \ub204\ub77d\uc744 \uacbd\uace0\ud569\ub2c8\ub2e4.)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}