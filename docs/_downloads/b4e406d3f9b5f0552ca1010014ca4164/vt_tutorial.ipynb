{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\ubc30\ud3ec\ub97c \uc704\ud55c \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38(Vision Transformer) \ubaa8\ub378 \ucd5c\uc801\ud654\ud558\uae30\n=================================================================\nAuthors : `Jeff Tang <https://github.com/jeffxtang>`_, `Geeta Chauhan <https://github.com/gchauhan/>`_\n\ubc88\uc5ed : `\uae40\ud0dc\uc601 <https://github.com/Taeyoung96/>`_\n\n\ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38(Vision Transformer)\ub294 \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ubd84\uc57c\uc5d0\uc11c \uc18c\uac1c\ub41c\n\ucd5c\uace0 \uc218\uc900\uc758 \uacb0\uacfc\ub97c \ub2ec\uc131\ud55c \ucd5c\uc2e0\uc758 \uc5b4\ud150\uc158 \uae30\ubc18(attention-based) \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc744\n\ucef4\ud4e8\ud130 \ube44\uc804 \ubd84\uc57c\uc5d0 \uc801\uc6a9\uc744 \ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4.\nFaceBook\uc5d0\uc11c \ubc1c\ud45c\ud55c Data-efficient Image Transformers\ub294 `DeiT <https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification>`_\n\uc774\ubbf8\uc9c0 \ubd84\ub958\ub97c \uc704\ud574 ImageNet \ub370\uc774\ud130\uc14b\uc744 \ud1b5\ud574 \ud6c8\ub828\ub41c\n\ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc785\ub2c8\ub2e4.\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294, DeiT\uac00 \ubb34\uc5c7\uc778\uc9c0 \uadf8\ub9ac\uace0 \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ud558\ub294\uc9c0 \ub2e4\ub8f0 \uac83\uc785\ub2c8\ub2e4.\n\uadf8 \ub2e4\uc74c \uc2a4\ud06c\ub9bd\ud305, \uc591\uc790\ud654, \ucd5c\uc801\ud654, \uadf8\ub9ac\uace0 iOS\uc640 \uc548\ub4dc\ub85c\uc774\ub4dc \uc571 \uc548\uc5d0\uc11c\n\ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \uc804\uccb4\uc801\uc778 \ub2e8\uacc4\ub97c \uc218\ud589\ud574 \ubcfc \uac83\uc785\ub2c8\ub2e4.\n\ub610\ud55c, \uc591\uc790\ud654\uc640 \ucd5c\uc801\ud654\uac00 \ub41c \ubaa8\ub378\uacfc \uc591\uc790\ud654\uc640 \ucd5c\uc801\ud654\uac00 \ub418\uc9c0 \uc54a\uc740 \ubaa8\ub378\uc744 \ube44\uad50\ud574 \ubcfc \uac83\uc774\uba70,\n\ub2e8\uacc4\ub97c \uc218\ud589\ud574 \uac00\uba74\uc11c \uc591\uc790\ud654\uc640 \ucd5c\uc801\ud654\ub97c \uc801\uc6a9\ud55c \ubaa8\ub378\uc774 \uc5bc\ub9c8\ub098 \uc774\uc810\uc744 \uac00\uc9c0\ub294\uc9c0 \ubcfc \uac83\uc785\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DeiT\ub780 \ubb34\uc5c7\uc778\uac00\n--------------------\n\n\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd(CNNs)\uc740 2012\ub144 \ub525\ub7ec\ub2dd\uc774 \uc2dc\uc791\ub41c \uc774\ud6c4\n\uc774\ubbf8\uc9c0 \ubd84\ub958\ub97c \uc218\ud589\ud560 \ub54c \uc8fc\uc694\ud55c \ubaa8\ub378\uc774\uc600\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc740 \uc77c\ubc18\uc801\uc73c\ub85c\n\ucd5c\ucca8\ub2e8\uc758 \uacb0\uacfc\ub97c \ub2ec\uc131\ud558\uae30 \uc704\ud574 \ud6c8\ub828\uc5d0 \uc218\uc5b5 \uac1c\uc758 \uc774\ubbf8\uc9c0\uac00 \ud544\uc694\ud588\uc2b5\ub2c8\ub2e4.\nDeiT\ub294 \ud6c8\ub828\uc5d0 \ub354 \uc801\uc740 \ub370\uc774\ud130\uc640 \ucef4\ud4e8\ud305 \uc790\uc6d0\uc744 \ud544\uc694\ub85c \ud558\ub294 \ube44\uc804 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc774\uba70,\n\ucd5c\uc2e0 CNN \ubaa8\ub378\uacfc \uc774\ubbf8\uc9c0 \ubd84\ub958\ub97c \uc218\ud589\ud558\ub294\ub370 \uacbd\uc7c1\uc744 \ud569\ub2c8\ub2e4.\n\uc774\ub294 DeiT\uc758 \ub450 \uac00\uc9c0 \uc8fc\uc694 \uad6c\uc131 \uc694\uc18c\uc5d0 \uc758\ud574 \uac00\ub2a5\ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n-  \ud6e8\uc52c \ub354 \ud070 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud55c \ud6c8\ub828\uc744 \uc2dc\ubbac\ub808\uc774\uc158\ud558\ub294 \ub370\uc774\ud130 \uc99d\uac15(augmentation)\n-  \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ub124\ud2b8\uc6cc\ud06c\uc5d0 CNN\uc758 \ucd9c\ub825\uac12\uc744 \uadf8\ub300\ub85c \uc99d\ub958(distillation)\ud558\uc5ec \ud559\uc2b5\ud560 \uc218 \uc788\ub3c4\ub85d \ud558\ub294 \uae30\ubc95\n\nDeiT\ub294 \uc81c\ud55c\ub41c \ub370\uc774\ud130\uc640 \uc790\uc6d0\uc744 \ud65c\uc6a9\ud558\uc5ec \ucef4\ud4e8\ud130 \ube44\uc804 \ud0dc\uc2a4\ud06c(task)\uc5d0 \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc744\n\uc131\uacf5\uc801\uc73c\ub85c \uc801\uc6a9\ud560 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\nDeiT\uc758 \uc880 \ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc744 \uc6d0\ud55c\ub2e4\uba74, `\uc800\uc7a5\uc18c <https://github.com/facebookresearch/deit>`_\n\uc640 `\ub17c\ubb38 <https://arxiv.org/abs/2012.12877>`_ \uc744 \ucc38\uace0\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DeiT\ub97c \ud65c\uc6a9\ud55c \uc774\ubbf8\uc9c0 \ubd84\ub958\n-------------------------------\n\nDeiT\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub294 DeiT \uc800\uc7a5\uc18c\uc5d0 README\ub97c \ucc38\uace0\ud558\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.\n\ube60\ub978 \ud14c\uc2a4\ud2b8\ub97c \uc704\ud574\uc11c, \uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub4e4\uc744\n\uc124\uce58\ud569\ub2c8\ub2e4:\n\npip install torch torchvision timm pandas requests\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Google Colab\uc5d0\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc2e4\ud589\ud569\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install timm pandas requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uadf8\ub7f0 \ub2e4\uc74c \uc544\ub798 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc2e4\ud589\ud569\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nimport torch\nimport timm\nimport requests\nimport torchvision.transforms as transforms\nfrom timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\nprint(torch.__version__)\n# Pytorch \ubc84\uc804\uc740 1.8.0 \uc774\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n\n\nmodel = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.Resize(256, interpolation=3),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n])\n\nimg = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\nimg = transform(img)[None,]\nout = model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ImageNet \ubaa9\ub85d\uc5d0 \ub530\ub77c `\ub77c\ubca8(labels) \ud30c\uc77c <https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a>`_\n\ud074\ub798\uc2a4 \uc778\ub371\uc2a4\uc758 \ucd9c\ub825\uc740 269\uc5ec\uc57c \ud558\uba70, \uc774\ub294 \u2018timber wolf, grey wolf, gray wolf, Canis lupus\u2019\uc5d0 \ub9e4\ud551\ub429\ub2c8\ub2e4.\n\n\uc774\uc81c DeiT \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\ub4e4\uc744 \ubd84\ub958\ud560 \uc218 \uc788\uc74c\uc744 \ud655\uc778\ud588\uc2b5\ub2c8\ub2e4.\niOS \ubc0f Android \uc571\uc5d0\uc11c \uc2e4\ud589\ud560 \uc218 \uc788\ub3c4\ub85d \ubaa8\ub378\uc744 \uc218\uc815\ud558\ub294 \ubc29\ubc95\uc744 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DeiT \uc2a4\ud06c\ub9bd\ud305\n----------------------\n\ubaa8\ubc14\uc77c\uc5d0\uc11c \uc774 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub824\uba74, \uc6b0\ub9ac\ub294 \uccab\ubc88\uc9f8\ub85c \ubaa8\ub378 \uc2a4\ud06c\ub9bd\ud305\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.\n\uc804\uccb4\uc801\uc778 \uac1c\uc694\ub294 `\uc2a4\ud06c\ub9bd\ud2b8 \uadf8\ub9ac\uace0 \ucd5c\uc801\ud654 \ub808\uc2dc\ud53c <https://tutorials.pytorch.kr/recipes/script_optimized.html>`_\n\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798 \ucf54\ub4dc\ub97c \uc2e4\ud589\ud558\uc5ec \uc774\uc804 \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ud55c DeiT \ubaa8\ub378\uc744\n\ubaa8\ubc14\uc77c\uc5d0\uc11c \uc2e4\ud589\ud560 \uc218 \uc788\ub294 TorchScript \ud615\uc2dd\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\nmodel.eval()\nscripted_model = torch.jit.script(model)\nscripted_model.save(\"fbdeit_scripted.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc57d 346MB \ud06c\uae30\uc758 \uc2a4\ud06c\ub9bd\ud305\ub41c \ubaa8\ub378 \ud30c\uc77c fbdeit_scripted.pt\uac00 \uc0dd\uc131\ub429\ub2c8\ub2e4.\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DeiT \uc591\uc790\ud654\n---------------------\n\ucd94\ub860 \uc815\ud655\ub3c4\ub97c \uac70\uc758 \ub3d9\uc77c\ud558\uac8c \uc720\uc9c0\ud558\uba74\uc11c \ud6c8\ub828\ub41c \ubaa8\ub378 \ud06c\uae30\ub97c \ud06c\uac8c \uc904\uc774\uae30 \uc704\ud574\n\ubaa8\ub378\uc5d0 \uc591\uc790\ud654\ub97c \uc801\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nDeiT\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378 \ub355\ubd84\uc5d0,\n\ubaa8\ub378\uc5d0 \ub3d9\uc801 \uc591\uc790\ud654\ub97c \uc27d\uac8c \uc801\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc65c\ub098\ud558\uba74 \ub3d9\uc801 \uc591\uc790\ud654\ub294 LSTM \ubaa8\ub378\uacfc \ud2b8\ub79c\uc2a4\ud3ec\uba38 \ubaa8\ub378\uc5d0\uc11c \uac00\uc7a5 \uc798 \uc801\uc6a9\ub418\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n(\uc790\uc138\ud55c \ub0b4\uc6a9\uc740 `\uc5ec\uae30 <https://pytorch.org/docs/stable/quantization.html?highlight=quantization#dynamic-quantization>`_\n\ub97c \ucc38\uace0\ud558\uc138\uc694.)\n\n\uc544\ub798\uc758 \ucf54\ub4dc\ub97c \uc2e4\ud589\uc2dc\ucf1c \ubd05\uc2dc\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc11c\ubc84 \ucd94\ub860\uc744 \uc704\ud574 'fbgemm'\uc744, \ubaa8\ubc14\uc77c \ucd94\ub860\uc744 \uc704\ud574 'qnnpack'\uc744 \uc0ac\uc6a9\ud574 \ubd05\uc2dc\ub2e4.\nbackend = \"fbgemm\" # \uc774 \uc8fc\ud53c\ud130 \ub178\ud2b8\ubd81\uc5d0\uc11c\ub294 \uc591\uc790\ud654\ub41c \ubaa8\ub378\uc758 \ub354 \ub290\ub9b0 \ucd94\ub860 \uc18d\ub3c4\ub97c \uc77c\uc73c\ud0a4\ub294 qnnpack\uc73c\ub85c \ub300\uccb4\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\nmodel.qconfig = torch.quantization.get_default_qconfig(backend)\ntorch.backends.quantized.engine = backend\n\nquantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\nscripted_quantized_model = torch.jit.script(quantized_model)\nscripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fbdeit_quantized_scripted.pt \ubaa8\ub378\uc758 \uc2a4\ud06c\ub9bd\ud305\uacfc \uc591\uc790\ud654\uac00 \uc801\uc6a9\ub41c \ubc84\uc804\uc774 \ub9cc\ub4e4\uc5b4\uc84c\uc2b5\ub2c8\ub2e4.\n\ubaa8\ub378\uc758 \ud06c\uae30\ub294 \ub2e8\uc9c0 89MB \uc785\ub2c8\ub2e4.\n\uc591\uc790\ud654\uac00 \uc801\uc6a9\ub418\uc9c0 \uc54a\uc740 \ubaa8\ub378\uc758 \ud06c\uae30\uc778 346MB\ubcf4\ub2e4 74%\ub098 \uac10\uc18c\ud588\uc2b5\ub2c8\ub2e4!\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub3d9\uc77c\ud55c \ucd94\ub860 \uacb0\uacfc\ub97c \ub9cc\ub4e4\uae30 \uc704\ud574 ``scripted_quantized_model`` \uc744\n\uc0ac\uc6a9\ud574 \ubd05\uc2dc\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = scripted_quantized_model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())\n# \ub3d9\uc77c\ud55c \ucd9c\ub825 \uacb0\uacfc\uc778 269\uac00 \ucd9c\ub825 \ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DeiT \ucd5c\uc801\ud654\n---------------------\n\ubaa8\ubc14\uc77c\uc5d0 \uc2a4\ud06c\ub9bd\ud2b8 \ub418\uace0 \uc591\uc790\ud654\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uae30 \uc704\ud55c\n\ub9c8\uc9c0\ub9c9 \ub2e8\uacc4\ub294 \ucd5c\uc801\ud654\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile\noptimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\noptimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc0dd\uc131\ub41c fbdeit_optimized_scripted_quantized.pt \ud30c\uc77c\uc740\n\uc591\uc790\ud654\ub418\uace0 \uc2a4\ud06c\ub9bd\ud2b8\ub418\uc9c0\ub9cc \ucd5c\uc801\ud654\ub418\uc9c0 \uc54a\uc740 \ubaa8\ub378\uacfc \ud06c\uae30\uac00 \uac70\uc758 \uac19\uc2b5\ub2c8\ub2e4.\n\ucd94\ub860 \uacb0\uacfc\ub294 \ub3d9\uc77c\ud558\uac8c \uc720\uc9c0\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = optimized_scripted_quantized_model(img)\nclsidx = torch.argmax(out)\nprint(clsidx.item())\n# \ub2e4\uc2dc \ud55c\ubc88, \ub3d9\uc77c\ud55c \ucd9c\ub825 \uacb0\uacfc\uc778 269\uac00 \ucd9c\ub825 \ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub77c\uc774\ud2b8 \uc778\ud130\ud504\ub9ac\ud130(Lite interpreter) \uc0ac\uc6a9\n-----------------------------------------\n\n\ub77c\uc774\ud2b8 \uc778\ud130\ud504\ub9ac\ud130\ub97c \uc0ac\uc6a9\ud558\uba74 \uc5bc\ub9c8\ub098 \ubaa8\ub378\uc758 \uc0ac\uc774\uc988\uac00 \uc791\uc544\uc9c0\uace0, \ucd94\ub860 \uc2dc\uac04\uc774 \uc9e7\uc544\uc9c0\ub294\uc9c0\n\uacb0\uacfc\ub97c \ud655\uc778\ud574 \ubd05\uc2dc\ub2e4. \uc774\uc81c \uc880 \ub354 \uac00\ubcbc\uc6b4 \ubc84\uc804\uc758 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4 \ubd05\uc2dc\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\nptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac00\ubcbc\uc6b4 \ubaa8\ub378\uc758 \ud06c\uae30\ub294 \uadf8\ub807\uc9c0 \uc54a\uc740 \ubc84\uc804\uc758 \ubaa8\ub378 \ud06c\uae30\uc640 \ube44\uc2b7\ud558\uc9c0\ub9cc,\n\ubaa8\ubc14\uc77c\uc5d0\uc11c \uac00\ubcbc\uc6b4 \ubc84\uc804\uc744 \uc2e4\ud589\ud558\uba74 \ucd94\ub860 \uc18d\ub3c4\uac00 \ube68\ub77c\uc9c8 \uac83\uc73c\ub85c \uc608\uc0c1\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucd94\ub860 \uc18d\ub3c4 \ube44\uad50\n---------------------------\n\n\ub124 \uac00\uc9c0 \ubaa8\ub378(\uc6d0\ubcf8 \ubaa8\ub378, \uc2a4\ud06c\ub9bd\ud2b8\ub41c \ubaa8\ub378, \uc2a4\ud06c\ub9bd\ud2b8\uc640 \uc591\uc790\ud654\ub97c \uc801\uc6a9\ud55c \ubaa8\ub378,\n\uc2a4\ud06c\ub9bd\ud2b8\uc640 \uc591\uc790\ud654\ub97c \uc801\uc6a9\ud55c \ud6c4 \ucd5c\uc801\ud654\ud55c \ubaa8\ub378)\uc758 \ucd94\ub860 \uc18d\ub3c4\uac00 \uc5b4\ub5bb\uac8c \ub2e4\ub978\uc9c0 \ud655\uc778\ud574 \ubd05\uc2dc\ub2e4.\n\n\uc544\ub798\uc758 \ucf54\ub4dc\ub97c \uc2e4\ud589\ud574 \ubd05\uc2dc\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n    out = model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof2:\n    out = scripted_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof3:\n    out = scripted_quantized_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof4:\n    out = optimized_scripted_quantized_model(img)\nwith torch.autograd.profiler.profile(use_cuda=False) as prof5:\n    out = ptl(img)\n\nprint(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\nprint(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\nprint(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\nprint(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\nprint(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Google Colab\uc5d0\uc11c \uc2e4\ud589 \uc2dc\ud0a8 \uacb0\uacfc\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n::\n\n   original model: 1236.69ms\n   scripted model: 1226.72ms\n   scripted & quantized model: 593.19ms\n   scripted & quantized & optimized model: 598.01ms\n   lite model: 600.72ms\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c \uacb0\uacfc\ub294 \uac01 \ubaa8\ub378\uc774 \uc18c\uc694\ud55c \ucd94\ub860 \uc2dc\uac04\uacfc\n\uc6d0\ubcf8 \ubaa8\ub378\uc5d0 \ub300\ud55c \uac01 \ubaa8\ub378\uc758 \uac10\uc18c\uc728\uc744 \uc694\uc57d\ud55c \uac83\uc785\ub2c8\ub2e4.\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'Model': ['original model','scripted model', 'scripted & quantized model', 'scripted & quantized & optimized model', 'lite model']})\ndf = pd.concat([df, pd.DataFrame([\n    [\"{:.2f}ms\".format(prof1.self_cpu_time_total/1000), \"0%\"],\n    [\"{:.2f}ms\".format(prof2.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof2.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof3.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof3.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof4.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof4.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n    [\"{:.2f}ms\".format(prof5.self_cpu_time_total/1000),\n     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof5.self_cpu_time_total)/prof1.self_cpu_time_total*100)]],\n    columns=['Inference Time', 'Reduction'])], axis=1)\n\nprint(df)\n\n\"\"\"\n        Model                             Inference Time    Reduction\n0\toriginal model                             1236.69ms           0%\n1\tscripted model                             1226.72ms        0.81%\n2\tscripted & quantized model                  593.19ms       52.03%\n3\tscripted & quantized & optimized model      598.01ms       51.64%\n4\tlite model                                  600.72ms       51.43%\n\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub354 \uc77d\uc744\uac70\ub9ac\n~~~~~~~~~~~~~~~~~\n\n- `Facebook Data-efficient Image Transformers <https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification>`__\n- `Vision Transformer with ImageNet and MNIST on iOS <https://github.com/pytorch/ios-demo-app/tree/master/ViT4MNIST>`__\n- `Vision Transformer with ImageNet and MNIST on Android <https://github.com/pytorch/android-demo-app/tree/master/ViT4MNIST>`__\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}