{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRay Tune\uc744 \uc774\uc6a9\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n===================================\n**\ubc88\uc5ed**: `\uc2ec\ud615\uc900 <http://github.com/95hj>`_\n\ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc740 \ubcf4\ud1b5\uc758 \ubaa8\ub378\uacfc \ub9e4\uc6b0 \uc815\ud655\ud55c \ubaa8\ub378\uac04\uc758 \ucc28\uc774\ub97c \ub9cc\ub4e4\uc5b4 \ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\uc885\uc885 \ub2e4\ub978 \ud559\uc2b5\ub960(Learnig rate)\uc744 \uc120\ud0dd\ud558\uac70\ub098 layer size\ub97c \ubcc0\uacbd\ud558\ub294 \uac83\uacfc \uac19\uc740 \uac04\ub2e8\ud55c \uc791\uc5c5\ub9cc\uc73c\ub85c\ub3c4 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\uae30\ub3c4 \ud569\ub2c8\ub2e4.\n\ub2e4\ud589\ud788, \ucd5c\uc801\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc870\ud569\uc744 \ucc3e\ub294\ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \ub3c4\uad6c\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n`Ray Tune <https://docs.ray.io/en/latest/tune.html>`_ \uc740 \ubd84\uc0b0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc744 \uc704\ud55c \uc5c5\uacc4 \ud45c\uc900 \ub3c4\uad6c\uc785\ub2c8\ub2e4. \nRay Tune\uc740 \ucd5c\uc2e0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac80\uc0c9 \uc54c\uace0\ub9ac\uc998\uc744 \ud3ec\ud568\ud558\uace0 TensorBoard \ubc0f \uae30\ud0c0 \ubd84\uc11d \ub77c\uc774\ube0c\ub7ec\ub9ac\uc640 \ud1b5\ud569\ub418\uba70 \uae30\ubcf8\uc801\uc73c\ub85c\n`Ray' \uc758 \ubd84\uc0b0 \uae30\uacc4 \ud559\uc2b5 \uc5d4\uc9c4\n<https://ray.io/>`_ \uc744 \ud1b5\ud574 \uad50\uc721\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 Ray Tune\uc744 \ud30c\uc774\ud1a0\uce58 \ud559\uc2b5 workflow\uc5d0 \ud1b5\ud569\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\ub824\uc90d\ub2c8\ub2e4.\nCIFAR10 \uc774\ubbf8\uc9c0 \ubd84\ub958\uae30\ub97c \ud6c8\ub828\ud558\uae30 \uc704\ud574 `\ud30c\uc774\ud1a0\uce58 \ubb38\uc11c\uc5d0\uc11c \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 <https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html>`_ \ud655\uc7a5\ud560 \uac83\uc785\ub2c8\ub2e4.\n\uc544\ub798\uc640 \uac19\uc774 \uc57d\uac04\uc758 \uc218\uc815\ub9cc \ucd94\uac00\ud558\uba74 \ub429\ub2c8\ub2e4.\n1. \ud568\uc218\uc5d0\uc11c \ub370\uc774\ud130 \ub85c\ub529 \ubc0f \ud559\uc2b5 \ubd80\ubd84\uc744 \uac10\uc2f8\ub450\uace0,\n2. \uc77c\ubd80 \ub124\ud2b8\uc6cc\ud06c \ud30c\ub77c\ubbf8\ud130\ub97c \uad6c\uc131 \uac00\ub2a5\ud558\uac8c \ud558\uace0,\n3. \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \ucd94\uac00\ud558\uace0 (\uc120\ud0dd \uc0ac\ud56d),\n4. \ubaa8\ub378 \ud29c\ub2dd\uc744 \uc704\ud55c \uac80\uc0c9 \uacf5\uac04\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n|\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud574 \uc544\ub798\uc758 \ud328\ud0a4\uc9c0\uac00 \uc124\uce58\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\ud558\uc2ed\uc2dc\uc624.\n-  ``ray[tune]``: \ubc30\ud3ec\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\n-  ``torchvision``: \ub370\uc774\ud130 \ud2b8\ub79c\uc2a4\ud3ec\uba38\uc758 \uacbd\uc6b0\n\uc124\uc815 / Imports\n---------------\nimport\ub4e4\ub85c \uc2dc\uc791\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\nimport numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nimport torchvision\nimport torchvision.transforms as transforms\nfrom ray import tune\nfrom ray.tune import CLIReporter\nfrom ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub300\ubd80\ubd84\uc758 import\ub4e4\uc740 \ud30c\uc774\ud1a0\uce58 \ubaa8\ub378\uc744 \ube4c\ub4dc\ud558\ub294\ub370 \ud544\uc694\ud569\ub2c8\ub2e4. \n\ub9c8\uc9c0\ub9c9 \uc138 \uac1c\uc758 import\ub4e4\ub9cc Ray Tune\uc744 \uc0ac\uc6a9\ud558\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4.\n\nData loaders\n------------\ndata loader\ub97c \uc790\uccb4 \ud568\uc218\ub85c \uac10\uc2f8\ub450\uace0 \uc804\uc5ed \ub370\uc774\ud130 \ub514\ub809\ud1a0\ub9ac\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4. \n\uc774\ub7f0 \uc2dd\uc73c\ub85c \uc11c\ub85c \ub2e4\ub978 \uc2e4\ud5d8\ub4e4 \uac04\uc5d0 \ub370\uc774\ud130 \ub514\ub809\ud1a0\ub9ac\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=True, download=True, transform=transform)\n\n    testset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uad6c\uc131 \uac00\ub2a5\ud55c \uc2e0\uacbd\ub9dd\n---------------------------\n\uad6c\uc131 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub9cc \ud29c\ub2dd\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4. \n\uc774 \uc608\uc2dc\ub97c \ud1b5\ud574 fully connected layer \ud06c\uae30\ub97c \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self, l1=120, l2=84):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n        self.fc2 = nn.Linear(l1, l2)\n        self.fc3 = nn.Linear(l2, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ud568\uc218\n------------------\n\ud765\ubbf8\ub86d\uac8c \ud558\uae30 \uc704\ud574 `\ud30c\uc774\ud1a0\uce58 \ubb38\uc11c\uc5d0\uc11c <https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html>`_ \n\uc608\uc81c\uc5d0 \uc77c\ubd80\ub97c \ubcc0\uacbd\ud558\uc5ec \uc18c\uac1c\ud569\ub2c8\ub2e4.\n\n\ud6c8\ub828 \uc2a4\ud06c\ub9bd\ud2b8\ub97c ``train_cifar(config, checkpoint_dir=None, data_dir=None)`` \ud568\uc218\ub85c \uac10\uc2f8\ub461\ub2c8\ub2e4. \n\uc9d0\uc791\ud560 \uc218 \uc788\ub4ef\uc774, ``config`` \ub9e4\uac1c\ubcc0\uc218\ub294 \ud6c8\ub828\ud560 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ubc1b\uc2b5\ub2c8\ub2e4. ``checkpoint_dir`` \ub9e4\uac1c\ubcc0\uc218\ub294 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c\n\ubcf5\uc6d0\ud558\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. ``data_dir`` \uc740 \ub370\uc774\ud130\ub97c \uc77d\uace0 \uc800\uc7a5\ud558\ub294 \ub514\ub809\ud1a0\ub9ac\ub97c \uc9c0\uc815\ud558\ubbc0\ub85c, \n\uc5ec\ub7ec \uc2e4\ud589\ub4e4\uc774 \ub3d9\uc77c\ud55c \ub370\uc774\ud130 \uc18c\uc2a4\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    net = Net(config[\"l1\"], config[\"l2\"])\n\n    if checkpoint_dir:\n        model_state, optimizer_state = torch.load(\n            os.path.join(checkpoint_dir, \"checkpoint\"))\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n\ub610\ud55c, \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \ud559\uc2b5\ub960(learning rate)\uc744 \uad6c\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n\ub610\ud55c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ud559\uc2b5 \ubc0f \uac80\uc99d \uc138\ud2b8\ub85c \ub098\ub215\ub2c8\ub2e4. \ub530\ub77c\uc11c \ub370\uc774\ud130\uc758 80%\ub294 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud558\uace0, \n\ub098\uba38\uc9c0 20%\uc5d0 \ub300\ud574 \uc720\ud6a8\uc131 \uac80\uc0ac \ubc0f \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub97c \ubc18\ubcf5\ud558\ub294 \ubc30\uce58 \ud06c\uae30\ub3c4 \uad6c\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nDataParallel\uc744 \uc774\uc6a9\ud55c GPU(\ub2e4\uc911)\uc9c0\uc6d0 \ucd94\uac00\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\uc774\ubbf8\uc9c0 \ubd84\ub958\ub294 GPU\ub97c \uc0ac\uc6a9\ud560 \ub54c \uc774\uc810\uc774 \ub9ce\uc2b5\ub2c8\ub2e4. \uc6b4\uc88b\uac8c\ub3c4 Ray Tune\uc5d0\uc11c \ud30c\uc774\ud1a0\uce58\uc758 \ucd94\uc0c1\ud654\ub97c \uacc4\uc18d \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\ub530\ub77c\uc11c \uc5ec\ub7ec GPU\uc5d0\uc11c \ub370\uc774\ud130 \ubcd1\ub82c \ud6c8\ub828\uc744 \uc9c0\uc6d0\ud558\uae30 \uc704\ud574 \ubaa8\ub378\uc744 ``nn.DataParallel`` \uc73c\ub85c \uac10\uc300 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n``device`` \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc6a9 \uac00\ub2a5\ud55c GPU\uac00 \uc5c6\uc744 \ub54c\ub3c4 \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4. \n\ud30c\uc774\ud1a0\uce58\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \ub370\uc774\ud130\ub97c GPU\uba54\ubaa8\ub9ac\uc5d0 \uba85\uc2dc\uc801\uc73c\ub85c \ubcf4\ub0b4\ub3c4\ub85d \uc694\uad6c\ud569\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n\uc774 \ucf54\ub4dc\ub294 \uc774\uc81c CPU\ub4e4, \ub2e8\uc77c GPU \ubc0f \ub2e4\uc911 GPU\uc5d0 \ub300\ud55c \ud559\uc2b5\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. \n\ud2b9\ud788 Ray\ub294 `\ubd80\ubd84GPU <https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus>`_ \ub3c4 \uc9c0\uc6d0\ud558\ubbc0\ub85c \n\ubaa8\ub378\uc774 GPU \uba54\ubaa8\ub9ac\uc5d0 \uc801\ud569\ud55c \uc0c1\ud669\uc5d0\uc11c\ub294 \ud14c\uc2a4\ud2b8 \uac04\uc5d0 GPU\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub098\uc911\uc5d0 \ub2e4\ub8f0 \uac83\uc785\ub2c8\ub2e4.\n\nRay Tune\uacfc \uc18c\ud1b5\ud558\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uac00\uc7a5 \ud765\ubbf8\ub85c\uc6b4 \ubd80\ubd84\uc740 Ray Tune\uacfc\uc758 \uc18c\ud1b5\uc785\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n        path = os.path.join(checkpoint_dir, \"checkpoint\")\n        torch.save((net.state_dict(), optimizer.state_dict()), path)\n\n    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n\n\uc5ec\uae30\uc11c \uba3c\uc800 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud55c \ub2e4\uc74c \uc77c\ubd80 \uba54\ud2b8\ub9ad\uc744 Ray Tune\uc5d0 \ub2e4\uc2dc \ubcf4\ub0c5\ub2c8\ub2e4. \ud2b9\ud788, validation loss\uc640 accuracy\ub97c \nRay Tune\uc73c\ub85c \ub2e4\uc2dc \ubcf4\ub0c5\ub2c8\ub2e4. \uadf8 \ud6c4 Ray Tune\uc740 \uc774\ub7ec\ud55c \uba54\ud2b8\ub9ad\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub97c \uc720\ub3c4\ud558\ub294 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uad6c\uc131\uc744 \n\uacb0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uba54\ud2b8\ub9ad\ub4e4\uc740 \ub610\ud55c \ub9ac\uc18c\uc2a4 \ub0ad\ube44\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \uc131\ub2a5\uc774 \uc88b\uc9c0 \uc54a\uc740 \uc2e4\ud5d8\uc744 \uc870\uae30\uc5d0 \uc911\uc9c0\ud558\ub294 \ub370 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\uc740 \uc120\ud0dd\uc0ac\ud56d\uc774\uc9c0\ub9cc `Population Based Training <https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html>`_ \n\uacfc \uac19\uc740 \uace0\uae09 \uc2a4\ucf00\uc904\ub7ec\ub97c \uc0ac\uc6a9\ud558\ub824\uba74 \ud544\uc694\ud569\ub2c8\ub2e4. \ub610\ud55c \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud558\uba74 \ub098\uc911\uc5d0 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub85c\ub4dc\ud558\uace0 \ud3c9\uac00 \uc138\ud2b8(test set)\uc5d0\uc11c \uac80\uc99d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nFull training function\n~~~~~~~~~~~~~~~~~~~~~~\n\n\uc804\uccb4 \ucf54\ub4dc \uc608\uc81c\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n    net = Net(config[\"l1\"], config[\"l2\"])\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    if checkpoint_dir:\n        model_state, optimizer_state = torch.load(\n            os.path.join(checkpoint_dir, \"checkpoint\"))\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs])\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n    valloader = torch.utils.data.DataLoader(\n        val_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n\n    for epoch in range(10):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n                                                running_loss / epoch_steps))\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n            path = os.path.join(checkpoint_dir, \"checkpoint\")\n            torch.save((net.state_dict(), optimizer.state_dict()), path)\n\n        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n    print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcf4\ub2e4\uc2dc\ud53c, \ub300\ubd80\ubd84\uc758 \ucf54\ub4dc\ub294 \uc6d0\ubcf8 \uc608\uc81c\uc5d0\uc11c \uc9c1\uc811 \uc801\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\nTest set \uc815\ud655\ub3c4(accuracy)\n-----------------\n\uc77c\ubc18\uc801\uc73c\ub85c \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud574 \ud14c\uc2a4\ud2b8\ud569\ub2c8\ub2e4. \nTest set \ub610\ud55c \ud568\uc218\ub85c \uac10\uc2f8\ub458 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2)\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ud568\uc218\ub294 \ub610\ud55c ``device`` \ud30c\ub77c\ubbf8\ud130\ub97c \uc694\uad6c\ud558\ubbc0\ub85c, test set \ud3c9\uac00\ub97c GPU\uc5d0\uc11c \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac80\uc0c9 \uacf5\uac04 \uad6c\uc131\n----------------------------\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c Ray Tune\uc758 \uac80\uc0c9 \uacf5\uac04\uc744 \uc815\uc758\ud574\uc57c \ud569\ub2c8\ub2e4. \uc608\uc2dc\ub294 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    config = {\n        \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n        \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16])\n    }\n\n``tune.sample_from()`` \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 \uace0\uc720\ud55c \uc0d8\ud50c \ubc29\ubc95\uc744 \uc815\uc758\ud558\uc5ec \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\uc774 \uc608\uc81c\uc5d0\uc11c ``l1`` \uacfc ``l2`` \ud30c\ub77c\ubbf8\ud130\ub294 4\uc640 256 \uc0ac\uc774\uc758 2\uc758 \uac70\ub4ed\uc81c\uacf1\uc774\uc5b4\uc57c \ud558\ubbc0\ub85c 4, 8, 16, 32, 64, 128, 256\uc785\ub2c8\ub2e4. \n``lr`` (\ud559\uc2b5\ub960)\uc740 0.0001\uacfc 0.1 \uc0ac\uc774\uc5d0\uc11c \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1 \ub418\uc5b4\uc544 \ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \ubc30\uce58 \ud06c\uae30\ub294 2, 4, 8, 16\uc911\uc5d0\uc11c \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac01 \uc2e4\ud5d8\uc5d0\uc11c, Ray Tune\uc740 \uc774\uc81c \uc774\ub7ec\ud55c \uac80\uc0c9 \uacf5\uac04\uc5d0\uc11c \ub9e4\uac1c\ubcc0\uc218 \uc870\ud569\uc744 \ubb34\uc791\uc704\ub85c \uc0d8\ud50c\ub9c1\ud569\ub2c8\ub2e4. \n\uadf8\ub7f0 \ub2e4\uc74c \uc5ec\ub7ec \ubaa8\ub378\uc744 \ubcd1\ub82c\ub85c \ud6c8\ub828\ud558\uace0 \uc774 \uc911\uc5d0\uc11c \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \ucc3e\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc131\ub2a5\uc774 \uc88b\uc9c0 \uc54a\uc740 \uc2e4\ud5d8\uc744 \uc870\uae30\uc5d0 \uc885\ub8cc\ud558\ub294 ``ASHAScheduler`` \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc0c1\uc218 ``data_dir`` \ud30c\ub77c\ubbf8\ud130\ub97c \uc124\uc815\ud558\uae30 \uc704\ud574 ``functools.partial`` \ub85c ``train_cifar`` \ud568\uc218\ub97c \uac10\uc2f8\ub461\ub2c8\ub2e4. \ub610\ud55c \uac01 \uc2e4\ud5d8\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uc790\uc6d0\ub4e4(resources)\uc744 Ray Tune\uc5d0 \uc54c\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. code-block:: python\n\n    gpus_per_trial = 2\n    # ...\n    result = tune.run(\n        partial(train_cifar, data_dir=data_dir),\n        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n        config=config,\n        num_samples=num_samples,\n        scheduler=scheduler,\n        progress_reporter=reporter,\n        checkpoint_at_end=True)\n\n\ud30c\uc774\ud1a0\uce58 ``DataLoader`` \uc778\uc2a4\ud134\uc2a4\uc758 ``num_workers`` \uc744 \ub298\ub9ac\uae30 \uc704\ud574 CPU \uc218\ub97c \uc9c0\uc815\ud558\uace0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\uac01 \uc2e4\ud5d8\uc5d0\uc11c \uc120\ud0dd\ud55c \uc218\uc758 GPU\ub4e4\uc740 \ud30c\uc774\ud1a0\uce58\uc5d0 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc2e4\ud5d8\ub4e4\uc740 \uc694\uccad\ub418\uc9c0 \uc54a\uc740 GPU\uc5d0 \uc561\uc138\uc2a4\ud560 \uc218 \uc5c6\uc73c\ubbc0\ub85c \uac19\uc740 \uc790\uc6d0\ub4e4\uc744 \uc0ac\uc6a9\ud558\ub294 \uc911\ubcf5\ub41c \uc2e4\ud5d8\uc5d0 \ub300\ud574 \uc2e0\uacbd\uc4f0\uc9c0 \uc54a\uc544\ub3c4 \ub429\ub2c8\ub2e4.\n\n\ubd80\ubd84 GPUs\ub97c \uc9c0\uc815\ud560 \uc218\ub3c4 \uc788\uc73c\ubbc0\ub85c, ``gpus_per_trial=0.5`` \uc640 \uac19\uc740 \uac83 \ub610\ud55c \uac00\ub2a5\ud569\ub2c8\ub2e4. \uc774\ud6c4 \uac01 \uc2e4\ud5d8\uc740 GPU\ub97c \uacf5\uc720\ud569\ub2c8\ub2e4. \uc0ac\uc6a9\uc790\ub294 \ubaa8\ub378\uc774 \uc5ec\uc804\ud788 GPU\uba54\ubaa8\ub9ac\uc5d0 \uc801\ud569\ud55c\uc9c0\ub9cc \ud655\uc778\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n\ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0a8 \ud6c4, \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \ucc3e\uace0 \uccb4\ud06c\ud3ec\uc778\ud2b8 \ud30c\uc77c\uc5d0\uc11c \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub85c\ub4dc\ud569\ub2c8\ub2e4. \uc774\ud6c4 test set \uc815\ud655\ub3c4(accuracy)\ub97c \uc5bb\uace0 \ubaa8\ub4e0 \uac83\ub4e4\uc744 \ucd9c\ub825\ud558\uc5ec \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc804\uccb4 \uc8fc\uc694 \uae30\ub2a5\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n    data_dir = os.path.abspath(\"./data\")\n    load_data(data_dir)\n    config = {\n        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16])\n    }\n    scheduler = ASHAScheduler(\n        metric=\"loss\",\n        mode=\"min\",\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2)\n    reporter = CLIReporter(\n        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n    result = tune.run(\n        partial(train_cifar, data_dir=data_dir),\n        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n        config=config,\n        num_samples=num_samples,\n        scheduler=scheduler,\n        progress_reporter=reporter)\n\n    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n    print(\"Best trial config: {}\".format(best_trial.config))\n    print(\"Best trial final validation loss: {}\".format(\n        best_trial.last_result[\"loss\"]))\n    print(\"Best trial final validation accuracy: {}\".format(\n        best_trial.last_result[\"accuracy\"]))\n\n    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if gpus_per_trial > 1:\n            best_trained_model = nn.DataParallel(best_trained_model)\n    best_trained_model.to(device)\n\n    best_checkpoint_dir = best_trial.checkpoint.value\n    model_state, optimizer_state = torch.load(os.path.join(\n        best_checkpoint_dir, \"checkpoint\"))\n    best_trained_model.load_state_dict(model_state)\n\n    test_acc = test_accuracy(best_trained_model, device)\n    print(\"Best trial test set accuracy: {}\".format(test_acc))\n\n\nif __name__ == \"__main__\":\n    # You can change the number of GPUs per trial here:\n    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucf54\ub4dc\ub97c \uc2e4\ud589\ud558\uba74 \uacb0\uacfc\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n::\n\n    Number of trials: 10 (10 TERMINATED)\n    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |\n    |-----+------+------+-------------+--------------+---------+------------+--------------------|\n    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |\n    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |\n    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |\n    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |\n    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |\n    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |\n    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |\n    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |\n    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |\n    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |\n    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n\n\n    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}\n    Best trial final validation loss: 1.181501\n    Best trial final validation accuracy: 0.5836\n    Best trial test set accuracy: 0.5806\n\n\ub300\ubd80\ubd84\uc758 \uc2e4\ud5d8\uc740 \uc790\uc6d0 \ub0ad\ube44\ub97c \ub9c9\uae30 \uc704\ud574 \uc77c\ucc0d \uc911\ub2e8\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\ub97c \uc5bb\uc740 \uc2e4\ud5d8\uc740 58%\uc758 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud588\uc73c\uba70, \uc774\ub294 \ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774\uac83\uc774 \uc804\ubd80\uc785\ub2c8\ub2e4! \uc774\uc81c \ud30c\uc774\ud1a0\uce58 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc870\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}