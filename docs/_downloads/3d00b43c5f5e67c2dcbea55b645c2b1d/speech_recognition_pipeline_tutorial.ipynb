{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nWav2Vec2\ub97c \uc774\uc6a9\ud574\uc11c \uc74c\uc131 \uc778\uc2dd\ud558\uae30\n=============================\n\n**\uc800\uc790**: `Moto Hira <moto@fb.com>`__\n\n**\ubc88\uc5ed**: `\uc7a5\ubcf4\uc724 <https://github.com/terri1102>`__\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 wav2vec 2.0\uc73c\ub85c \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc774\uc6a9\ud574\uc11c \uc5b4\ub5bb\uac8c \uc74c\uc131 \uc778\uc2dd\uc744 \n\uc218\ud589\ud558\ub294\uc9c0 \uc548\ub0b4\ud569\ub2c8\ub2e4. [`\ub17c\ubb38 <https://arxiv.org/abs/2006.11477>`__]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac1c\uc694\n-----\n\n\uc74c\uc131\uc778\uc2dd\uc740 \uc544\ub798\uc640 \uac19\uc740 \uacfc\uc815\uc73c\ub85c \uc9c4\ud589\ub429\ub2c8\ub2e4.\n\n1. \uc624\ub514\uc624 \ud30c\ud615\uc73c\ub85c\ubd80\ud130 \uc74c\ud5a5 \ud2b9\uc131\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4.\n\n2. \ud504\ub808\uc784\ubcc4\ub85c \uc74c\ud5a5 \ud2b9\uc131\uc758 \ud074\ub798\uc2a4\ub97c \ucd94\uc815\ud569\ub2c8\ub2e4.\n\n3. \ud074\ub798\uc2a4 \ud655\ub960\uc758 \uc2dc\ud000\uc2a4\uc5d0 \ub530\ub77c\uc11c \uac00\uc124\uc744 \uc124\ub9bd\ud569\ub2c8\ub2e4.\n\nTorchaudio\ub294 \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378 \uac00\uc911\uce58\uc640 \uae30\ub300 \uc0d8\ud50c\ub9c1 \ub808\uc774\ud2b8\ub098 \ud074\ub798\uc2a4 \ub77c\ubca8\uacfc \uac19\uc740 \n\uad00\ub828 \uc815\ubcf4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\ub7f0 \uc815\ubcf4\ub4e4\uc740 \n:py:func:`torchaudio.pipelines` \ubaa8\ub4c8\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc900\ube44\uc0ac\ud56d\n-------\n\n\uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub4e4\uc744 \ubd88\ub7ec\uc624\uace0 \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\ub97c \uac00\uc838\uc624\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n\nimport os\n\nimport IPython\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport requests\nimport torch\nimport torchaudio\n\nmatplotlib.rcParams[\"figure.figsize\"] = [16.0, 4.8]\n\ntorch.random.manual_seed(0)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(torch.__version__)\nprint(torchaudio.__version__)\nprint(device)\n\nSPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"  # noqa: E501\nSPEECH_FILE = \"_assets/speech.wav\"\n\nif not os.path.exists(SPEECH_FILE):\n    os.makedirs(\"_assets\", exist_ok=True)\n    with open(SPEECH_FILE, \"wb\") as file:\n        file.write(requests.get(SPEECH_URL).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud30c\uc774\ud504\ub77c\uc778 \uc0dd\uc131\ud558\uae30\n----------------\n\n\uba3c\uc800 \ud2b9\uc131 \ucd94\ucd9c\uacfc \ud074\ub798\uc2a4 \ubd84\ub958\ub97c \uc218\ud589\ud558\ub294 Wav2Vec2 \ubaa8\ub378\uc744 \uc0dd\uc131\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\nTorchaudio\uc5d0\ub294 \uc0ac\uc804 \ud559\uc2b5\ub41c Wav2Vec2 \ubaa8\ub378 \uac00\uc911\uce58\uac00 \ub450 \uc885\ub958 \uc788\uc2b5\ub2c8\ub2e4. \n\ud558\ub098\ub294 ASR \ud0dc\uc2a4\ud06c\ub97c \uc704\ud574 \ubbf8\uc138 \uc870\uc815\ub41c \uac00\uc911\uce58\uc774\uace0 \ub2e4\ub978 \ud558\ub098\ub294 \ubbf8\uc138 \uc870\uc815\ub418\uc9c0 \uc54a\uc740 \n\uac00\uc911\uce58\uc785\ub2c8\ub2e4.\n\nWav2Vec2 (\uadf8\ub9ac\uace0 HuBERT) \ubaa8\ub378\ub4e4\uc740 \uc790\uae30 \uc9c0\ub3c4 \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc774 \ubaa8\ub378\ub4e4\uc740 \uba3c\uc800\n\ud45c\ud604(representation)\uc744 \uc5bb\uae30 \uc704\ud574 \uc624\ub514\uc624 \ub370\uc774\ud130\ub9cc\uc73c\ub85c \ud559\uc2b5\ub418\uc5c8\uace0, \n\ud2b9\uc815\ud55c \ud0dc\uc2a4\ud06c\ub97c \uc704\ud574 \ub77c\ubca8\uc744 \ucd94\uac00\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n\ubbf8\uc138 \uc870\uc815\ub418\uc9c0 \uc54a\uc740 \uc0ac\uc804 \ud559\uc2b5\ub41c \uac00\uc911\uce58\ub294 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \ud0dc\uc2a4\ud06c\ub97c \uc704\ud574\uc11c \n\ubbf8\uc138 \uc870\uc815\ub420 \uc218 \uc788\uc9c0\ub9cc \uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \uc774 \ubd80\ubd84\uc5d0 \ub300\ud574 \ub2e4\ub8e8\uc9c0\ub294 \uc54a\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc740 \n:py:func:`torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H` \uc785\ub2c8\ub2e4.\n\n\uc774 \uc678\uc5d0\ub3c4 :py:mod:`torchaudio.pipelines` \uc5d0\ub294 \ub2e4\uc591\ud55c \ubaa8\ub378\ub4e4\uc774 \uc788\uc2b5\ub2c8\ub2e4. \n\ubaa8\ub378 \ud559\uc2b5\uc744 \uc704\ud55c \uc138\ubd80 \uc0ac\ud56d\uc740 \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n\uc544\ub798\uc758 \ucf54\ub4dc\uc5d0\uc11c \ubc88\ub4e4 \uac1d\uccb4(object)\ub294 \ubaa8\ub378\uc744 \uc0dd\uc131(instantiate)\ud558\uace0 \ub2e4\ub978 \uc815\ubcf4\ub97c \uc5bb\uae30 \uc704\ud55c \n\uc778\ud130\ud398\uc774\uc2a4\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\ub97c \uc774\uc6a9\ud574 \uc0d8\ud50c\ub9c1 \ub808\uc774\ud2b8\uc640 \ud074\ub798\uc2a4 \ub77c\ubca8\uc744 \ud655\uc778\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n\nprint(\"Sample Rate:\", bundle.sample_rate)\n\nprint(\"Labels:\", bundle.get_labels())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc740 \uc544\ub798\uc640 \uac19\uc774 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc744 \ud1b5\ud574 \uc0ac\uc804 \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c\n\uac00\uc838\uc640\uc11c \ubaa8\ub378\uc5d0 \ub123\uc5b4\uc90d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = bundle.get_model().to(device)\n\nprint(model.__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n--------------\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 Creative Commons 4.0 \ub77c\uc774\uc120\uc2a4\uc778 \n`VOiCES \ub370\uc774\ud130\uc14b <https://iqtlabs.github.io/voices/>`__ \uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(SPEECH_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\uae30 \uc704\ud574 :py:func:`torchaudio.load` \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\ub9cc\uc57d \ub370\uc774\ud130\uc758 \uc0d8\ud50c\ub9c1 \ub808\uc774\ud2b8\uac00 pipeline\uc5d0\uc11c \uae30\ub300\ud558\ub294 \uc0d8\ud50c\ub9c1 \ub808\uc774\ud2b8\uc640 \ub2e4\ub978 \uacbd\uc6b0 \n:py:func:`torchaudio.functional.resample` \uc744 \uc774\uc6a9\ud574\uc11c \ub9ac\uc0d8\ud50c\ub9c1\ud569\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>- :py:func:`torchaudio.functional.resample` \uc740 CUDA tensor\uc5d0\ub3c4 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n   - \uac19\uc740 \uc138\ud2b8\uc758 \uc0d8\ud50c\ub9c1 \ub808\uc774\ud2b8\uc5d0 \ub300\ud574 \uc5ec\ub7ec \ubc88 \ub9ac\uc0d8\ud50c\ub9c1\uc744 \uc218\ud589\ud560 \uacbd\uc6b0, \n     :py:func:`torchaudio.transforms.Resample` \ub97c \uc0ac\uc6a9\ud558\uba74 \uc131\ub2a5\uc774 \ub354 \uac1c\uc120\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "waveform, sample_rate = torchaudio.load(SPEECH_FILE)\nwaveform = waveform.to(device)\n\nif sample_rate != bundle.sample_rate:\n    waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc74c\ud5a5 \ud2b9\uc131 \ucd94\ucd9c\ud558\uae30\n----------------\n\n\ub2e4\uc74c\uc73c\ub85c \uc9c4\ud589\ud560 \uac83\uc740 \uc624\ub514\uc624\uc5d0\uc11c \uc74c\ud5a5 \ud2b9\uc131\uc744 \ucd94\ucd9c\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Wav2Vec2 \ubaa8\ub378\uc740 ASR \ud0dc\uc2a4\ud06c\ub97c \uc704\ud574 \ubbf8\uc138 \uc870\uc815\ub418\uc5b4 \ud2b9\uc131 \ucd94\ucd9c\uacfc \ubd84\ub958\ub97c \n   \ud55c \ubc88\uc5d0 \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n   \ud558\uc9c0\ub9cc \uc790\uc138\ud55c \uc124\uba85\uc744 \uc704\ud574 \uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ud2b9\uc131 \ucd94\ucd9c\uc744 \ud558\ub294 \ubc29\ubc95\ub3c4 \uc124\uba85\ud558\uaca0\uc2b5\ub2c8\ub2e4.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n    features, _ = model.extract_features(waveform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubc18\ud658\ub418\ub294 \ud2b9\uc131\uc740 tensor\uc758 \ubc30\uc5f4\uc774\uace0 \uac01 tensor\ub294 transformer \ub808\uc774\uc5b4\uc758 \ucd9c\ub825\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(len(features), 1, figsize=(16, 4.3 * len(features)))\nfor i, feats in enumerate(features):\n    ax[i].imshow(feats[0].cpu())\n    ax[i].set_title(f\"Feature from transformer layer {i+1}\")\n    ax[i].set_xlabel(\"Feature dimension\")\n    ax[i].set_ylabel(\"Frame (time-axis)\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud2b9\uc131 \ubd84\ub958\ud558\uae30\n------------\n\n\uc74c\ud5a5 \ud2b9\uc131\uc744 \ucd94\ucd9c\ud55c \ud6c4 \ub2e4\uc74c \ub2e8\uacc4\ub294 \ud2b9\uc131\uc744 \uce74\ud14c\uace0\ub9ac\ub85c \ubd84\ub958\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\nWav2Vec2 \ubaa8\ub378\uc740 \ud2b9\uc131 \ucd94\ucd9c\uacfc \ubd84\ub958\ub97c \ud55c \ubc88\uc5d0 \uc218\ud589\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n    emission, _ = model(waveform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\uacfc\ub294 \ud655\ub960\uc758 \ud615\ud0dc\uac00 \uc544\ub2cc \ub85c\uc9d3(logit)\uc758 \ud615\ud0dc\ub85c \ub098\uc635\ub2c8\ub2e4.\n\n\uc774\ub97c \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.imshow(emission[0].cpu().T)\nplt.title(\"Classification result\")\nplt.xlabel(\"Frame (time-axis)\")\nplt.ylabel(\"Class\")\nplt.show()\nprint(\"Class labels:\", bundle.get_labels())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud0c0\uc784 \ub77c\uc778\uc5d0 \ub530\ub77c \ud2b9\uc815\ud55c \ub77c\ubca8\uc774 \uac15\ud558\uac8c \ub098\ud0c0\ub098\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub300\ubcf8(transcript) \uc0dd\uc131\ud558\uae30\n------------------------\n\n\uc774\uc81c \ub77c\ubca8 \ud655\ub960\uc758 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ub300\ubcf8(transcript)\uc744 \uc0dd\uc131\ud560 \ucc28\ub840\uc785\ub2c8\ub2e4. \uc774\ub807\uac8c \uac00\uc124\uc744 \n\uc0dd\uc131\ud558\ub294 \uacfc\uc815\uc744 \"\ub514\ucf54\ub529\"\uc774\ub77c\uace0 \ubd80\ub985\ub2c8\ub2e4.\n\n\ub514\ucf54\ub529\uc740 \ub2e8\uc21c\ud55c \ubd84\ub958\ubcf4\ub2e4\ub294 \ub354 \uc815\uad50\ud55c \uc791\uc5c5\uc785\ub2c8\ub2e4. \n\ud2b9\uc815 \ud0c0\uc784 \uc2a4\ud15d\uc5d0\uc11c \ub514\ucf54\ub529\uc744 \ud558\ub294 \uac83\uc740 \uc8fc\ubcc0 \uad00\uce21\uc5d0 \uc601\ud5a5\uc744 \ubc1b\uc744 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\n\uc608\ub97c \ub4e4\uc5b4 ``night`` \uc640 ``knight`` \uc758 \uacbd\uc6b0\ub97c \uc0dd\uac01\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. ``night`` \uc640 \n``knight`` \uc758 \uc0ac\uc804 \ud655\ub960 \ubd84\ud3ec\uac00 \ub2e4\ub974\ub354\ub77c\ub3c4 \n(\uc77c\ubc18\uc801\uc778 \ub300\ud654\uc5d0\uc11c ``night`` \uac00 ``knight`` \ubcf4\ub2e4 \ud6e8\uc52c \ub354 \uc790\uc8fc \ub4f1\uc7a5\ud569\ub2c8\ub2e4) \n``a knight with a sword`` \uc640 \uac19\uc740 \ubb38\uc7a5\uc5d0\uc11c ``knight`` \ub85c \uc815\ud655\ud55c \ub300\ubcf8\uc744 \uc0dd\uc131\ud558\uae30 \n\uc704\ud574\uc11c\ub294 \ub514\ucf54\ub529 \uacfc\uc815\uc5d0\uc11c \ucda9\ubd84\ud55c \ubb38\ub9e5\uc744 \ubcfc \ub54c\uae4c\uc9c0 \ucd5c\uc885 \uacb0\uc815\uc744 \uc5f0\uae30\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\ub514\ucf54\ub529\uc744 \uc704\ud55c \ub2e4\uc591\ud55c \uae30\uc220\ub4e4\uc740 \ub9ce\uc740 \uacbd\uc6b0 \n\ub2e8\uc5b4 \uc0ac\uc804\uacfc \uc5b8\uc5b4 \ubaa8\ub378\uacfc \uac19\uc740 \uc678\ubd80 \ub9ac\uc18c\uc2a4\ub97c \uc694\uad6c\ud569\ub2c8\ub2e4.\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ub2e8\uc21c\ud568\uc744 \uc704\ud574 \ud0d0\uc695\uc801\uc778(greedy) \ub514\ucf54\ub529\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc678\ubd80 \uc694\uc18c\uc5d0 \n\uc758\uc874\ud558\uc9c0 \uc54a\uace0 \uac01 \ud0c0\uc784 \uc2a4\ud15d\uc5d0\uc11c \uac00\uc7a5 \uc88b\uc740 \uac00\uc124\uc744 \uc120\ud0dd\ud558\uaca0\uc2b5\ub2c8\ub2e4. \n\ub530\ub77c\uc11c \ubb38\ub9e5 \uc815\ubcf4\ub294 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uace0 \ud558\ub098\uc758 \ub300\ubcf8\ub9cc \uc0dd\uc131\ub429\ub2c8\ub2e4.\n\n\ud0d0\uc695\uc801\uc778 \ub514\ucf54\ub529 \uc54c\uace0\ub9ac\uc998\uc744 \uc815\uc758\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GreedyCTCDecoder(torch.nn.Module):\n    def __init__(self, labels, blank=0):\n        super().__init__()\n        self.labels = labels\n        self.blank = blank\n\n    def forward(self, emission: torch.Tensor) -> str:\n        \"\"\"Given a sequence emission over labels, get the best path string\n        Args:\n          emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n\n        Returns:\n          str: The resulting transcript\n        \"\"\"\n        indices = torch.argmax(emission, dim=-1)  # [num_seq,]\n        indices = torch.unique_consecutive(indices, dim=-1)\n        indices = [i for i in indices if i != self.blank]\n        return \"\".join([self.labels[i] for i in indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub514\ucf54\ub354 \uac1d\uccb4\ub97c \uc0dd\uc131\ud558\uace0, \ub300\ubcf8\uc744 \ub514\ucf54\ub529\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "decoder = GreedyCTCDecoder(labels=bundle.get_labels())\ntranscript = decoder(emission[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uacb0\uacfc\ub97c \ud655\uc778\ud558\uace0 \uc624\ub514\uc624\ub97c \ub2e4\uc2dc \ub4e4\uc5b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(transcript)\nIPython.display.Audio(SPEECH_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ASR \ubaa8\ub378\uc740 Connectionist Temporal Classification (CTC)\uc774\ub77c\ub294 \uc190\uc2e4 \ud568\uc218\ub97c \n\uc0ac\uc6a9\ud558\uc5ec \ubbf8\uc138 \uc870\uc815\ub429\ub2c8\ub2e4. CTC \uc190\uc2e4 \ud568\uc218\uc758 \uc138\ubd80 \uc0ac\ud56d\uc740 \n`\uc5ec\uae30 <https://distill.pub/2017/ctc/>`__ \ub97c \ucc38\uace0\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\nCTC\uc5d0\uc11c \uacf5\ubc31 \ud1a0\ud070 (\u03f5)\uc740 \uae30\uc874 \uc2ec\ubcfc\uc758 \ubc18\ubcf5\uc744 \ub098\ud0c0\ub0b4\ub294 \uc2a4\ud398\uc15c \ud1a0\ud070\uc785\ub2c8\ub2e4. \n\ub514\ucf54\ub529 \uacfc\uc815\uc5d0\uc11c \uacf5\ubc31 \ud1a0\ud070\uc740 \ubb34\uc2dc\ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\ub860\n----\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc74c\ud5a5 \ud2b9\uc131 \ucd94\ucd9c\uacfc \uc74c\uc131 \uc778\uc2dd\uc744 \uc704\ud574\uc11c \n:py:mod:`torchaudio.pipelines` \ub97c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ud558\ub294\uc9c0 \uc54c\uc544\ubcf4\uc558\uc2b5\ub2c8\ub2e4. \n\ubaa8\ub378\uc744 \ub9cc\ub4e4\uace0 \uc0b0\ucd9c\ubb3c(emission)\uc744 \uc5bb\ub294 \ubaa8\ub4e0 \uacfc\uc815\uc740 \uc544\ub798\uc758 2\uc904 \ub9cc\uc73c\ub85c\ub3c4 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n\n::\n\n   model = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.get_model()\n   emission = model(waveforms, ...)\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}