{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nnumpy \uc640 scipy \ub97c \uc774\uc6a9\ud55c \ud655\uc7a5(Extensions) \ub9cc\ub4e4\uae30\n=====================================================\n**Author**: `Adam Paszke <https://github.com/apaszke>`_\n\n**Updated by**: `Adam Dziedzic <https://github.com/adam-dziedzic>`_\n\n**\ubc88\uc5ed**: `Ajin Jeong <https://github.com/ajin-jng>`_\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ub450 \uac00\uc9c0 \uc791\uc5c5\uc744 \uc218\ud589\ud560 \uac83\uc785\ub2c8\ub2e4:\n\n1. \ub9e4\uac1c \ubcc0\uc218\uac00 \uc5c6\ub294 \uc2e0\uacbd\ub9dd \uacc4\uce35(layer) \ub9cc\ub4e4\uae30\n    - \uc774\ub294 \uad6c\ud604\uc758 \uc77c\ubd80\ub85c **numpy** \ub97c \ud638\ucd9c\ud569\ub2c8\ub2e4.\n\n2. \ud559\uc2b5 \uac00\ub2a5\ud55c \uac00\uc911\uce58\uac00 \uc788\ub294 \uc2e0\uacbd\ub9dd \uacc4\uce35(layer) \ub9cc\ub4e4\uae30\n    - \uc774\ub294 \uad6c\ud604\uc758 \uc77c\ubd80\ub85c **Scipy** \ub97c \ud638\ucd9c\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.autograd import Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9e4\uac1c \ubcc0\uc218\uac00 \uc5c6\ub294(Parameter-less) \uc608\uc2dc\n----------------------------------------\n\n\uc774 \uacc4\uce35(layer)\uc740 \ud2b9\ubcc4\ud788 \uc720\uc6a9\ud558\uac70\ub098 \uc218\ud559\uc801\uc73c\ub85c \uc62c\ubc14\ub978 \uc791\uc5c5\uc744 \uc218\ud589\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\uc774\ub984\uc740 \ub300\ucda9 BadFFTFunction\uc73c\ub85c \uc9c0\uc5c8\uc2b5\ub2c8\ub2e4.\n\n**\uacc4\uce35(layer) \uad6c\ud604**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy.fft import rfft2, irfft2\n\n\nclass BadFFTFunction(Function):\n    @staticmethod\n    def forward(ctx, input):\n        numpy_input = input.detach().numpy()\n        result = abs(rfft2(numpy_input))\n        return input.new(result)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        numpy_go = grad_output.numpy()\n        result = irfft2(numpy_go)\n        return grad_output.new(result)\n\n# \uc774 \uacc4\uce35\uc5d0\ub294 \ub9e4\uac1c \ubcc0\uc218\uac00 \uc5c6\uc73c\ubbc0\ub85c nn.Module \ud074\ub798\uc2a4\uac00 \uc544\ub2cc \ud568\uc218\ub85c \uac04\ub2e8\ud788 \uc120\uc5b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ndef incorrect_fft(input):\n    return BadFFTFunction.apply(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\uc0dd\uc131\ub41c \uacc4\uce35(layer)\uc758 \uc0ac\uc6a9 \uc608\uc2dc:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = torch.randn(8, 8, requires_grad=True)\nresult = incorrect_fft(input)\nprint(result)\nresult.backward(torch.randn(result.size()))\nprint(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9e4\uac1c \ubcc0\uc218\uac00 \uc788\ub294(Parameterized) \uc608\uc2dc\n----------------------------------------\n\n\ub525\ub7ec\ub2dd \ubb38\ud5cc\uc5d0\uc11c \uc774 \uacc4\uce35(layer)\uc758 \uc2e4\uc81c \uc5f0\uc0b0\uc740 \uc0c1\ud638 \uc0c1\uad00(cross-correlation)\uc774\uc9c0\ub9cc\n\ud569\uc131\uacf1(convolution)\uc774\ub77c\uace0 \ud5f7\uac08\ub9ac\uac8c \ubd80\ub974\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n(\ud569\uc131\uacf1\uc740 \ud544\ud130\ub97c \ub4a4\uc9d1\uc5b4\uc11c \uc5f0\uc0b0\uc744 \ud558\ub294 \ubc18\uba74, \uc0c1\ud638 \uc0c1\uad00\uc740 \uadf8\ub807\uc9c0 \uc54a\uc740 \ucc28\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4)\n\n\ud559\uc2b5 \uac00\ub2a5\ud55c \uac00\uc911\uce58\ub97c \uac00\ub294 \ud544\ud130(\ucee4\ub110)\ub97c \uac16\ub294 \uc0c1\ud638 \uc0c1\uad00 \uacc4\uce35\uc744 \uad6c\ud604\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc5ed\uc804\ud30c \ub2e8\uacc4(backward pass)\uc5d0\uc11c\ub294 \uc785\ub825\uc5d0 \ub300\ud55c \uae30\uc6b8\uae30(gradient)\uc640 \ud544\ud130\uc5d0 \ub300\ud55c \uae30\uc6b8\uae30\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy import flip\nimport numpy as np\nfrom scipy.signal import convolve2d, correlate2d\nfrom torch.nn.modules.module import Module\nfrom torch.nn.parameter import Parameter\n\n\nclass ScipyConv2dFunction(Function):\n    @staticmethod\n    def forward(ctx, input, filter, bias):\n        # \ubd84\ub9ac(detach)\ud558\uc5ec NumPy\ub85c \ubcc0\ud658(cast)\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n        input, filter, bias = input.detach(), filter.detach(), bias.detach()\n        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n        result += bias.numpy()\n        ctx.save_for_backward(input, filter, bias)\n        return torch.as_tensor(result, dtype=input.dtype)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        grad_output = grad_output.detach()\n        input, filter, bias = ctx.saved_tensors\n        grad_output = grad_output.numpy()\n        grad_bias = np.sum(grad_output, keepdims=True)\n        grad_input = convolve2d(grad_output, filter.numpy(), mode='full')\n        # \uc717\uc904\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 \ud45c\ud604\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4:\n        # grad_input = correlate2d(grad_output, flip(flip(filter.numpy(), axis=0), axis=1), mode='full')\n        grad_filter = correlate2d(input.numpy(), grad_output, mode='valid')\n        return torch.from_numpy(grad_input), torch.from_numpy(grad_filter).to(torch.float), torch.from_numpy(grad_bias).to(torch.float)\n\n\nclass ScipyConv2d(Module):\n    def __init__(self, filter_width, filter_height):\n        super(ScipyConv2d, self).__init__()\n        self.filter = Parameter(torch.randn(filter_width, filter_height))\n        self.bias = Parameter(torch.randn(1, 1))\n\n    def forward(self, input):\n        return ScipyConv2dFunction.apply(input, self.filter, self.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\uc0ac\uc6a9 \uc608\uc2dc:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "module = ScipyConv2d(3, 3)\nprint(\"Filter and bias: \", list(module.parameters()))\ninput = torch.randn(10, 10, requires_grad=True)\noutput = module(input)\nprint(\"Output from the convolution: \", output)\noutput.backward(torch.randn(8, 8))\nprint(\"Gradient for the input map: \", input.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\uae30\uc6b8\uae30(gradient) \ud655\uc778:**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.autograd.gradcheck import gradcheck\n\nmoduleConv = ScipyConv2d(3, 3)\n\ninput = [torch.randn(20, 20, dtype=torch.double, requires_grad=True)]\ntest = gradcheck(moduleConv, input, eps=1e-6, atol=1e-4)\nprint(\"Are the gradients correct: \", test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}