{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uc2ec\ud654 \uacfc\uc815 : Bi-LSTM CRF\uc640 \ub3d9\uc801 \uacb0\uc815\n======================================================\n\n\ub3d9\uc801, \uc815\uc801 \ub525 \ub7ec\ub2dd \ud234\ud0b7(toolkits) \ube44\uad50\n--------------------------------------------\n\nPytorch\ub294 *\ub3d9\uc801* \uc2e0\uacbd\ub9dd \ud234\ud0b7\uc785\ub2c8\ub2e4. \ub2e4\ub978 \ub3d9\uc801 \uc2e0\uacbd\ub9dd \ud234\ud0b7\uc73c\ub85c\ub294\n`Dynet <https://github.com/clab/dynet>`_ \uc774 \uc788\uc2b5\ub2c8\ub2e4.(\uc774 \ud234\ud0b7\uc744\n\uc608\ub85c \ub4e0 \uc774\uc720\ub294 \uc0ac\uc6a9\ud558\ub294 \ubc95\uc774 Pytorch\uc640 \ube44\uc2b7\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. Dynet\uc758 \uc608\uc81c\ub97c \ubcf4\uba74\nPytorch\ub85c \uad6c\ud604\ud560 \ub54c\ub3c4 \ub3c4\uc6c0\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4.) \ubc18\ub300\ub85c *\uc815\uc801* \ud234\ud0b7\ub4e4\ub85c\nTheano, Keras, TensorFlow \ub4f1\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc8fc\uc694 \ucc28\uc774\uc810\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n* \uc815\uc801 \ud234\ud0b7\uc744 \uc4f8 \ub54c\ub294 \uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \ud55c \ubc88\ub9cc \uc815\uc758\ud558\uace0, \ucef4\ud30c\uc77c \ud55c \ud6c4,\n  \ub370\uc774\ud130\ub97c \uacc4\uc0b0 \uadf8\ub798\ud504\uc5d0 \ub118\uae41\ub2c8\ub2e4.\n* \ub3d9\uc801 \ud234\ud0b7\uc5d0\uc11c\ub294 *\uac01 \ub370\uc774\ud130* \uc758 \uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \uc815\uc758\ud558\uba70 \ucef4\ud30c\uc77c\ud558\uc9c0\n  \uc54a\uace0 \uc989\uac01 \uc2e4\ud589\ub429\ub2c8\ub2e4.\n\n\uacbd\ud5d8\uc774 \ub9ce\uc9c0 \uc54a\ub2e4\uba74 \ub450 \ubc29\uc2dd\uc758 \ucc28\uc774\ub97c \uc54c\uae30 \uc5b4\ub835\uc2b5\ub2c8\ub2e4. \ub525 \ub7ec\ub2dd \uae30\ubc18\uc758\n\uad6c\uad6c\uc870 \ubd84\uc11d\uae30(constituent parser)\ub97c \uc608\ub85c \ub4e4\uc5b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \ubaa8\ub378\uc740 \ub300\ub7b5\n\ub2e4\uc74c\uacfc \uac19\uc740 \uacfc\uc815\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n* \ud2b8\ub9ac\ub97c \uc0c1\ud5a5\uc2dd(bottom-up)\uc73c\ub85c \ub9cc\ub4e4\uc5b4 \ub098\uac11\ub2c8\ub2e4.\n* \ucd5c\uc0c1\uc704 \ub178\ub4dc\ub97c \ud0dc\uae45\ud569\ub2c8\ub2e4. (\ubb38\uc7a5\uc758 \uac01 \ub2e8\uc5b4)\n* \uac70\uae30\uc11c\ubd80\ud130 \uc2e0\uacbd\ub9dd\uacfc \ub2e8\uc5b4\ub4e4\uc758 \uc784\ubca0\ub529\uc744 \uc774\uc6a9\ud574 \uad6c\uad6c\uc870\ub97c \uc774\ub8e8\ub294 \uc870\ud569\uc744\n  \ucc3e\uc544\ub0c5\ub2c8\ub2e4. \uc0c8\ub85c\uc6b4 \uad6c\uad6c\uc870\ub97c \uc0dd\uc131\ud560 \ub54c\ub9c8\ub2e4 \uad6c\uad6c\uc870\uc758 \uc784\ubca0\ub529\uc744 \uc5bb\uae30 \uc704\ud55c\n  \uc5b4\ub5a4 \uae30\uc220\uc774 \ud544\uc694\ud569\ub2c8\ub2e4. \uc9c0\uae08\uc740 \uc2e0\uacbd\ub9dd\uc774 \uc624\uc9c1 \uc785\ub825 \ubb38\uc7a5\ub9cc \ucc38\uace0\ud560\n  \uac83\uc785\ub2c8\ub2e4. \"The green cat scratched the wall\"\uc774\ub780 \ubb38\uc7a5\uc5d0\uc11c, \ubaa8\ub378\uc758 \uc5b4\ub290 \uc2dc\uc810\uc5d0\n  $(i,j,r) = (1, 3, \\text{NP})$ \ubc94\uc704 (\ub2e8\uc5b4 1\uc5d0\uc11c\ubd80\ud130 \ub2e8\uc5b4 3\uae4c\uc9c0\uac00\n  NP \uad6c\uad6c\uc870\ub77c\ub294 \ub73b\uc774\uba70, \uc774 \ubb38\uc7a5\uc5d0\uc11c\ub294 \"The green cat\") \ub97c \uacb0\ud569\ud558\uae38 \uc6d0\ud560\n  \uac83\uc785\ub2c8\ub2e4.\n\n\uadf8\ub7f0\ub370, \ub610\ub2e4\ub978 \ubb38\uc7a5 \"Somewhere, the big fat cat scratched the wall\" \uc5d0\uc11c\ub294\n\uc5b4\ub290 \uc2dc\uc810\uc5d0 $(2, 4, NP)$ \uad6c\uad6c\uc870\ub97c \ub9cc\ub4e4\uae30\ub97c \uc6d0\ud560 \uac83\uc785\ub2c8\ub2e4. \uc6b0\ub9ac\uac00\n\ub9cc\ub4e4\uae30 \uc6d0\ud558\ub294 \uad6c\uad6c\uc870\ub4e4\uc740 \ubb38\uc7a5\uc5d0 \ub530\ub77c \ub2e4\ub985\ub2c8\ub2e4. \ub9cc\uc57d \uc815\uc801 \ud234\ud0b7\uc5d0\uc11c\ucc98\ub7fc\n\uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \ud55c \ubc88\ub9cc \ucef4\ud30c\uc77c\ud55c\ub2e4\uba74, \uc774 \uacfc\uc815\uc744 \ud504\ub85c\uadf8\ub798\ubc0d\ud558\uae30 \ub9e4\uc6b0 \uc5b4\ub835\uac70\ub098\n\ubd88\uac00\ub2a5\ud560 \uac83\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ub3d9\uc801 \ud234\ud0b7\uc5d0\uc11c\ub294 \ud558\ub098\uc758 \uacc4\uc0b0 \uadf8\ub798\ud504\ub9cc \uc788\uc9c0\n\uc54a\uc2b5\ub2c8\ub2e4. \uac01 \ubb38\uc7a5\ub4e4\ub9c8\ub2e4 \uc0c8\ub85c\uc6b4 \uacc4\uc0b0 \uadf8\ub798\ud504\uac00 \uc788\uc744 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774\ub7f0\n\ubb38\uc81c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\n\n\ub3d9\uc801 \ud2c0\ud0b7\uc740 \ub514\ubc84\uae45 \ud558\uae30 \ub354 \uc27d\uace0, \ucf54\ub4dc\uac00 \uae30\ubc18 \uc5b8\uc5b4\uc640 \ub354 \ube44\uc2b7\ud569\ub2c8\ub2e4\n(Pytorch\uc640 Dynet\uc774 Keras \ub610\ub294 Theano \ubcf4\ub2e4 Python \ucf54\ub4dc\uc640 \ub354 \ube44\uc2b7\ud569\ub2c8\ub2e4).\n\nBi-LSTM Conditional Rnadom Field \uc124\uba85\n-------------------------------------------\n\n\uc774 \uc601\uc5ed\uc5d0\uc11c\ub294 \uac1c\uccb4\uba85 \uc778\uc2dd\uc744 \uc218\ud589\ud558\ub294 \uc644\uc131\ub41c Bi-LSTM Conditional Random\nField \uc608\uc2dc\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc704\uc5d0 \ub098\uc628 LSTM \ud0dc\uac70(tagger)\ub294 \uc77c\ubc18\uc801\uc73c\ub85c\n\ud488\uc0ac \ud0dc\uae45\uc744 \ud558\uae30\uc5d0 \ucda9\ubd84\ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc CRF \uac19\uc740 \uc5f0\uc18d\ub41c \ub370\uc774\ud130\ub97c \ub2e4\ub8e8\ub294\n\ubaa8\ub378\uc740 \uc88b\uc740 \uac1c\uccb4\uba85 \uc778\uc2dd \ubaa8\ub378(NER)\uc5d0 \uaf2d \ud544\uc694\ud569\ub2c8\ub2e4. \uc5ec\ub7ec\ubd84\uc774 CRF\ub97c \uc798 \uc54c\uace0\n\uc788\ub2e4\uace0 \uac00\uc815\ud558\uaca0\uc2b5\ub2c8\ub2e4. \uc774\ub984\uc774 \ubb34\uc12d\uac8c \ub4e4\ub9b4 \uc218\ub3c4 \uc788\uc9c0\ub9cc, LSTM\uc774 \ud2b9\uc9d5\uc744\n\uc81c\uacf5\ud558\ub294 \uc810\uc744 \uc81c\uc678\ud558\uba74 \uc774 \ubaa8\ub378\uc740 CRF \uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ub354 \ubc1c\uc804\ub41c \ubaa8\ub378\uc774\uba70,\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \uc55e\ubd80\ubd84\uc5d0 \ub098\uc654\ub358 \ubaa8\ub378\ubcf4\ub2e4 \ud6e8\uc52c \ubcf5\uc7a1\ud569\ub2c8\ub2e4. \ub118\uc5b4\uac00\uace0 \uc2f6\ub2e4\uba74\n\ub118\uc5b4\uac00\ub3c4 \uad1c\ucc2e\uc2b5\ub2c8\ub2e4. \uc774\ud574\ud560 \uc218 \uc788\ub2e4\uace0 \uc0dd\uac01\ud55c\ub2e4\uba74, \uc544\ub798\ub97c \uc77d\uc5b4\ubcf4\uc138\uc694:\n\n-  \ud0dc\uadf8 k\uc5d0 \ub300\ud55c i\ubc88\uc9f8 \ub2e8\uacc4\uc758 \ube44\ud130\ube44(viterbi) \ubcc0\uc218\ub97c \uc704\ud574 \uc21c\ud658 \ud750\ub984\uc744 \ub9cc\ub4e0\ub2e4.\n-  \uc21c\ubc29\ud5a5 \ubcc0\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \uc704\uc758 \uc21c\ud55c \ud750\ub984\uc744 \uc870\uc815\ud55c\ub2e4.\n-  \uc21c\ubc29\ud5a5 \ubcc0\uc218\ub97c \ub85c\uadf8 \uacf5\uac04\uc5d0\uc11c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \ub2e4\uc2dc \ud55c \ubc88 \uc870\uc815\ud55c\ub2e4.\n   (\ud78c\ud2b8 : \ub85c\uadf8-\ud569-\uc9c0\uc218\uc2b9)\n\n\uc704\uc758 \uc138\uac00\uc9c0\ub97c \ud560 \uc218 \uc788\ub2e4\uba74, \uc544\ub798\uc758 \ucf54\ub4dc\ub97c \uc774\ud574\ud560 \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4.\nCRF\ub294 \uc870\uac74\ubd80 \ud655\ub960\uc744 \uacc4\uc0b0\ud55c\ub2e4\ub294 \uc810\uc744 \uae30\uc5b5\ud558\uc138\uc694. $y$ \ub97c \uc5f0\uc18d\ub41c\n\ud0dc\uadf8\ub77c \ud558\uace0, $x$ \ub97c \uc5f0\uc18d\ub41c \uc785\ub825 \ub2e8\uc5b4\ub77c \ud558\uaca0\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\uba74 \uc544\ub798\uc758\n\uc2dd\uc744 \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\\begin{align}P(y|x) = \\frac{\\exp{(\\text{Score}(x, y)})}{\\sum_{y'} \\exp{(\\text{Score}(x, y')})}\\end{align}\n\n\uc810\uc218(score) \ud568\uc218\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ub41c \ub85c\uadf8 \ud3ec\ud150\uc15c(potential) $\\log \\psi_i(x,y)$\n\ud568\uc218\uc5d0 \uc758\ud574 \uacb0\uc815\ub429\ub2c8\ub2e4.\n\n\\begin{align}\\text{Score}(x,y) = \\sum_i \\log \\psi_i(x,y)\\end{align}\n\n\ubd84\ubc30 \ud568\uc218(partition function)\ub97c \ub2e8\uc21c\ud654\ud558\uae30 \uc704\ud574\uc11c, \ud3ec\ud150\uc15c\uc774 \uc8fc\ubcc0\uc758\n\ud2b9\uc9d5\ub4e4\ub9cc \ubc18\uc601\ud55c\ub2e4\uace0 \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\nBi-LSTM CRF \uc548\uc5d0 \ubc30\ucd9c(emission), \uc804\uc774(transition) \ub450 \uc885\ub958\uc758 \ud3ec\ud150\uc15c\uc744\n\uc815\uc758\ud569\ub2c8\ub2e4. $i$ \ubc88\uc9f8 \ub2e8\uc5b4\uc5d0 \ub300\ud55c \ubc30\ucd9c \ud3ec\ud150\uc15c\uc740 Bi-LSTM\uc758\n$i$ \ubc88\uc9f8 \uc2dc\uc810\uc758 \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uacb0\uc815\ud569\ub2c8\ub2e4. \uc804\uc774 \uc810\uc218\ub294 $|T|x|T|$\n\ud615\ud0dc\uc778 \ud589\ub82c $\\textbf{P}$ \uc5d0 \uc800\uc7a5\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. $T$ \ub294\n\ud0dc\uadf8\uc758 \uc9d1\ud569\uc785\ub2c8\ub2e4. \uc774 \uad6c\ud604\uc5d0\uc11c, $\\textbf{P}_{j,k}$ \ub294 tag $j$ \uc5d0\uc11c\ntag $k$ \ub85c\uc758 \uc804\uc774 \uc810\uc218\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c:\n\n\\begin{align}\\text{Score}(x,y) = \\sum_i \\log \\psi_\\text{EMIT}(y_i \\rightarrow x_i) + \\log \\psi_\\text{TRANS}(y_{i-1} \\rightarrow y_i)\\end{align}\n\n\\begin{align}= \\sum_i h_i[y_i] + \\textbf{P}_{y_i, y_{i-1}}\\end{align}\n\n\ub450 \ubc88\uc9f8 \uc2dd\uc5d0\uc11c \uace0\uc720\ud558\uace0 \uc74c\uc218\uac00 \uc544\ub2cc \uc778\ub371\uc2a4\uc5d0 \uc758\ud574 \ud0dc\uadf8\uac00 \ubd80\uc5ec\ub410\ub2e4\uace0\n\uac04\uc8fc\ud569\ub2c8\ub2e4.\n\n\uc704\uc758 \uc124\uba85\uc774 \ub108\ubb34 \uac04\ub2e8\ud558\ub2e4\uace0 \uc0dd\uac01\ud55c\ub2e4\uba74 CRF\uc5d0 \ub300\ud55c Michael Collins\uc758\n\uae00\uc744 `\uc5ec\uae30 <http://www.cs.columbia.edu/%7Emcollins/crf.pdf>`__ \uc5d0\uc11c\n\uc77d\uc5b4\ubcf4\uc138\uc694.\n\n\uad6c\ud604 \ubb38\uc11c\n--------------------\n\n\uc544\ub798\uc758 \uc608\uc2dc\ub294 \ub85c\uadf8 \uacf5\uac04\uc5d0\uc11c \ubd84\ubc30 \ud568\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud55c \uc21c\ubc29\ud5a5 \uc54c\uace0\ub9ac\uc998\uacfc\n\ubcf5\ud638\ud654\ud558\uae30 \uc704\ud55c \ube44\ud130\ube44 \uc54c\uace0\ub9ac\uc998\uc744 \uad6c\ud604\ud55c \uac83\uc785\ub2c8\ub2e4. \uc5ed\uc804\ud30c\n\ub2e8\uacc4\uc5d0\uc11c \ubcc0\ud654\ub3c4\ub294 \uc790\ub3d9\uc73c\ub85c \uacc4\uc0b0\ub420 \uac83\uc785\ub2c8\ub2e4. \uc6b0\ub9ac\uac00 \uc9c1\uc811 \ud560 \uc77c\uc740\n\uc5c6\uc2b5\ub2c8\ub2e4.\n\n\uc774 \uad6c\ud604\uc740 \ucd5c\uc801\uc758 \uc0c1\ud0dc\uac00 \uc544\ub2d9\ub2c8\ub2e4. \uacfc\uc815\uc744 \uc774\ud574\ud588\ub2e4\uba74, \uc21c\ubc29\ud5a5 \uc54c\uace0\ub9ac\uc998\n\uc0c1\uc5d0\uc11c \ub2e4\uc74c \ud0dc\uadf8\ub97c \uc21c\ucc28\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\ub294 \uacfc\uc815\uc744 \ud558\ub098\uc758 \ud070 \uc5f0\uc0b0\uc73c\ub85c \uc904\uc77c\n\uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc544\ub9c8 \ube60\ub974\uac8c \uc54c \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4. \uc774 \ucf54\ub4dc\ub294 \uac00\ub2a5\ud55c \uc77d\uae30\n\uc27d\uac8c \uc791\uc131\ud588\uc2b5\ub2c8\ub2e4. \uc801\uc808\ud558\uac8c \uc218\uc815\ud558\uba74, \uc774 \ud0dc\uac70\ub97c \uc2e4\uc81c \ubb38\uc81c\ub4e4\uc5d0 \uc0ac\uc6a9\ud560\n\uc218\ub3c4 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc791\uc131\uc790: Robert Guthrie\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucf54\ub4dc \uac00\ub3c5\uc131\uc744 \ub192\uc5ec\uc8fc\ub294 \ubcf4\uc870 \ud568\uc218\ub4e4\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def argmax(vec):\n    # argmax\ub97c \ud30c\uc774\uc36c \uc815\uc218\ud615\uc73c\ub85c \ubc18\ud658\ud569\ub2c8\ub2e4.\n    _, idx = torch.max(vec, 1)\n    return idx.item()\n\n\ndef prepare_sequence(seq, to_ix):\n    idxs = [to_ix[w] for w in seq]\n    return torch.tensor(idxs, dtype=torch.long)\n\n\n# \uc21c\ubc29\ud5a5 \uc54c\uace0\ub9ac\uc998\uc744 \uc704\ud574 \uc218\uce58\uc801\uc73c\ub85c \uc548\uc815\uc801\uc778 \ubc29\ubc95\uc73c\ub85c \ub85c\uadf8 \ud569 \uc9c0\uc218\uc2b9\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\ndef log_sum_exp(vec):\n    max_score = vec[0, argmax(vec)]\n    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n    return max_score + \\\n        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc0dd\uc131\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class BiLSTM_CRF(nn.Module):\n\n    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.vocab_size = vocab_size\n        self.tag_to_ix = tag_to_ix\n        self.tagset_size = len(tag_to_ix)\n\n        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n                            num_layers=1, bidirectional=True)\n\n        # LSTM\uc758 \ucd9c\ub825\uc744 \ud0dc\uadf8 \uacf5\uac04\uc73c\ub85c \ub300\uc751\uc2dc\ud0b5\ub2c8\ub2e4.\n        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n\n        # \uc804\uc774 \ub9e4\uac1c\ubcc0\uc218 \ud589\ub82c. i, j \uc131\ubd84\uc740 i\uc5d0\uc11c j\ub85c \ubcc0\ud560 \ub54c\uc758 \uc810\uc218\uc785\ub2c8\ub2e4.\n        self.transitions = nn.Parameter(\n            torch.randn(self.tagset_size, self.tagset_size))\n\n        # \uc774 \ub450 \ucf54\ub4dc\ub294 \uc2dc\uc791 \ud0dc\uadf8\ub85c \uc804\uc774\ud558\uc9c0 \uc54a\uace0, \uc815\uc9c0 \ud0dc\uadf8\uc5d0\uc11c\ubd80\ud130\n        # \uc804\uc774\ud558\uc9c0 \uc54a\ub3c4\ub85d \uac15\uc81c\ud569\ub2c8\ub2e4.\n        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n\n        self.hidden = self.init_hidden()\n\n    def init_hidden(self):\n        return (torch.randn(2, 1, self.hidden_dim // 2),\n                torch.randn(2, 1, self.hidden_dim // 2))\n\n    def _forward_alg(self, feats):\n        # \ubd84\ubc30 \ud568\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 \uc21c\ubc29\ud5a5 \uc54c\uace0\ub9ac\uc998\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n        init_alphas = torch.full((1, self.tagset_size), -10000.)\n        # START_TAG\ub294 \ubaa8\ub4e0 \uc810\uc218\ub97c \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n\n        # \uc790\ub3d9\uc73c\ub85c \uc5ed\uc804\ud30c \ub418\ub3c4\ub85d \ubcc0\uc218\ub85c \uac10\uc309\ub2c8\ub2e4.\n        forward_var = init_alphas\n\n        # \ubb38\uc7a5\uc758 \uac01 \uc131\ubd84\uc744 \ubc18\ubcf5 \ucc98\ub9ac\ud569\ub2c8\ub2e4.\n        for feat in feats:\n            alphas_t = []  # \ud604\uc7ac \uc2dc\uc810\uc758 \uc21c\ubc29\ud5a5 \ud150\uc11c\n            for next_tag in range(self.tagset_size):\n                # \uc774\uc804\uc758 \ud0dc\uadf8\uc640 \uc0c1\uad00\uc5c6\uc774 \ubc30\ucd9c \uc810\uc218\ub97c \uc804\ud30c\ud569\ub2c8\ub2e4.\n                emit_score = feat[next_tag].view(\n                    1, -1).expand(1, self.tagset_size)\n                # trans_score\uc758 i\ubc88\uc9f8 \uc131\ubd84\uc740 i\ub85c\ubd80\ud130 next_tag\ub85c \uc804\uc774\ud560 \uc810\uc218\uc785\ub2c8\ub2e4.\n                trans_score = self.transitions[next_tag].view(1, -1)\n                # next_tag_var\uc758 i\ubc88\uc9f8 \uc131\ubd84\uc740 \ub85c\uadf8-\ud569-\uc9c0\uc218\uc2b9\uc744 \uacc4\uc0b0\ud558\uae30 \uc804\n                # i\uc5d0\uc11c next_tag\ub85c \uac00\ub294 \uac04\uc120\uc758 \uac12\uc785\ub2c8\ub2e4.\n                next_tag_var = forward_var + trans_score + emit_score\n                # \uc774 \ud0dc\uadf8\uc758 \uc21c\ubc29\ud5a5 \ubcc0\uc218\ub294 \ubaa8\ub4e0 \uc810\uc218\ub4e4\uc758 \ub85c\uadf8-\ud569-\uc9c0\uc218\uc2b9 \uacc4\uc0b0\n                # \uacb0\uacfc\uc785\ub2c8\ub2e4.\n                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n            forward_var = torch.cat(alphas_t).view(1, -1)\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        alpha = log_sum_exp(terminal_var)\n        return alpha\n\n    def _get_lstm_features(self, sentence):\n        self.hidden = self.init_hidden()\n        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n        lstm_feats = self.hidden2tag(lstm_out)\n        return lstm_feats\n\n    def _score_sentence(self, feats, tags):\n        # \uc8fc\uc5b4\uc9c4 \ud0dc\uadf8 \uc21c\uc5f4\uc5d0 \uc810\uc218\ub97c \ub9e4\uae41\ub2c8\ub2e4.\n        score = torch.zeros(1)\n        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n        for i, feat in enumerate(feats):\n            score = score + \\\n                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n        return score\n\n    def _viterbi_decode(self, feats):\n        backpointers = []\n\n        # \ube44\ud130\ube44 \ubcc0\uc218\ub97c \ub85c\uadf8 \uacf5\uac04 \uc0c1\uc5d0 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n        init_vvars = torch.full((1, self.tagset_size), -10000.)\n        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n\n        # i \ub2e8\uacc4\uc758 forward_var\ub294 i-1 \ub2e8\uacc4\uc758 \ube44\ud130\ube44 \ubcc0\uc218\ub97c \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n        forward_var = init_vvars\n        for feat in feats:\n            bptrs_t = []  # \ud604\uc7ac \ub2e8\uacc4\uc758 backpointer\ub97c \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n            viterbivars_t = []  # \ud604\uc7ac \ub2e8\uacc4\uc758 \ube44\ud130\ube44 \ubcc0\uc218\ub97c \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n            for next_tag in range(self.tagset_size):\n                # next_tag_var[i]\ub294 \uc774\uc804 \ub2e8\uacc4\uc758 \ud0dc\uadf8 i\uc5d0 \ub300\ud55c \ube44\ud130\ube44 \ubcc0\uc218\uc640,\n                # \ud0dc\uadf8 i\uc5d0\uc11c next_tag\ub85c \uc804\uc774\ud560 \uc810\uc218\ub97c \ub354\ud55c \uac12\uc744 \uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n                # \ubc30\ucd9c \uc810\uc218\ub294 argmax\uc640 \uc0c1\uad00 \uc5c6\uae30 \ub54c\ubb38\uc5d0(\uc544\ub798 \ucf54\ub4dc\uc5d0\uc11c \ucd94\uac00\ud560 \uac83\uc785\ub2c8\ub2e4)\n                # \uc5ec\uae30\uc5d0 \ud3ec\ud568\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n                next_tag_var = forward_var + self.transitions[next_tag]\n                best_tag_id = argmax(next_tag_var)\n                bptrs_t.append(best_tag_id)\n                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n            # \uc774\uc81c \ubc30\ucd9c \uc810\uc218\ub97c \ub354\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0 \ubc29\uae08 \uacc4\uc0b0\ud55c \ube44\ud130\ube44 \ubcc0\uc218\uc758\n            # \uc9d1\ud569\uc744 forward_var\uc5d0 \ud560\ub2f9\ud569\ub2c8\ub2e4.\n            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n            backpointers.append(bptrs_t)\n\n        # STAP_TAG\ub85c\uc758 \uc804\uc774\n        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n        best_tag_id = argmax(terminal_var)\n        path_score = terminal_var[0][best_tag_id]\n\n        # \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \uad6c\ud558\uae30 \uc704\ud574 back pointer\ub97c \ub530\ub77c\uac11\ub2c8\ub2e4.\n        best_path = [best_tag_id]\n        for bptrs_t in reversed(backpointers):\n            best_tag_id = bptrs_t[best_tag_id]\n            best_path.append(best_tag_id)\n        # \uc2dc\uc791 \ud0dc\uadf8\ub97c \ube7c\ub0c5\ub2c8\ub2e4 (\uc2dc\uc791 \ud0dc\uadf8\ub294 \ubc18\ud658\ub41c \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4)\n        start = best_path.pop()\n        assert start == self.tag_to_ix[START_TAG]  # \uc644\uacb0\uc131 \uac80\uc0ac (Sanity check)\n        best_path.reverse()\n        return path_score, best_path\n\n    def neg_log_likelihood(self, sentence, tags):\n        feats = self._get_lstm_features(sentence)\n        forward_score = self._forward_alg(feats)\n        gold_score = self._score_sentence(feats, tags)\n        return forward_score - gold_score\n\n    def forward(self, sentence):  # \uc774 \ud568\uc218\uc640 \uc704\uc758 _forward_alg\ub97c \ud5f7\uac08\ub9ac\uc9c0 \ub9c8\uc138\uc694.\n        # Bi-LSTM\uc73c\ub85c\ubd80\ud130 \ubc30\ucd9c \uc810\uc218\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\n        lstm_feats = self._get_lstm_features(sentence)\n\n        # \uc8fc\uc5b4\uc9c4 \ud2b9\uc9d5(\ubc30\ucd9c \uc810\uc218)\ub4e4\ub85c \ucd5c\uc801\uc758 \uacbd\ub85c\ub97c \ucc3e\uc544\ub0c5\ub2c8\ub2e4.\n        score, tag_seq = self._viterbi_decode(lstm_feats)\n        return score, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud6c8\ub828 \uc2e4\ud589\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "START_TAG = \"<START>\"\nSTOP_TAG = \"<STOP>\"\nEMBEDDING_DIM = 5\nHIDDEN_DIM = 4\n\n# \ud6c8\ub828\uc6a9 \ub370\uc774\ud130\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\ntraining_data = [(\n    \"the wall street journal reported today that apple corporation made money\".split(),\n    \"B I I I O O O B I O O\".split()\n), (\n    \"georgia tech is a university in georgia\".split(),\n    \"B I O O O O B\".split()\n)]\n\nword_to_ix = {}\nfor sentence, tags in training_data:\n    for word in sentence:\n        if word not in word_to_ix:\n            word_to_ix[word] = len(word_to_ix)\n\ntag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n\nmodel = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n\n# \ud6c8\ub828 \uc804 \uc608\uce21 \uacb0\uacfc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.\nwith torch.no_grad():\n    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n    print(model(precheck_sent))\n\n# Make sure prepare_sequence from earlier in the LSTM section is loaded\n# \uc704\uc758 \ubcf4\uc870 \ud568\uc218 \uc601\uc5ed\uc5d0 \uc788\ub294 prepare_sequence \ud568\uc218\uac00 \ubd88\ub7ec\uc640 \uc84c\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\nfor epoch in range(\n        300):  # \ub2e4\uc2dc \ub9d0\ud558\uc9c0\ub9cc, \uc544\ub9c8 300 \uc5d0\ud3ed\uc744 \uc2e4\ud589\ud558\uc9c4 \uc54a\uc744 \uac83\uc785\ub2c8\ub2e4. \uc774\uac83\uc740 \uc5f0\uc2b5\uc6a9 \ub370\uc774\ud130\uc785\ub2c8\ub2e4.\n    for sentence, tags in training_data:\n        # 1\ub2e8\uacc4. Pytorch\uac00 \ubcc0\ud654\ub3c4\ub97c \ub204\uc801\ud55c\ub2e4\ub294 \uac83\uc744 \uae30\uc5b5\ud558\uc138\uc694.\n        # \uadf8\uac83\ub4e4\uc744 \uc81c\uac70\ud569\ub2c8\ub2e4.\n        model.zero_grad()\n\n        # 2\ub2e8\uacc4. \uc785\ub825 \ub370\uc774\ud130\ub97c \uc2e0\uacbd\ub9dd\uc5d0 \uc0ac\uc6a9\ub420 \uc218 \uc788\ub3c4\ub85d \ub2e8\uc5b4\n        # \uc778\ub371\uc2a4\ub4e4\uc758 \ud150\uc11c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n        sentence_in = prepare_sequence(sentence, word_to_ix)\n        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n\n        # 3\ub2e8\uacc4. \uc21c\ubc29\ud5a5 \uacc4\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n        loss = model.neg_log_likelihood(sentence_in, targets)\n\n        # 4\ub2e8\uacc4. \uc190\uc2e4\uac12, \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uace0 optimizer.step()\uc744 \ud638\ucd9c\ud558\uc5ec\n        # \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \uac31\uc2e0\ud569\ub2c8\ub2e4.\n        loss.backward()\n        optimizer.step()\n\n# \ud6c8\ub828\uc774 \ub05d\ub09c \ud6c4 \uc608\uce21 \uacb0\uacfc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.\nwith torch.no_grad():\n    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n    print(model(precheck_sent))\n# \ub2e4 \ud588\uc2b5\ub2c8\ub2e4!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5f0\uc2b5 : \ud310\ubcc4\uc801(discriminative) \ud0dc\uae45\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \uc190\uc2e4 \ud568\uc218\n------------------------------------------------------------\n\n\uc0ac\uc2e4 \ubcf5\ud638\ud654 \ud560 \ub54c\ub294 \ube44\ud130\ube44 \uacbd\ub85c \uc810\uc218\ub85c \uc5ed\uc804\ud30c\ub97c \ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \uacc4\uc0b0\n\uadf8\ub798\ud504\ub97c \ub9cc\ub4e4 \ud544\uc694\uac00 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc774\ubbf8 \ub9cc\ub4e4\uc5c8\uc73c\ub2c8, \ube44\ud130\ube44 \uacbd\ub85c\n\uc810\uc218\uc640 \uc2e4\uc81c \uc815\ub2f5 \uacbd\ub85c \uc810\uc218\uc758 \ucc28\uc774\ub97c \uc190\uc2e4 \ud568\uc218\ub85c \uc0ac\uc6a9\ud574\uc11c \ud0dc\uac70\ub97c\n\ud559\uc2b5\uc2dc\ucf1c \ubcf4\uc138\uc694. \uc190\uc2e4 \ud568\uc218\uc758 \uac12\uc740 \uc74c\uc218\uac00 \uc544\ub2c8\uc5b4\uc57c \ud558\uba70, \uc608\uce21\ub41c \ud0dc\uadf8\n\uc21c\uc5f4\uc774 \uc815\ub2f5\uc774\ub77c\uba74 \uc190\uc2e4 \ud568\uc218\uc758 \uac12\uc740 0\uc774\uc5b4\uc57c \ud569\ub2c8\ub2e4. \uc774\uac83\uc740 \ubcf8\uc9c8\uc801\uc73c\ub85c\n*\uad6c\uc870\ud654\ub41c \ud37c\uc149\ud2b8\ub860* \uc785\ub2c8\ub2e4.\n\n\uc774\ubbf8 \ube44\ud130\ube44\uc640 score_sentence \ud568\uc218\uac00 \uad6c\ud604\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \uac04\ub2e8\ud788 \uc218\uc815\ud560\n\uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc740 *\ud559\uc2b5 \ub370\uc774\ud130\uc5d0 \ub530\ub77c \ubcc0\ud558\ub294* \uacc4\uc0b0 \uadf8\ub798\ud504\uc758 \ud55c\n\uc608\uc2dc\uc785\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc744 \uc815\uc801 \ud234\ud0b7\uc5d0\uc11c \uad6c\ud604\ud574 \ubcf4\uc9c0\ub294 \uc54a\uc558\ub294\ub370, \uad6c\ud604\uc774\n\uac00\ub2a5\ud558\uc9c0\ub9cc \ub35c \uc9c1\uad00\uc801\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc2e4\uc81c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud574\ubcf4\uace0 \ube44\uad50\ud574\ubcf4\uc138\uc694!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}